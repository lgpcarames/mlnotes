#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Notas sobre Machine Learning com AWS
\end_layout

\begin_layout Section
Engenharia de Dados
\end_layout

\begin_layout Subsection
Amazon S3
\end_layout

\begin_layout Subsubsection*
Visão Geral
\end_layout

\begin_layout Itemize
O amazon S3 permite que as pessoas armazenem objetos (arquivos) em buckets
 (diretórios);
\end_layout

\begin_layout Itemize
Os buckets devem ter um nome único global, isso porque o endereço de acesso
 de todos os usuários do S3 deve ser único;
\end_layout

\begin_layout Itemize
Os objetos (arquivos) tem uma chave.
 A chave é o caminho completo:
\end_layout

\begin_deeper
\begin_layout Labeling
\labelwidthstring 00.00.0000
<my_bucket>/my_file.txt
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
<my_bucket>/my_folder1/another_folder/my_file.txt
\end_layout

\end_deeper
\begin_layout Itemize
Isso é útil e interessante quando olharmos partições: as partições permitem
 uma consulta mais otimizada;
\end_layout

\begin_layout Itemize
O tamanho máximo de um objeto é de 5TB;
\end_layout

\begin_layout Itemize
Tags de objeto (chave/valor, até 10), úteis para segurança e ciclo de vida;
\end_layout

\begin_layout Subsubsection*
AWS S3 para Machine Learning
\end_layout

\begin_layout Itemize
Backbone para muitos seviços de ML do AWS (ex.
 SageMaker)
\end_layout

\begin_layout Itemize
Cria um DataLake:
\end_layout

\begin_deeper
\begin_layout Itemize
Tamanho infinito, sem necessidade de provisionar o espaço que será utilizado;
\end_layout

\end_deeper
\begin_layout Itemize
Durabilidade 99,99999999%
\end_layout

\begin_deeper
\begin_layout Itemize
A durabilidade é uma medida da probabilidade de seus dados serem não serem
 corrompidos, quanto maior a durabilidade, menos a chance de serem corrompidos.
\end_layout

\end_deeper
\begin_layout Itemize
Armazenamento (S3) desacoplado do processamento (EC2, Amazon, Athena, Amazon
 RedShift Spectrum, Amazon Rekognition e AWS Glue);
\end_layout

\begin_layout Itemize
Arquitetura centralizada: isso é importante para que se tenha todos os seus
 arquivos em único local de forma centralizada;
\end_layout

\begin_layout Itemize
Armazenamento de objetos: suporta qualquer tipo de arquivo;
\end_layout

\begin_layout Itemize
Formatos comuns para ML: CSV, JSON, Parquet, ORC, Avro, Protobuf;
\end_layout

\begin_layout Subsubsection*
AWS S3: Particionamento
\end_layout

\begin_layout Itemize
Padrões para acelerar consultas em intervalos (ex: AWS Athena)
\end_layout

\begin_layout Itemize
Por data: S3://bucket/my-data-set/year/month/day/hour/data_00.csv
\end_layout

\begin_layout Itemize
Por produto: S3://bucket/my-data-set/product-id/data_32.csv
\end_layout

\begin_layout Itemize
Você pode definir qual estratégia de particionamento você quer
\end_layout

\begin_layout Itemize
O particionamento de dados será feito por algumas ferramentas que vamos
 usar.
 (AWS Glue)
\end_layout

\begin_layout Subsection
S3 Storage - Camadas de Armazenamento e Políticas de Ciclo de Vida
\end_layout

\begin_layout Itemize
Amazon S3 Standard - Uso geral;
\end_layout

\begin_layout Itemize
Amazon S3 - Acesso Infrequente (IA);
\end_layout

\begin_layout Itemize
Amazon S3 One Zone - Acesso Infrequente: Armazenada em um local único;
\end_layout

\begin_layout Itemize
Amazon S3 - Camada Inteligente: O serviço escolhe os melhores locais de
 armazenamento visando melhores preços;
\end_layout

\begin_layout Itemize
Amazon Glacier: Utilizado para arquivar dados que não serão mais utilizados;
\end_layout

\begin_layout Subsubsection*
Regras de Ciclo de vida
\end_layout

\begin_layout Itemize
Conjunto de regras para mover os dados entre diferentes camadas, para reduzir
 custo de armazenamento;
\end_layout

\begin_layout Itemize
Exemplo: Primeiramente o arquivo é alocado para uso geral, depois de um
 tempo, este arquivo é alocado para uso infrequente, depois de mais algum
 tempo, esse arquivo então é arquivado, sendo alocado para o Amazon Glacier;
\end_layout

\begin_layout Itemize
Ações de transição: Objetos fazem a transição para outra classe de armazenamento
;
\end_layout

\begin_deeper
\begin_layout Itemize
Mover objetos da classe Padrão para o Uso Infrequente depois de 60 dias
 de criação;
\end_layout

\begin_layout Itemize
Mover os objetos do Uso Infrequente para o Glacier após 6 meses;
\end_layout

\end_deeper
\begin_layout Itemize
Ações de expiração: O S3 exclui objetos experiados para nós ao nosso critério.
\end_layout

\begin_layout Subsection
Segurança
\end_layout

\begin_layout Subsubsection*
Criptografia S3 para Objetos
\end_layout

\begin_layout Itemize
Criptografia S3: A criptografia pode ser realizada no servidor AWS ou pelo
 próprio cliente;
\end_layout

\begin_layout Itemize
Exitem 4 métodos de criptografia para objetos no S3;
\end_layout

\begin_deeper
\begin_layout Itemize
SSE-S3: Criptografa objetos S3 usando chaves criadas e gerenciadas pelo
 AWS;
\end_layout

\begin_layout Itemize
SSE-KMS: Usa o serviço de gestão de chaves do AWS para gerenciar chaves
 criptográficas;
\end_layout

\begin_deeper
\begin_layout Itemize
Segurança adicional (usuário deve ter acesso à chave KMS);
\end_layout

\begin_layout Itemize
Trilha de auditoria da chave KMS;
\end_layout

\end_deeper
\begin_layout Itemize
SSE-C: Quando se quer gerencias as suas próprias chaves;
\end_layout

\begin_layout Itemize
Criptografia no cliente: Ocorre fora do ambiente AWS;
\end_layout

\end_deeper
\begin_layout Itemize
De uma perspectiva de ML, SSE-S3 e SSE-KMS são os mais usados;
\end_layout

\begin_layout Subsubsection*
Gestão de Segurança
\end_layout

\begin_layout Itemize
Gestão de segurança baseada no usuário
\end_layout

\begin_deeper
\begin_layout Itemize
Políticas IAM (Identity Access Management) - Quais chamadas de API devem
 ser permitidas para usuários específicos;
\end_layout

\end_deeper
\begin_layout Itemize
Baseada em recursos
\end_layout

\begin_deeper
\begin_layout Itemize
Políticas de buckets: 
\end_layout

\begin_deeper
\begin_layout Itemize
Regras abrangentes de buckets;
\end_layout

\begin_layout Itemize
Permitem contas cruzadas
\end_layout

\end_deeper
\begin_layout Itemize
Lista de controle de acesso a objetos (ACL):
\end_layout

\begin_deeper
\begin_layout Itemize
Controle mais detalhado;
\end_layout

\end_deeper
\begin_layout Itemize
Lista de controle de acesso ao bucket (ACL):
\end_layout

\begin_deeper
\begin_layout Itemize
Menos comum;
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Políticas de Buckets S3:
\end_layout

\begin_deeper
\begin_layout Itemize
Políticas baseadas em JSON:
\end_layout

\begin_deeper
\begin_layout Itemize
Gerenciamento de Recursos: buckets e objetos
\end_layout

\begin_layout Itemize
Ações: vai permitir ou negar o consumo de uma API;
\end_layout

\begin_layout Itemize
Efeito da API: Permitir ou negar;
\end_layout

\begin_layout Itemize
Principal: A conta ou usuário que aplica a política;
\end_layout

\end_deeper
\begin_layout Itemize
Use a política de Bucket S3 para:
\end_layout

\begin_deeper
\begin_layout Itemize
Dar acesso ao público a um bucket;
\end_layout

\begin_layout Itemize
Forçar objetos a serem criptografados no upload;
\end_layout

\begin_layout Itemize
Dar acesso a outra conta (conta cruzada);
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Criptografia Padrão S3 vs Políticas de Buckets
\end_layout

\begin_deeper
\begin_layout Itemize
A forma antiga de habilitar criptografia por padrão era usar uma política
 de Bucket e recusar qualquer comando HTTP sem o cabeçalho apropriado;
\end_layout

\begin_layout Itemize
A nova forma é usar a opção de 
\begin_inset Quotes eld
\end_inset

criptografia padrão
\begin_inset Quotes erd
\end_inset

 no S3;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Segurança S3 - Outros
\end_layout

\begin_layout Itemize
Rede - VPC (Virtual Private Cloud) Endpoint Gateway:
\end_layout

\begin_deeper
\begin_layout Itemize
Permite que o tráfico fique dentro da sua VPC, ao invés de ir para a internet
 pública;
\end_layout

\begin_layout Itemize
Garante que seus serviços privados (AWS SageMaker) possam acessar o S3;
\end_layout

\begin_layout Itemize
Muito importante para o exame AWS ML;
\end_layout

\end_deeper
\begin_layout Itemize
Log e Auditoria
\end_layout

\begin_deeper
\begin_layout Itemize
Logs de acesso podem ser armazenados em outro bucket S3;
\end_layout

\begin_layout Itemize
Chamadas de API podem ser logadas na 
\begin_inset Quotes eld
\end_inset

AWS Cloud Trail
\begin_inset Quotes erd
\end_inset

;
\end_layout

\end_deeper
\begin_layout Itemize
Baseados em Tags: Combina política IAM e políticas de Bucket:
\end_layout

\begin_deeper
\begin_layout Itemize
Exemplo: Adicionar a tag classification=PHI a seus objetos;
\end_layout

\end_deeper
\begin_layout Subsection
AWS Kinesis Data Stream Data Firehose
\end_layout

\begin_layout Subsubsection*
AWS Kineses: Visão Geral
\end_layout

\begin_layout Itemize
Kinesis é uma alternativa gerenciada do Apache Kafka;
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
O Apache Kafka é uma ferramenta de Data Streaming.
 
\end_layout

\begin_layout Plain Layout
No Data Streaming os dados são processados em tempo real, ou muito próximo
 do real.
 Diferente do batch de dados, que é um processamento em blocos, geralmente
 ocorrendo tomando os dados obtidos a partir de um intervalo de tempo, como
 dias, semanas meses, ou anos.
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Ótimo para logs de aplicações, IOT, clickstreams;
\end_layout

\begin_layout Itemize
Ótimo para processar dados em tempo real;
\end_layout

\begin_layout Itemize
Ótimo para frameworks de processamento em streaming (Spark, NiFi, etc.)
\end_layout

\begin_layout Itemize
Dados são automaticamente replicados de forma síncrona para 
\begin_inset Formula $3AZ$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Itemize
O AWS Kinesis é formado por 4 aplicações principais:
\end_layout

\begin_deeper
\begin_layout Itemize
Kinesis Streams: Ingestão de streaming com baixa latência e em grande escala;
\end_layout

\begin_layout Itemize
Kinesis Analytics: Executa análise em tempo real em streams usando SQL;
\end_layout

\begin_layout Itemize
Kinesis Firehose: Carrega streams no S3, RedShift, ElasticSearch e Splunk;
\end_layout

\begin_layout Itemize
Kinesis Video Streams: Usado para stream de vídeo em tempo real;
\end_layout

\end_deeper
\begin_layout Itemize
Visão Geral do Kinesis Streams:
\end_layout

\begin_deeper
\begin_layout Itemize
Streams são divididos em Shards ordenados/partições;
\end_layout

\begin_layout Itemize
Os shards devem ser provisionados com antecedência (Planejamento de capacidade);
\end_layout

\begin_layout Itemize
Retenção de dados é de 24 horas por padrão, pode chegar a 7 dias;
\end_layout

\begin_layout Itemize
Capaz de reprocessar dados;
\end_layout

\begin_layout Itemize
Várias aplicações podem consumir o mesmo stream;
\end_layout

\begin_layout Itemize
Uma vez que os dados são inseridos no Kinesis, não pode ser excluído (Imutabilid
ade);
\end_layout

\begin_layout Itemize
Registros podem ter até 1MB de tamanho;
\end_layout

\end_deeper
\begin_layout Itemize
Limites de dados do Kinesis Data
\end_layout

\begin_deeper
\begin_layout Itemize
Produtores
\end_layout

\begin_deeper
\begin_layout Itemize
1MB por segundo ou 1000 mensagens na escrita por SHARD;
\end_layout

\begin_layout Itemize
Ou então 
\begin_inset Quotes eld
\end_inset

ProvisionedThroughputException
\begin_inset Quotes erd
\end_inset

 será levantado, caso o limite seja ultrapassado;
\end_layout

\end_deeper
\begin_layout Itemize
Consumidor clássico:
\end_layout

\begin_deeper
\begin_layout Itemize
2MB/s de leitura por SHARD entre todos os consumidores;
\end_layout

\begin_layout Itemize
5 camadas de API por segundo por SHARD entre todos os consumidores
\end_layout

\end_deeper
\begin_layout Itemize
Retenção de dados:
\end_layout

\begin_deeper
\begin_layout Itemize
24 horas por padrão
\end_layout

\begin_layout Itemize
Pode ser estendido até por 7 dias;
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Kinesis Data Firehose:
\end_layout

\begin_deeper
\begin_layout Itemize
Serviço totalmente gerenciado, sem administração;
\end_layout

\begin_layout Itemize
Próximo ao tempo real (mínimo de 60 segundos de latencia para batches não
 completos);
\end_layout

\begin_layout Itemize
Ingestão de dados no RedShift/Amazon S3/ElasticSearch/Splunk
\end_layout

\begin_layout Itemize
Escala automaticamente;
\end_layout

\begin_layout Itemize
Suporte a muitos formatos de dados;
\end_layout

\begin_layout Itemize
Conversão de dados CSV/JSON para Parquet/ORC (apenas para o S3);
\end_layout

\begin_layout Itemize
Transformação de dados através do AWS Lambda (ex: CSV=>JSON);
\end_layout

\begin_layout Itemize
Suporta compressão quando usa o Amazon S3 (GZIP, ZIP e SNAPPY);
\end_layout

\begin_layout Itemize
Paga-se pela quantidade de dados que entra no Firehose;
\end_layout

\end_deeper
\begin_layout Itemize
Kinesis Data Analytics
\end_layout

\begin_deeper
\begin_layout Itemize
Casos de uso:
\end_layout

\begin_deeper
\begin_layout Itemize
Streaming ETL: Seleciona colunas, faz transformações simples em dados em
 streaming;
\end_layout

\begin_layout Itemize
Gerador contínuo de métricas: classificação ao vivo para um jogo mobile;
\end_layout

\begin_layout Itemize
Análise responsiva: verifica certo critério e cria alertas (filtrando);
\end_layout

\end_deeper
\begin_layout Itemize
Características:
\end_layout

\begin_deeper
\begin_layout Itemize
Paga apenas por recursos consumidos (mas não é barato);
\end_layout

\begin_layout Itemize
Serverless: escala automaticamente;
\end_layout

\begin_layout Itemize
Usa permissão IAM para acessar fontes de streaming e destinos;
\end_layout

\begin_layout Itemize
SQL ou Flink para escrever o processamento;
\end_layout

\begin_layout Itemize
Descoberta de Schema;
\end_layout

\begin_layout Itemize
Lambda pode ser usado para pré-processamento;
\end_layout

\end_deeper
\begin_layout Itemize
Machine Learning no Kinesis Data Analytics:
\end_layout

\begin_deeper
\begin_layout Itemize
RANDOM_CUT_FOREST:
\end_layout

\begin_deeper
\begin_layout Itemize
Função SQL usada para detecção de anomalias em colunas numéricas de um stream;
\end_layout

\begin_layout Itemize
Exemplo: detectar passageiros anormais no metrô durante a maratona de Nova
 Iorque;
\end_layout

\begin_layout Itemize
Usa o histórico recente para processar o modelo;
\end_layout

\end_deeper
\begin_layout Itemize
HOTSPOTS:
\end_layout

\begin_deeper
\begin_layout Itemize
Localiza e informa sobre regiões relativamente densas nos seus dados;
\end_layout

\begin_layout Itemize
Exemplo: uma coleção de servidores superaquecidos em um datacenter;
\end_layout

\end_deeper
\end_deeper
\end_deeper
\begin_layout Itemize
Resumo do Kinesis - Machine Learning:
\end_layout

\begin_deeper
\begin_layout Itemize
Kinesis Data Stream: Cria aplicações de machine learning em tempo real;
\end_layout

\begin_layout Itemize
Kinesis Data Analytics: algoritmos ETL/ML em tempo real em stream;
\end_layout

\begin_layout Itemize
Kinesis Video Stream: Stream de vídeo em tempo real para criar aplicações
 em ML;
\end_layout

\end_deeper
\begin_layout Subsection
Glue Data Catalog
\end_layout

\begin_layout Itemize
Repositório de metadados para todas as suas tabelas;
\end_layout

\begin_deeper
\begin_layout Itemize
Automatiza inferência de schema: lembrando que schema é a definição dos
 seus dados ou a estrutura que os dados tem.
\end_layout

\begin_layout Itemize
O schema é versionado: a medida que a estrutura é mudada, ela é versionada;
\end_layout

\end_deeper
\begin_layout Itemize
Integrado com o Athena ou RedShift Spectrum (schema e data discovery)
\end_layout

\begin_layout Itemize
Glue Crawlers pode lhe ajudar a construir um Glue Data Catalog;
\end_layout

\begin_layout Subsubsection*
Glue Data Catalog - Crawlers
\end_layout

\begin_layout Itemize
Crawlers exploram seus dados para inferir schemas e partições;
\end_layout

\begin_layout Itemize
Funciona com JSON, Parquet, CSV, relacional;
\end_layout

\begin_layout Itemize
Crawlers funciona com: S3, Amazon RedShift, Amazon RDS;
\end_layout

\begin_layout Itemize
O Crawler pode ser agendado ou rodado sob demanda;
\end_layout

\begin_layout Itemize
Para rodar o crawler precisa de uma credencial ou IAM Role para acessar
 as fontes de dados;
\end_layout

\begin_layout Subsubsection*
Glue e Partições S3
\end_layout

\begin_layout Itemize
Glue Crawler vai extrair partições baseadas em como seus dados no S3 estão
 organizados;
\end_layout

\begin_layout Itemize
Pense com antecedência sobre como você consultará seu data lake no S3;
\end_layout

\begin_layout Itemize
Exemplo: dispositivos enviam dados de sensores a cada hora;
\end_layout

\begin_deeper
\begin_layout Itemize
Você consulta principalmente por intervalos de tempo?
\end_layout

\begin_deeper
\begin_layout Itemize
Em caso afirmativo, organize seus intervalos como S3://my-bucket/dataset/aaaa/mm
/dd/dispositivo
\end_layout

\end_deeper
\begin_layout Itemize
Você consulta principalmente por dispositivo?
\end_layout

\begin_deeper
\begin_layout Itemize
Em caso afirmativo, organize seus intervalos como S3://my-bucket/dataset/device/
aaaa/mm/dd
\end_layout

\end_deeper
\end_deeper
\begin_layout Subsubsection*
Glue ETL
\end_layout

\begin_layout Itemize
Transformar dados, limpar dados, enriquecer dados (antes de fazer a análise)
\end_layout

\begin_deeper
\begin_layout Itemize
Gera código ETL em Python ou Scala, você pode modificar o código;
\end_layout

\begin_layout Itemize
Ou você pode fornecer seus próprios scripts Spark ou Pyspark;
\end_layout

\begin_layout Itemize
O destino pode ser S3, JDBC (RDS, RedShift) ou o catálogo de dados do Glue;
\end_layout

\end_deeper
\begin_layout Itemize
Totalmente gerenciado, econômico, paga apenas pelos recursos consumidos;
\end_layout

\begin_layout Itemize
Os jobs são executados em uma plataforma spark serverless;
\end_layout

\begin_layout Itemize
Glue Scheduler para agendar os trabalhos
\end_layout

\begin_layout Itemize
Glue Triggers para automatizar execuções de trabalho com base em 
\begin_inset Quotes eld
\end_inset

eventos
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Subsubsection*
Glue ET: Transformações
\end_layout

\begin_layout Itemize
Transformações empacotadas (Bundled):
\end_layout

\begin_deeper
\begin_layout Itemize
DropFields, DropNullFields: Remover campos nulos;
\end_layout

\begin_layout Itemize
Filter: Específica uma função para filtrar registros;
\end_layout

\begin_layout Itemize
Join: Para enriquecer os dados;
\end_layout

\begin_layout Itemize
Map: Adicionar campos, excluir campos, realizar pesquisas externas;
\end_layout

\end_deeper
\begin_layout Itemize
Transformações para aprendizado de máquinas:
\end_layout

\begin_deeper
\begin_layout Itemize
FindMatches ML: Identifica registros duplicados ou correspondentes em seu
 conjunto de dados, mesmo quando os registros não têm um identificador único
 comum e nenhum campo que corresponde exatamente;
\end_layout

\begin_layout Itemize
Conversões de formato: CSV, JSON, AVRO, Parquet, ORC, XML;
\end_layout

\begin_layout Itemize
Transformações do Apache Spark (exemplo: K-means);
\end_layout

\end_deeper
\begin_layout Subsection
AWS Data Stores Para Machine Learning 
\end_layout

\begin_layout Itemize
RedShift - Data Warehousing, SQL Analytics (OLAP - Online Analytical Processing)
:
\end_layout

\begin_deeper
\begin_layout Itemize
Carrega dados do S3 para o RedShift;
\end_layout

\begin_layout Itemize
Use o RedShift Spectrum para consultar dados diretamente no S3 (sem necessitar
 carregar);
\end_layout

\end_deeper
\begin_layout Itemize
RDS, Aurora:
\end_layout

\begin_deeper
\begin_layout Itemize
Armazenamento Relacional, SQL (OLTP - Online Transaction Processing);
\end_layout

\begin_layout Itemize
Servidores devem ser provisionados com antecedência;
\end_layout

\end_deeper
\begin_layout Itemize
DynamoDB:
\end_layout

\begin_deeper
\begin_layout Itemize
Armazenamento NoSQL, serverless, provisão com capacidade de leitura e escrita;
\end_layout

\begin_layout Itemize
Útil para armazenar o modelo de machine learning servido pela sua aplicação;
\end_layout

\end_deeper
\begin_layout Itemize
S3:
\end_layout

\begin_deeper
\begin_layout Itemize
Armazenamento de objetos;
\end_layout

\begin_layout Itemize
Serverless, armazenamento infinito;
\end_layout

\begin_layout Itemize
Integração com a maioria dos serviços AWS;
\end_layout

\end_deeper
\begin_layout Itemize
ElasticSearch:
\end_layout

\begin_deeper
\begin_layout Itemize
Indexação de dados;
\end_layout

\begin_layout Itemize
Pesquisa nos dados;
\end_layout

\begin_layout Itemize
Clickstream Analytics;
\end_layout

\end_deeper
\begin_layout Itemize
ElastiCache:
\end_layout

\begin_deeper
\begin_layout Itemize
Mecanismo de cache;
\end_layout

\begin_layout Itemize
Não é usado para aprendizado de máquina;
\end_layout

\end_deeper
\begin_layout Subsection
AWS Data Pipeline
\end_layout

\begin_layout Itemize
Os destinos incluem S3, RDS, DynamoDB, RedShift e EMR;
\end_layout

\begin_layout Itemize
Gerencia dependências entre tarefas;
\end_layout

\begin_layout Itemize
Tenta novamente e notifica falhas;
\end_layout

\begin_layout Itemize
As fontes de dados podem ser locais (on-premises);
\end_layout

\begin_layout Itemize
Altamente disponível;
\end_layout

\begin_layout Subsubsection*
AWS Data Pipeline vs Glue
\end_layout

\begin_layout Itemize
Glue:
\end_layout

\begin_deeper
\begin_layout Itemize
Glue ETL - Executa o código Apache Spark, baseado em Scala ou Python, com
 foco no ETL;
\end_layout

\begin_layout Itemize
Não se preocupa em configurar ou gerenciar os recursos;
\end_layout

\begin_layout Itemize
Tem um catálogo de dados para disponibililzar os dados para o Athena ou
 RedShift Spectrum;
\end_layout

\end_deeper
\begin_layout Itemize
Data Pipeline:
\end_layout

\begin_deeper
\begin_layout Itemize
Serviço de Orquestração;
\end_layout

\begin_layout Itemize
Mais controle sobre o ambiente, recursos de computação que executam código;
\end_layout

\begin_layout Itemize
Permite acesso à instâncias EC2 ou EMR (cria recursos em sua própria conta);
\end_layout

\end_deeper
\begin_layout Section
Análise de dados exploratória
\end_layout

\begin_layout Subsection
AWS Athena
\end_layout

\begin_layout Itemize
Serviço de consulta interativa para S3 (SQL);
\end_layout

\begin_deeper
\begin_layout Itemize
Não há necessidade de carregar dados, ele permanece no S3;
\end_layout

\begin_layout Itemize
Utiliza Presto;
\end_layout

\begin_layout Itemize
Serverless;
\end_layout

\begin_layout Itemize
Suporta muitos formatos de dados:
\end_layout

\begin_deeper
\begin_layout Itemize
CSV (legível para humanos);
\end_layout

\begin_layout Itemize
JSON (legível para humanos);
\end_layout

\begin_layout Itemize
ORC (colunar, divísivel);
\end_layout

\begin_layout Itemize
Parquet (colunar, divísivel);
\end_layout

\begin_layout Itemize
Avro (divísivel);
\end_layout

\begin_layout Itemize
Não estruturado, semiestruturado ou estruturado;
\end_layout

\end_deeper
\begin_layout Itemize
Alguns exemplos:
\end_layout

\begin_deeper
\begin_layout Itemize
Consultas ad-hoc de logs da web;
\end_layout

\begin_layout Itemize
Consultas de dados de teste antes de carregar no RedShift;
\end_layout

\begin_layout Itemize
Analisa olos do cloudtrail/cloudfront/VPL/ELB, etc no S3;
\end_layout

\begin_layout Itemize
Integração com notebookos do Jupyter, Zeppelin, RStudio;
\end_layout

\begin_layout Itemize
Integração com o QuickSight;
\end_layout

\begin_layout Itemize
Integração via ODBC/JDBC com ferramentas de visualização;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Modelo de custo do Athena;
\end_layout

\begin_layout Itemize
Paga conforme o uso
\end_layout

\begin_deeper
\begin_layout Itemize
$5 por TB;
\end_layout

\begin_layout Itemize
Consultas bem-sucedidas ou canceladas contam, consultas com falha não;
\end_layout

\end_deeper
\begin_layout Itemize
Sem custo para DDL (CREATE, ALTER, DROP, etc.)
\end_layout

\begin_layout Itemize
Economize muito dinheiro usando formatos em colunas:
\end_layout

\begin_deeper
\begin_layout Itemize
ORC, Parquet;
\end_layout

\begin_layout Itemize
Economize 30-90% e obtenha melhor desempenho;
\end_layout

\end_deeper
\begin_layout Itemize
Glue e S3 têm seus próprios custos;
\end_layout

\begin_layout Subsubsection*
Segurança no Athena 
\end_layout

\end_deeper
\begin_layout Itemize
Controle de Acesso
\end_layout

\begin_deeper
\begin_layout Itemize
IAM, ACLs, Políticas de bucket S3;
\end_layout

\begin_layout Itemize
/AmazonAthenaFullAccess/AWSQuicksightAthenaAccess
\end_layout

\end_deeper
\begin_layout Itemize
Criptografia resultados 
\begin_inset Quotes eld
\end_inset

at rest
\begin_inset Quotes erd
\end_inset

 no diretórios de staging do S3;
\end_layout

\begin_layout Itemize
Croptografia 
\begin_inset Quotes eld
\end_inset

server side
\begin_inset Quotes erd
\end_inset

 com chave KMS (CSE-KMS);
\end_layout

\begin_layout Itemize
Croptografia 
\begin_inset Quotes eld
\end_inset

server side
\begin_inset Quotes erd
\end_inset

 com chave KMS (SSE-KMS);
\end_layout

\begin_layout Itemize
Possibilidade de acesso entre contas na política de Bucket S3;
\end_layout

\begin_layout Itemize
Criptografia Transport Layer Security (TLS) 
\begin_inset Quotes eld
\end_inset

em trânsito
\begin_inset Quotes erd
\end_inset

.
 (entre Athena e S3)
\end_layout

\begin_layout Subsubsection*
Quando não usar o Athena
\end_layout

\begin_layout Itemize
Relatório/Visualização altamente formatados
\end_layout

\begin_deeper
\begin_layout Itemize
É para isso que serve o Quicksight
\end_layout

\end_deeper
\begin_layout Itemize
ETL
\end_layout

\begin_deeper
\begin_layout Itemize
Em vez disso, use o Glue;
\end_layout

\end_deeper
\begin_layout Subsection
Amazon QuickSight
\end_layout

\begin_layout Itemize
Serviço de análise de dados rápido, fácil e baseado na nuvem;
\end_layout

\begin_layout Itemize
Permite que todos os funcionários de uma organização:
\end_layout

\begin_deeper
\begin_layout Itemize
Crie visualizações;
\end_layout

\begin_layout Itemize
Realizar análise ad-hoc;
\end_layout

\begin_layout Itemize
Obtenha rapidamente insight de negócios a partir de dados;
\end_layout

\begin_layout Itemize
A qualquer hora, em qualquer dispositivo (navegadores, celular);
\end_layout

\begin_layout Itemize
Serverless;
\end_layout

\end_deeper
\begin_layout Itemize
Fontes de dados QuickSight
\end_layout

\begin_deeper
\begin_layout Itemize
RedShift;
\end_layout

\begin_layout Itemize
Aurora/RDS;
\end_layout

\begin_layout Itemize
Athena;
\end_layout

\begin_layout Itemize
EC2: Hosted databases
\end_layout

\begin_layout Itemize
Arquivos (S3 ou on-premises)
\end_layout

\begin_deeper
\begin_layout Itemize
Excel;
\end_layout

\begin_layout Itemize
CSV, TSV
\end_layout

\begin_layout Itemize
Formatos de log
\end_layout

\end_deeper
\begin_layout Itemize
A preparação de dados permite ETL limitado;
\end_layout

\end_deeper
\begin_layout Itemize
SPICE
\end_layout

\begin_deeper
\begin_layout Itemize
Os conjuntos de dados são importados para o SPICE
\end_layout

\begin_deeper
\begin_layout Itemize
Mecanismo de cálculo in-memory super rápido e paralelo;
\end_layout

\begin_layout Itemize
Usa armazenamento colunar in-memory, geração de código de máquina;
\end_layout

\begin_layout Itemize
Acelera consultas interativas em grandes conjuntos de dados;
\end_layout

\end_deeper
\begin_layout Itemize
Cada usuário recebe 10GB de SPICE;
\end_layout

\begin_layout Itemize
Altamente disponível durável;
\end_layout

\begin_layout Itemize
Escala para centenas de milhares de usuários;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Casos de uso do QuickSight
\end_layout

\begin_layout Itemize
Exploração/Visualização ad-hoc interativa de dados;
\end_layout

\begin_layout Itemize
Painéis e KPIs;
\end_layout

\begin_layout Itemize
Histórias
\end_layout

\begin_deeper
\begin_layout Itemize
Visitas guiadas por visualizações específicas de uma análise
\end_layout

\begin_layout Itemize
Transmitir os pontos-chave, processo de pensamento, evolução de uma análise;
\end_layout

\begin_layout Itemize
Analisar/Visualizar dados de:
\end_layout

\begin_deeper
\begin_layout Itemize
Logs no S3;
\end_layout

\begin_layout Itemize
Bancos de dados on-premises
\end_layout

\begin_layout Itemize
AWS (RDS, RedShift, Athena, S3)
\end_layout

\begin_layout Itemize
Aplicativos SaaS, como salesforce;
\end_layout

\begin_layout Itemize
Qualquer fonte de dados JDBC/ODBC
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Machine Learning Insights
\end_layout

\begin_deeper
\begin_layout Itemize
Detecção de anomalia;
\end_layout

\begin_layout Itemize
Previsão;
\end_layout

\begin_layout Itemize
Autonarrativas
\end_layout

\end_deeper
\begin_layout Subsubsection*
QuickSight quando não usar
\end_layout

\begin_layout Itemize
Relatórios prontos formatados;
\end_layout

\begin_deeper
\begin_layout Itemize
Quicksight é para consultas e visualizações ad-hoc;
\end_layout

\end_deeper
\begin_layout Itemize
ETL
\end_layout

\begin_deeper
\begin_layout Itemize
Use Glue, embora Quicksight possa fazer algumas transformações;
\end_layout

\end_deeper
\begin_layout Itemize
Segurança do Quicksight;
\end_layout

\begin_deeper
\begin_layout Itemize
Autenticação multifator em sua conta
\end_layout

\begin_layout Itemize
Conectividade VPC;
\end_layout

\begin_deeper
\begin_layout Itemize
Adicione o intervalo de endereços IP do Quicksight aos seus grupos de segurança
 de banco de dados;
\end_layout

\end_deeper
\begin_layout Itemize
Segurança de nível de linha;
\end_layout

\begin_layout Itemize
Acesso VPC privado
\end_layout

\begin_deeper
\begin_layout Itemize
Interface de rede 
\begin_inset Quotes eld
\end_inset

Elastic
\begin_inset Quotes erd
\end_inset

, AWS Direct Connect;
\end_layout

\end_deeper
\end_deeper
\begin_layout Subsubsection*
Gestão de usuários no QuickSight
\end_layout

\begin_layout Itemize
Usuários definidos via IAM ou inscrição por e-mail;
\end_layout

\begin_layout Itemize
Integração do Active Directory com QuickSight Enterprise Edition;
\end_layout

\begin_layout Itemize
Precificação do QuickSight:
\end_layout

\begin_deeper
\begin_layout Itemize
Pagamento anual:
\end_layout

\begin_deeper
\begin_layout Itemize
Standard: $9/Usuário/mês
\end_layout

\begin_layout Itemize
Enterprise: $18/Usuário/mês
\end_layout

\end_deeper
\begin_layout Itemize
Capacidade extra do spice (além do 10GB)
\end_layout

\begin_deeper
\begin_layout Itemize
$0,25 (standard) $0,38 (enterprise)/GB/mês
\end_layout

\end_deeper
\begin_layout Itemize
Mês a mês
\end_layout

\begin_deeper
\begin_layout Itemize
Standard: $12/GB/mês
\end_layout

\begin_layout Itemize
Enterprise: $24/GB/mês
\end_layout

\end_deeper
\begin_layout Itemize
Edição Enterprise:
\end_layout

\begin_deeper
\begin_layout Itemize
Criptografia 
\begin_inset Quotes eld
\end_inset

at rest
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
Integração com Microsoft Active Directory
\end_layout

\end_deeper
\end_deeper
\begin_layout Subsection
O que é EMR?
\end_layout

\begin_layout Itemize
Elastic Map Reduce;
\end_layout

\begin_layout Itemize
Estrutura Gerenciada do Hadoop em instâncias EC2;
\end_layout

\begin_layout Itemize
Inclui Spark, HBase, Presto, Flink, Hive e mais;
\end_layout

\begin_layout Itemize
EMR notebooks;
\end_layout

\begin_layout Itemize
Vários pontos de integração com AWS;
\end_layout

\begin_layout Subsubsection*
Cluster EMR
\end_layout

\begin_layout Itemize
Master Node: Gerencia o cluster
\end_layout

\begin_deeper
\begin_layout Itemize
Instâncias EC2 única;
\end_layout

\end_deeper
\begin_layout Itemize
Core Node: hospeda dados HDFS e executa tarefas
\end_layout

\begin_deeper
\begin_layout Itemize
Pode ser escalado para cima e para baixo, mas com algum risco;
\end_layout

\end_deeper
\begin_layout Itemize
Task Node: Executa tarefas, não hospeda dados;
\end_layout

\begin_deeper
\begin_layout Itemize
Sem risco de perda de dados ao remover;
\end_layout

\begin_layout Itemize
Bom uso de instâncias pontuais;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Uso do EMR
\end_layout

\begin_layout Itemize
Clusters transitórios versus clusters de longa duração 
\begin_inset Note Note
status open

\begin_layout Plain Layout
O cluster transitório é encerrado quando ele concluir todas as etapas.
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Pode alternar task nodes usando 
\begin_inset Quotes eld
\end_inset

Spot Instances
\begin_inset Quotes erd
\end_inset

 para capacidade temporária;
\end_layout

\begin_layout Itemize
Pode usar instâncias reservadas em clusters de longa duração para economizar
 dinheiro;
\end_layout

\end_deeper
\begin_layout Itemize
Conecta diretamente ao mestre para executar ao jobs;
\end_layout

\begin_layout Itemize
Envie as etapas ordenadas por meio do console;
\end_layout

\begin_layout Subsubsection*
Integração EMR / AWS
\end_layout

\begin_layout Itemize
Amazon EC2 para as instâncias dos nós que fazem parte do cluster
\end_layout

\begin_layout Itemize
Amazon VPC para configurar a rede virtual na qual você inicia suas instâncias;
\end_layout

\begin_layout Itemize
Amazon S3 para armazenar dados de entrada e saída;
\end_layout

\begin_layout Itemize
Amazon CloudWatch para monitorar o desempenho do cluster e configurar alarmes;
\end_layout

\begin_layout Itemize
AWS IAM para configurar permissões;
\end_layout

\begin_layout Itemize
AWS CloudTrail para auditar as solicitações feitas ao serviço;
\end_layout

\begin_layout Itemize
AWS Data Pipeline para agendar e iniciar seus clusters;
\end_layout

\begin_layout Subsubsection*
EMR Storage
\end_layout

\begin_layout Itemize
HDFS
\end_layout

\begin_layout Itemize
EMRFS: Acessa S3 como se fosse HDFS
\end_layout

\begin_deeper
\begin_layout Itemize
Visualização consistente EMRFS 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
EMRFS você lê dados em S3 como se fosse em HDFS
\end_layout

\end_inset

 - Opcional para consistência S3;
\end_layout

\begin_layout Itemize
Usa DynamoDB para monitorar consistência;
\end_layout

\end_deeper
\begin_layout Itemize
Sistema de arquivos local
\end_layout

\begin_layout Itemize
EBS para HDFS
\end_layout

\begin_layout Itemize
O armazenamento é temporário, então quando você encerrar o cluster os dados
 serão perdidos;
\end_layout

\begin_layout Itemize
Então ele é útil como armazenamento em cache para resultados temporários;
\end_layout

\begin_layout Itemize
Cobrança do EMR por hora
\end_layout

\begin_deeper
\begin_layout Itemize
Mais cobrança EC2
\end_layout

\end_deeper
\begin_layout Itemize
Provê novos nós se um nó central falhar;
\end_layout

\begin_layout Itemize
Pode adicionar e remover nós de tarefas rapidamente;
\end_layout

\begin_layout Itemize
Pode redimensionar os nós centrais de um cluster em execução;
\end_layout

\begin_layout Subsubsection*
Então, o que é Hadoop?
\end_layout

\begin_layout Itemize
O Hadoop é um ecossistema de bigdata.
\end_layout

\begin_layout Itemize
Ele é composto pelos seguintes módulos: 
\end_layout

\begin_deeper
\begin_layout Itemize
Hadoop Core, que tem as bibliotecas e utilitários necessários para os outros
 módulos do Hadoop; 
\end_layout

\begin_layout Itemize
HDFS, sistema de arquivos distribuídos e escalável para Hadoop, ele distribui
 os dados que armazena entre todas as instâncias do cluster.
 Neste caso aqui, o HDFS é não persistente, portanto, se você encerra o
 cluster, os dados são apagados; 
\end_layout

\begin_layout Itemize
Hadoop YARN (Yet Another Resource Negotiator) é um componente para gerenciar
 de forma centralizada os recursos do cluster; 
\end_layout

\begin_layout Itemize
E por fim, o MapReduce, que é uma estrutura de software que permite que
 você crie aplicativos que são capazes de processar grandes volumes de dados,
 em paralelo, em clusters, ao mesmo tempo tolerante à falhas;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Apache Spark
\end_layout

\begin_layout Itemize
O Apache Spark é um sistema de processamento distribuído de código aberto,
 e ele é frequentemente utilizado para processamento de dados;
\end_layout

\begin_layout Itemize
Ele utiliza cache na memória e otimiza a execução das consultas;
\end_layout

\begin_layout Itemize
Com esses elementos, você tem um resultado das análises de maneira mais
 rápido, mesmo com um grande volume de dados sendo processados;
\end_layout

\begin_layout Itemize
Além disso, ele tem APIs, para você desenvolver as suas aplicações em Java,
 Scala, Python e R;
\end_layout

\begin_layout Itemize
Ele suporta a reutilização de código, para vários tipos de tarefas;
\end_layout

\begin_layout Subsubsection*
Como ele é utilizado?
\end_layout

\begin_layout Itemize
Ele pode ser utilizado para o processamento de streaming de dados;
\end_layout

\begin_deeper
\begin_layout Itemize
Por exemplo, ele pode ser utilizado para processar dados em tempo real coletados
 do Amazon Kinesis;
\end_layout

\begin_layout Itemize
Ou do Apache Kafka, ou do Apache Streaming;
\end_layout

\end_deeper
\begin_layout Itemize
A análise do Apache Spark é feita de maneira totalmente tolerante à falhas
 e os resultados são gravados no S3, ou num cluster do HDFS;
\end_layout

\begin_layout Itemize
Com relação ao aprendizado de máquina:
\end_layout

\begin_deeper
\begin_layout Itemize
O Spark inclui o ML Library, ou Machine Learning Library, uma biblioteca
 para fazer aprendizado de máquina em dados de grandes volumes;
\end_layout

\begin_layout Itemize
Ele possui ainda o Spark SQL, que é uma ferramenta de SQL interativo que
 é usado para consultas interativas de baixa latência utilizando linguagem
 SQL ou SQL Hive;
\end_layout

\begin_layout Itemize
Ele não é usado para OLTP, e também não é utilizado para processar dados
 em lote (batch).
 Ele é uma ferramenta para processar dados à medida que os dados são carregados;
\end_layout

\end_deeper
\begin_layout Itemize
Como funciona o Spark?
\end_layout

\begin_deeper
\begin_layout Itemize
Os aplicativos Spark são executados como conjuntos independentes de processos
 em um cluster;
\end_layout

\begin_layout Itemize
Eles são coordenados pelo objeto Spark Context, no programa principal;
\end_layout

\begin_layout Itemize
Logo, a primeira coisa a ser feita quando vamos processar dados utilizando
 o Spark é criar o contexto do Spark;
\end_layout

\begin_layout Itemize
O Spark Context se conecta em diferentes gerenciadores de cluster que alocam
 recursos entre os aplicativos que estão usando os contextos;
\end_layout

\begin_layout Itemize
E quando eles se conectam, o spark adquire executores nos nós que fazem
 parte do cluster;
\end_layout

\begin_layout Itemize
Esses executores são proessos que executam cálculos e armazenam dados para
 os aplicativos que estão executando este código;
\end_layout

\begin_layout Itemize
Na etapa final, o Spark Context envia a tarefa para os executores então
 executarem;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Spark MLLib
\end_layout

\begin_layout Itemize
Classificação: logistic regression, naive bayes;
\end_layout

\begin_layout Itemize
Regressão;
\end_layout

\begin_layout Itemize
Árvore de Decisão;
\end_layout

\begin_layout Itemize
Recommendation engine (ALS);
\end_layout

\begin_layout Itemize
Clustering (K-Means);
\end_layout

\begin_layout Itemize
LDA (topic modeling);
\end_layout

\begin_layout Itemize
Utilitários de fluxo de trabalho de ML (pipelines, transformação de atributos,
 persistência)
\end_layout

\begin_layout Itemize
SVD, PCA, estatísticas;
\end_layout

\begin_layout Subsubsection*
Zeppelin + Spark
\end_layout

\begin_layout Itemize
Pode executar o código do spark interativamente (como no shell do spark);
\end_layout

\begin_layout Itemize
Isso acelera seu ciclo de desenvolvimento;
\end_layout

\begin_layout Itemize
Permite fácil experimentação e exploração de seu big data;
\end_layout

\begin_layout Itemize
Pode executar consultas SQL diretamente no SparkSQL;
\end_layout

\begin_layout Itemize
Os resultados da consulta podem ser visualizados em tabelas e gráficos;
\end_layout

\begin_layout Itemize
Faz com que o Spark pareça mais uma ferramenta de ciência de dados;
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsubsection*
EMR Notebook
\end_layout

\begin_layout Itemize
Conceito semelhante ao Zeppelin, com mais integração AWS;
\end_layout

\begin_layout Itemize
Notebooks com backup para S3;
\end_layout

\begin_layout Itemize
Provisione clusters a partir do notebook;
\end_layout

\begin_layout Itemize
Hospedado em um VPC;
\end_layout

\begin_layout Itemize
Acessado apenas por meio do console AWS;
\end_layout

\begin_layout Subsubsection*
Segurança no EMR
\end_layout

\begin_layout Itemize
IAM policies: Concedem ou negam permissão e determinam quais ações um usuário
 pode tomar no EMR, além de outros recursos do AWS.
 Também podemos combinar políticas IAM com tag para controlar o acesso aos
 clusters;
\end_layout

\begin_layout Itemize
Kerberos: É um protocolo de autenticação de rede, que garante que as senhas
 e outras credenciais não sejam enviadas através da rede sem ser criptografadas;
\end_layout

\begin_layout Itemize
SSH: Fornece uma forma segura para os usuários se conectarem por linha de
 comando em instâncias de um cluster.
 Ele também fornece tunelamento para que as interfaces web dos aplicativos
 hospedados no Master Node sejam acessadas;
\end_layout

\begin_layout Itemize
IAM roles: Controla como o EMR pode acessar outros serviços do AWS.
 Cada cluster deve ter uma role de serviço e uma role por perfil de instância
 do EC2, e as políticas de IAM anexadas a essa role fornece permissões para
 o cluster interoperar com outros serviços do AWS e isso vai ser feito com
 o nome do próprio usuário;
\end_layout

\begin_layout Subsubsection*
EMR: Escolhendo os tipos de Instância
\end_layout

\begin_layout Itemize
Master Node:
\end_layout

\begin_deeper
\begin_layout Itemize
m4.large se <50 nós, m4.xlarge se >50 nós;
\end_layout

\end_deeper
\begin_layout Itemize
Core & task nodes:
\end_layout

\begin_deeper
\begin_layout Itemize
m4.large geralmente é suficiente
\end_layout

\begin_layout Itemize
Se o cluster esperar muito por dependências externas (por exemplo um web
 crawler), t2.medium;
\end_layout

\begin_layout Itemize
Desempenho maior: m4.xlarge;
\end_layout

\begin_layout Itemize
Aplicativos de computação intensiva: instâncias com mais CPU;
\end_layout

\begin_layout Itemize
Banco de dados, aplicativos de cache em memória: instâncias com mais memória;
\end_layout

\begin_layout Itemize
Rede/uso intensivo de CPU (NLP, ML) - instâncias de cluster de computador;
\end_layout

\end_deeper
\begin_layout Itemize
Spot Instances
\end_layout

\begin_deeper
\begin_layout Itemize
Bons para nós de tarefa;
\end_layout

\begin_layout Itemize
Use apenas no core & master se você estiver testando ou muito sensível ao
 custo, você está arriscando a perda parcial de dados;
\end_layout

\end_deeper
\begin_layout Subsection
Engenharia de Atributos
\end_layout

\begin_layout Subsubsection*
O que é a Engenharia de Atributos?
\end_layout

\begin_layout Itemize
Aplicar seu conhecimento dos dados - e do modelo que você está usando -
 para criar características melhores para treinar o seu modelo.
\end_layout

\begin_deeper
\begin_layout Itemize
Quais características devo usar?
\end_layout

\begin_layout Itemize
Preciso transformar estas características de alguma forma?
\end_layout

\begin_layout Itemize
Como faço para lidar com dados faltantes?
\end_layout

\begin_layout Itemize
Devo criar novas características a partir das existentes?
\end_layout

\end_deeper
\begin_layout Itemize
Você não pode simplesmente inserir dados brutos e esperar bons resultados;
\end_layout

\begin_layout Itemize
Esta é a arte do aprendizado de máquina, onde a experiência é aplicada;
\end_layout

\begin_layout Subsubsection*
A Maldição da Dimensionalidade
\end_layout

\begin_layout Itemize
Muitas características podem ser um problema - leva a dados esparsos;
\end_layout

\begin_layout Itemize
Cada característica é uma nova dimensão
\end_layout

\begin_layout Itemize
Grande parte da engenharia de atributos é selecionar os atributos mais relevante
s para o problema em questão
\end_layout

\begin_deeper
\begin_layout Itemize
Muitas vezezé aqui que o conhecimento do domínio entra em jogo
\end_layout

\end_deeper
\begin_layout Itemize
Técnicas de redução de dimensionalidade não supervisionadas também podem
 ser empregadas para transformar muitas características em menos características
;
\end_layout

\begin_layout Itemize
PCA;
\end_layout

\begin_layout Itemize
K-Means;
\end_layout

\begin_layout Subsubsection*
Imputando dados ausentes: substituição pela média
\end_layout

\begin_layout Itemize
Substituir os valores ausentes pelo valor médio das colunas (colunas, não
 linhas! Uma coluna representa um único atributo.
 Só faz sentido tirar a média de outras amostras do mesmo atributo);
\end_layout

\begin_layout Itemize
Rápido e fácil, não afeta a média ou o tamanho da amostra do conjunto de
 dados geral;
\end_layout

\begin_layout Itemize
A mediana pode ser uma escolha melhor do que a média quando há outliers;
\end_layout

\begin_layout Itemize
De uma maneira geral pode não ser uma boa ideia:
\end_layout

\begin_deeper
\begin_layout Itemize
Funciona apenas a nível da coluna, perde correlações entre as características;
\end_layout

\begin_layout Itemize
Não pode ser usado em características categóricas (inputar com valor mais
 frequente pode funcionar neste caso, no entando...);
\end_layout

\begin_layout Itemize
Não muito preciso;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Imputando dados ausentes: Machine Learning
\end_layout

\begin_layout Itemize
kNN: Encontre K linhas 
\begin_inset Quotes eld
\end_inset

mais próximas
\begin_inset Quotes erd
\end_inset

 (mais semelhantes) e calcula a média de seus valores;
\end_layout

\begin_deeper
\begin_layout Itemize
Requer dados numéricos, não categóricos;
\end_layout

\begin_layout Itemize
Existem maneiras de lidar com dados categóricos (distância de Hamming),
 mas os dados categóricos provavelmente são mais bem servidos por...
\end_layout

\end_deeper
\begin_layout Itemize
Deep Learning
\end_layout

\begin_deeper
\begin_layout Itemize
Crie um modelo de aprendizado de máquina para imputar dados para seu modelo
 de aprendizado de máquina;
\end_layout

\begin_layout Itemize
Funciona bem para dados categóricos.
 Funciona bem, mas é complexo;
\end_layout

\end_deeper
\begin_layout Itemize
Regressão
\end_layout

\begin_deeper
\begin_layout Itemize
Encontre relações lineares ou não-lineares entre a característica ausente
 e outras características;
\end_layout

\begin_layout Itemize
Técnica mais avançada: MICE (Multiple Imputation de Chained Equations)
\end_layout

\end_deeper
\begin_layout Subsubsection*
Imputando dados ausentes: basta obter mais dados
\end_layout

\begin_layout Itemize
O que é melhor do que imputar dados? Obtendo mais dados reais!
\end_layout

\begin_layout Itemize
Às vezes, você só precisa se esforçar mais ou coletar mais dados;
\end_layout

\begin_layout Subsubsection*
O que são dados não balanceados?
\end_layout

\begin_layout Itemize
Grande discrepância entre casos 
\begin_inset Quotes eld
\end_inset

positivos
\begin_inset Quotes erd
\end_inset

 e 
\begin_inset Quotes eld
\end_inset

negativos
\begin_inset Quotes erd
\end_inset

;
\end_layout

\begin_deeper
\begin_layout Itemize
Ou seja, detecção de fraude.
 A fraude é rara e a maioria das linhas não será fraude;
\end_layout

\begin_layout Itemize
Não deixe que a terminologia o confunda, 
\begin_inset Quotes eld
\end_inset

Positivo
\begin_inset Quotes erd
\end_inset

 não significa 
\begin_inset Quotes eld
\end_inset

bom
\begin_inset Quotes erd
\end_inset

;
\end_layout

\begin_deeper
\begin_layout Itemize
Isso significa que o que você está testando foi o que aconteceu;
\end_layout

\begin_layout Itemize
Se seu modelo de aprendizado de máquina é feito para detectar fraude, então
 fraude é o caso positivo;
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Um problema com redes neurais: não aprende corretamente;
\end_layout

\begin_layout Subsubsection*
Oversampling
\end_layout

\begin_layout Itemize
Amostras duplicadas da classe minoritária;
\end_layout

\begin_layout Itemize
Pode ser feito aleatoriamente;
\end_layout

\begin_layout Subsubsection*
Undersampling
\end_layout

\begin_layout Itemize
Em vez de criar mais amostras positivas, remova as negativas;
\end_layout

\begin_layout Itemize
Jogar dados fora geralmente não é a resposta certa;
\end_layout

\begin_deeper
\begin_layout Itemize
A menos que você esteja especificamente tentando evitar problemas de escala
 de 
\begin_inset Quotes eld
\end_inset

big data
\begin_inset Quotes erd
\end_inset

;
\end_layout

\end_deeper
\begin_layout Subsubsection*
SMOTE
\end_layout

\begin_layout Itemize
É o acrônimo para Synthetic Minority Oversampling Technique;
\end_layout

\begin_layout Itemize
Gera artificialmente novas amostras da classe minoritária usando os vizinhos
 mais próximos;
\end_layout

\begin_deeper
\begin_layout Itemize
Execute K-vizinhos mais próximos de cada amostra da classe minoritária;
\end_layout

\begin_layout Itemize
Crie uma nova amostra a partir do resultado kNN (média dos vizinhos);
\end_layout

\end_deeper
\begin_layout Itemize
Ambos geram novas amostras e classes de maioria de subamostras;
\end_layout

\begin_layout Itemize
Geralmente melhor do que apenas oversampling;
\end_layout

\begin_layout Subsubsection*
Ajustando os limites
\end_layout

\begin_layout Itemize
Ao fazer previsões sobre uma classificação (fraude/não-fraude), você tem
 algum tipo de limite de probabilidade em que sinalizará como o caso positivo
 (fraude);
\end_layout

\begin_layout Itemize
Se você tiver muitos falsos positivos, uma maneira de corrigir isso é simplesmen
te aumentar esse limite;
\end_layout

\begin_deeper
\begin_layout Itemize
Garante a redução de falsos positivos;
\end_layout

\begin_layout Itemize
Mas pode resultar em mais falsos negativos;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Outliers
\end_layout

\begin_layout Itemize
São valores que fogem muito do padrão dos demais dados;
\end_layout

\begin_layout Itemize
Quando falamos de outlier, sempre temos que falar de variância e desvio
 padrão, pois elas são métricas importantes para entender quando um dado
 se apresenta como um outlier;
\end_layout

\begin_layout Subsubsection*
Variância
\end_layout

\begin_layout Itemize
A variância mede o quão 
\begin_inset Quotes eld
\end_inset

espalhados
\begin_inset Quotes erd
\end_inset

 os dados estão;
\end_layout

\begin_layout Itemize
Variância (
\begin_inset Formula $\sigma^{2}$
\end_inset

) é simplesmente a me´dia das diferenças ao quadrado da média;
\end_layout

\begin_layout Itemize
Exemplo: Qual é a variação do conjunto de dados (1, 4, 5, 4, 8)?
\end_layout

\begin_deeper
\begin_layout Itemize
Primeiro encontre a média
\begin_inset Formula 
\[
\overline{x}=\frac{\left(1+4+5+4+8\right)}{5}=4.4
\]

\end_inset


\end_layout

\begin_layout Itemize
Agora encontre as diferenças da média: 
\begin_inset Formula 
\[
x_{i}-\overline{x}=\left(-3.4,-0.4,0.6,-0.4,3.6\right)
\]

\end_inset


\end_layout

\begin_layout Itemize
Encontre as diferenças ao quadrado:
\begin_inset Formula 
\[
\left(x_{i}-\overline{x}\right)^{2}=\left(11.56,0.16,0.36,0.16,12.96\right)
\]

\end_inset


\end_layout

\begin_layout Itemize
Encontre a média das diferenças ao quadrado:
\begin_inset Formula 
\[
\sigma^{2}=\frac{11.56+0.16+0.36+0.16+12.96}{5}=5.04
\]

\end_inset


\end_layout

\end_deeper
\begin_layout Subsubsection*
O desvio padrão 
\begin_inset Formula $\sigma$
\end_inset

 é apenas a raiz quadrada da variância
\end_layout

\begin_layout Itemize
No nosso exemplo, considerando que 
\begin_inset Formula $\sigma^{2}=5.04$
\end_inset

, logo, o desvio padrão é 
\begin_inset Formula $\sigma=\sqrt{5.04}=2.24$
\end_inset

;
\end_layout

\begin_layout Itemize
Portanto, o desvio padrão de 
\begin_inset Formula $x=\left(1,4,5,4,8\right)$
\end_inset

 é 
\begin_inset Formula $2.24$
\end_inset

;
\end_layout

\begin_layout Itemize
Geralmente é usado como uma forma de identificar valores discrepantes;
\end_layout

\begin_layout Itemize
Os pontos de dados que se encontram a mais de um desvio padrão da média
 podem ser c onsiderados incomuns;
\end_layout

\begin_layout Itemize
Você pode falar sobre o quão extremo é um ponto de dados falando sobre 
\begin_inset Quotes eld
\end_inset

quantos sigmas
\begin_inset Quotes erd
\end_inset

 de distância da média ele está;
\end_layout

\begin_layout Subsubsection*
Lidando com Outliers
\end_layout

\begin_layout Itemize
Às vezes é apropriado remover outliers de seus dados de treinamento;
\end_layout

\begin_layout Itemize
Faça isso com responsabilidade.
 Entenda porque você está fazendo isso.
\end_layout

\begin_layout Itemize
Por exemplo: na filtragem colaborativa, um único usuário que avalia milhares
 de filmes pode ter um grande efeito nas avaliações de todos os outros.
 Isso pode não ser bom;
\end_layout

\begin_layout Itemize
Outro exemplo: em dados de log da web, outliers podem representar bots ou
 outros agentes que devem ser descartados;
\end_layout

\begin_layout Itemize
Mas se alguém realmente quer a renda média de cidadãos americanos, por exemplo,
 não tire os bilionários só porque você quer;
\end_layout

\begin_layout Itemize
Desvio padrão fornece uma maneira fundamentada para classificar valores
 discrepantes;
\end_layout

\begin_layout Itemize
Encontre pontos de dados mais do que alguns múltiplos de um desvio padrão
 em seus dados de treinamento;
\end_layout

\begin_layout Itemize
Que múltiplo? Você apenas tem que usar o bom senso;
\end_layout

\begin_layout Itemize
Lembre-se do algoritmo Random Cut Forest da AWS é feito para detecção de
 outliers;
\end_layout

\begin_layout Itemize
Encontrado no QuickSight, Kinesis Analytics, SageMaker e mais;
\end_layout

\begin_layout Subsubsection*
Binning
\end_layout

\begin_layout Itemize
Agrupe as observações com base em intervalos de valores;
\end_layout

\begin_layout Itemize
Exemplo: idades estimadas das pessoas;
\end_layout

\begin_deeper
\begin_layout Itemize
Coloque todos os 20 e poucos anos em uma categoria, 30 e poucos em outra,
 etc.
\end_layout

\end_deeper
\begin_layout Itemize
O binning de quantis categoriza os dados por seu lugar na distribuição de
 dados;
\end_layout

\begin_deeper
\begin_layout Itemize
Garante tamanhos uniformes dos 
\begin_inset Quotes eld
\end_inset

bins
\begin_inset Quotes erd
\end_inset

;
\end_layout

\end_deeper
\begin_layout Itemize
Transforma dados numéricos em dados ordinais;
\end_layout

\begin_layout Itemize
Especialmente útil quando há incerteza nas medições;
\end_layout

\begin_layout Subsubsection*
Transformando
\end_layout

\begin_layout Itemize
Aplicar alguma função a um atributo para torná-lo mais adequado para o treinamen
to;
\end_layout

\begin_layout Itemize
Dados de atributos com tendência exponencial podem se beneficiar de uma
 transformação logarítmica;
\end_layout

\begin_layout Itemize
Exemplo: recomendações do YouTube;
\end_layout

\begin_deeper
\begin_layout Itemize
Um atributo numérico 
\begin_inset Formula $x$
\end_inset

 também é representada por 
\begin_inset Formula $x^{2}$
\end_inset

 e 
\begin_inset Formula $\sqrt{x}$
\end_inset

;
\end_layout

\begin_layout Itemize
Isso permite o aprendizado de funções super e sublineares;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Codificação - Encoding
\end_layout

\begin_layout Itemize
Transformar dados em alguma nova representação exigida pelo modelo;
\end_layout

\begin_layout Itemize
Um dos mais famosos é o One-Hot Encoding;
\end_layout

\begin_deeper
\begin_layout Itemize
Crie 
\begin_inset Quotes eld
\end_inset

intervalos
\begin_inset Quotes erd
\end_inset

 para cada categoria;
\end_layout

\begin_layout Itemize
O intervalo para sua categoria tem 1;
\end_layout

\begin_layout Itemize
Todos os outros têm 0;
\end_layout

\begin_layout Itemize
Muito comum no aprendizado profundo, onde as categorias são representadas
 por 
\begin_inset Quotes eld
\end_inset

neurônios
\begin_inset Quotes erd
\end_inset

 de saída individual;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Escala / Normalização
\end_layout

\begin_layout Itemize
Alguns modelos preferem que os dados de atributos sejam normalmente distribuídos
 em torno de 0 (a maioria das redes neurais);
\end_layout

\begin_layout Itemize
A maioria dos modelos exige que os atributos sejam, pelo menos, dimensionados
 para valores comparáveis;
\end_layout

\begin_deeper
\begin_layout Itemize
Caso contrário, atributos com magnitudes maiores terão mais peso do que
 deveriam;
\end_layout

\begin_layout Itemize
Exemplo: modelagem de idade e renda como atributos - as rendas serão valores
 muito maiores do que as idades;
\end_layout

\end_deeper
\begin_layout Itemize
Scikit-learn tem um módulo de pré-processamento (MinMaxScaler, etc);
\end_layout

\begin_layout Itemize
Lembre-se de escalar seus resultados de volta;
\end_layout

\begin_layout Subsubsection*
Shuffling
\end_layout

\begin_layout Itemize
Muitos algoritmos se beneficiam de 
\begin_inset Quotes eld
\end_inset

embaralhar
\begin_inset Quotes erd
\end_inset

 seus dados de treinamento;
\end_layout

\begin_layout Itemize
Caso contrário, eles podem aprender com os sinais residuais dos dados de
 treinamento resultante da ordem em que foram coletados;
\end_layout

\begin_layout Subsection
SageMaker Ground Truth
\end_layout

\begin_layout Subsubsection*
O que é o Ground Truth?
\end_layout

\begin_layout Itemize
Às vezes, você não tem dados de treinamento, e eles precisam ser gerados
 primeiro por humanos;
\end_layout

\begin_layout Itemize
Exemplo: treinar um modelo de classificação de imagens.
 Alguém precisa marcar um monte de imagens com o que são imagens antes de
 treinar uma rede neural;
\end_layout

\begin_layout Itemize
Ground Truth gerencia humanos que rotularação seus dados para fins de treinament
o;
\end_layout

\begin_layout Subsubsection*
Mas é mais do que isso
\end_layout

\begin_layout Itemize
Ground Truth cria seu próprio modelo à medida que as imagens são rotuladas
 por pessoas;
\end_layout

\begin_layout Itemize
Conforme este modelo aprende, apenas as imagens sobre as quais o modelo
 não tem certeza são enviadas para rotuladores humanos;
\end_layout

\begin_layout Itemize
Isso pode reduzir o custo dos trabalhos de etiquetagem em 70%;
\end_layout

\begin_layout Subsubsection*
Quem são esses rotuladores humanos?
\end_layout

\begin_layout Itemize
Mechanicala Turk;
\end_layout

\begin_layout Itemize
Sua própria equipe interna;
\end_layout

\begin_layout Itemize
Empresas profissionais de rotulagem;
\end_layout

\begin_layout Subsubsection*
Outras maneiras de gerar rótulos de treinamento;
\end_layout

\begin_layout Itemize
Rekognition;
\end_layout

\begin_deeper
\begin_layout Itemize
Serviço AWS para reconhecimento de imagem;
\end_layout

\begin_layout Itemize
Classificar imagens automaticamente;
\end_layout

\end_deeper
\begin_layout Itemize
Compreender
\end_layout

\begin_deeper
\begin_layout Itemize
Serviço AWS para análise de texto e modelagem de tópicos;
\end_layout

\begin_layout Itemize
Classifique automaticamente o texto por tópicos, sentimento;
\end_layout

\end_deeper
\begin_layout Itemize
Qualquer modelo pré-treinado ou técnica não-supervisionada que pode ser
 útil;
\end_layout

\begin_layout Section
Modelagem
\end_layout

\begin_layout Subsection
Introdução ao Deep Learning
\end_layout

\begin_layout Subsubsection*
A inspiração biológica
\end_layout

\begin_layout Itemize
Neurônios em seu córtex cerebral são conectados por meio de axônios;
\end_layout

\begin_layout Itemize
Um neurônio 
\begin_inset Quotes eld
\end_inset

dispara
\begin_inset Quotes erd
\end_inset

 para os neurônios aos quais está conectado, quando uma quantidade suficiente
 de seus sinais de entrada é ativada;
\end_layout

\begin_layout Itemize
Muito simples no nível do neurônio individual - mas camadas de neurônios
 conectadas dessa forma podem gerar comportamento de aprendizagem;
\end_layout

\begin_layout Itemize
Bilhões de neurônios, cada um com milhares de conexões, geram uma mente;
\end_layout

\begin_layout Subsection*
Colunas corticais
\end_layout

\begin_layout Itemize
Os neurônios em seu córtex parecem ser or ganizados em muitas pilhas, ou
 
\begin_inset Quotes eld
\end_inset

colunas
\begin_inset Quotes erd
\end_inset

 que processam informações em paralelo;
\end_layout

\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

Mini-colunas
\begin_inset Quotes erd
\end_inset

 de cerca de 100 neurônios são organizadas em 
\begin_inset Quotes eld
\end_inset

hiper-colunas
\begin_inset Quotes erd
\end_inset

 maiores.
 Existem 100 milhões de mini-colunas em seu córtex;
\end_layout

\begin_layout Itemize
Isso é coincidentemente semelhante a como a GPU funciona;
\end_layout

\begin_layout Subsubsection*
Deep Learning Frameworks
\end_layout

\begin_layout Itemize
Tensorflow / Keras;
\end_layout

\begin_layout Itemize
MXNet; 
\begin_inset listings
inline false
status open

\begin_layout Plain Layout

model = Sequential()
\end_layout

\begin_layout Plain Layout

\end_layout

\begin_layout Plain Layout

model.add(Dense(64, activation='relu', input_dim=20))
\end_layout

\begin_layout Plain Layout

model.add(Dropout(0.5))
\end_layout

\begin_layout Plain Layout

model.add(Dense(64, activation='relu))
\end_layout

\begin_layout Plain Layout

model.add(Dropout(0.5))
\end_layout

\begin_layout Plain Layout

model.add(Dense(10, activation='softmax'))
\end_layout

\begin_layout Plain Layout

sgd = SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)
\end_layout

\begin_layout Plain Layout

model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'
])
\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
Tipos de redes neurais
\end_layout

\begin_layout Itemize
Feedforward Neural Networks;
\end_layout

\begin_layout Itemize
Convolutional Neural Networks (CNN);
\end_layout

\begin_deeper
\begin_layout Itemize
Classificação da imagem (há uma placa de pare nesta imagem?);
\end_layout

\end_deeper
\begin_layout Itemize
Recurrent Neural Networks (RNNs);
\end_layout

\begin_deeper
\begin_layout Itemize
Lida com sequências no tempo (prever preços de ações, entender palavras
 em uma frase, tradução, etc);
\end_layout

\begin_layout Itemize
LSTM, GRU;
\end_layout

\end_deeper
\begin_layout Subsection
Funções de ativação
\end_layout

\begin_layout Itemize
Define a saída de um nó/neurônio de acordo com seus 
\begin_inset Quotes eld
\end_inset

sinais
\begin_inset Quotes erd
\end_inset

 de entrada;
\end_layout

\begin_layout Itemize
A definição da função de ativação é importante, pois diferentes funções
 de ativação podem render performances bastantes diferentes da rede neural;
\end_layout

\begin_layout Itemize
Exemplos de função de ativação impróprias:
\end_layout

\begin_deeper
\begin_layout Itemize
Função de ativação linear;
\end_layout

\begin_deeper
\begin_layout Itemize
Uma rede neural deve ter uma função de ativação não-linear para que possa
 tratar de problemas complexos (não-lineares), se não a função de ativação
 não consegue ser aprimorada.
 Logo, uma função de ativação linear não interfere no resultado da rede
 neural no final;
\end_layout

\begin_layout Itemize
Não pode executar backpropagation;
\end_layout

\end_deeper
\begin_layout Itemize
Binary step function;
\end_layout

\begin_deeper
\begin_layout Itemize
A solução será de ligado ou desligado;
\end_layout

\begin_layout Itemize
Sendo assim, não é possível lidar com múltiplas classes, pois sua natureza
 é completamente binária;
\end_layout

\begin_layout Itemize
Inclinações verticais, elas não funcionam bem quando você precisa realizar
 o backpropagation;
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Em vez disso, precisamos de funções de ativação não-lineares;
\end_layout

\begin_deeper
\begin_layout Itemize
Pois, elas podem criar mapeamentos complexos entre entradas e saídas;
\end_layout

\begin_layout Itemize
Permitem backpropagation, ou seja, a derivada delas possui valor útil;
\end_layout

\begin_layout Itemize
Permite várias camadas, pois funções lineares degeneram em uma única camada;
\end_layout

\end_deeper
\begin_layout Itemize
Algumas funções de ativação não-lineares:
\end_layout

\begin_deeper
\begin_layout Itemize
Sigmoid/tanh;
\end_layout

\begin_deeper
\begin_layout Itemize
Gera 0-1 (sigmoide/logística)
\end_layout

\begin_layout Itemize
-1 a 1 (tanh / tangente hiperbólica)
\end_layout

\begin_layout Itemize
Mas mudam lentamente para valores altos ou baixos;
\end_layout

\begin_deeper
\begin_layout Itemize
Problema do 
\begin_inset Quotes eld
\end_inset

vanishing gradient
\begin_inset Quotes erd
\end_inset

;
\end_layout

\end_deeper
\begin_layout Itemize
Computacionalmente caro;
\end_layout

\begin_layout Itemize
tanh geralmente é preferível em relação à sigmóide;
\end_layout

\end_deeper
\begin_layout Itemize
Rectified Linear Unit (ReLU);
\end_layout

\begin_deeper
\begin_layout Itemize
Muito popular;
\end_layout

\begin_layout Itemize
Fácil e rápida de calcular
\end_layout

\begin_layout Itemize
Mas quando as entradas são zero ou negativas, temos uma função linear e
 consequentemente os mesmo problemas vistos;
\end_layout

\begin_deeper
\begin_layout Itemize
O 
\begin_inset Quotes eld
\end_inset

Dying ReLU problem
\begin_inset Quotes erd
\end_inset

;
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Leaky ReLU;
\end_layout

\begin_deeper
\begin_layout Itemize
Resolve o problema do 
\begin_inset Quotes eld
\end_inset

Dying ReLU
\begin_inset Quotes erd
\end_inset

 introduzindo uma inclinação negativa abaixo de 0 (geralmente não tão íngreme);
\end_layout

\end_deeper
\begin_layout Itemize
Parametric ReLU (PReLU)
\end_layout

\begin_deeper
\begin_layout Itemize
ReLU, mas a inclinação na parte negativa é 
\begin_inset Quotes eld
\end_inset

aprendida
\begin_inset Quotes erd
\end_inset

 por backpropagation;
\end_layout

\begin_layout Itemize
Pode ser bastante complicada;
\end_layout

\end_deeper
\begin_layout Itemize
Outras variações de ReLU;
\end_layout

\begin_deeper
\begin_layout Itemize
Exponential Linear Unit (ELU);
\end_layout

\begin_layout Itemize
Swish;
\end_layout

\begin_deeper
\begin_layout Itemize
Do Google, tem um desempenho muito bom;
\end_layout

\begin_layout Itemize
Mas é do Google, não da Amazon;
\end_layout

\begin_layout Itemize
Traz benefício com redes muito profundas (mais de 40 camadas);
\end_layout

\end_deeper
\begin_layout Itemize
Maxout;
\end_layout

\begin_deeper
\begin_layout Itemize
Produz o máximo das entradas;
\end_layout

\begin_layout Itemize
Tecnicamente, ReLU é um caso especial da maxout;
\end_layout

\begin_layout Itemize
Mas duplica os parâmetros que precisam ser treinados, muitas vezes ela não
 é viável;
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Softmax;
\end_layout

\begin_deeper
\begin_layout Itemize
Usado na camada de saída (final) de um problema de classificação múltipla;
\end_layout

\begin_layout Itemize
Converte basicamente os resultados em probabilidades para cada classificação;
\end_layout

\begin_layout Itemize
Não é possível produzir mais de um rótulo para algo (sigmóide pode);
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Escolhendo uma função de ativação;
\end_layout

\begin_deeper
\begin_layout Itemize
Para classificação múltipla, use softmax na camada de saída;
\end_layout

\begin_layout Itemize
RNN's se 
\begin_inset Quotes eld
\end_inset

dão bem
\begin_inset Quotes erd
\end_inset

 com tanh;
\end_layout

\begin_layout Itemize
Para todas as outras:
\end_layout

\begin_deeper
\begin_layout Itemize
Comece com ReLU;
\end_layout

\begin_layout Itemize
Para tentar melhorar, experimente Leaky ReLU;
\end_layout

\begin_layout Itemize
Último recurso: PReLU, Maxout;
\end_layout

\begin_layout Itemize
Swish para redes realmente profundas;
\end_layout

\end_deeper
\end_deeper
\begin_layout Subsection
Redes Neurais Convolucionais
\end_layout

\begin_layout Subsubsection*
CNN's: Para que servem?
\end_layout

\begin_layout Itemize
Quando você tem dados que não se alinham perfeitamente em colunas;
\end_layout

\begin_deeper
\begin_layout Itemize
Imagens nas quais você deseja encontrar características;
\end_layout

\begin_layout Itemize
Tradução;
\end_layout

\begin_layout Itemize
Classificação de sentenças;
\end_layout

\end_deeper
\begin_layout Itemize
Podem encontrar características que não estão em um local específico;
\end_layout

\begin_deeper
\begin_layout Itemize
Como uma placa de pare em uma foto;
\end_layout

\begin_layout Itemize
Ou palavras dentro de uma frase;
\end_layout

\end_deeper
\begin_layout Itemize
São 
\begin_inset Quotes eld
\end_inset

invariáveis na localização de características
\begin_inset Quotes erd
\end_inset

;
\end_layout

\begin_layout Itemize
Inspirado na biologia do córtex visual;
\end_layout

\begin_deeper
\begin_layout Itemize
Os campos receptivos locais são grupos de neurônios que respondem apenas
 a uma parte do que seus olhos veem (sub-amostragem);
\end_layout

\begin_layout Itemize
Eles se sobrepõem para cobrir todo o campo visual (convoluções);
\end_layout

\begin_layout Itemize
Eles alimentam camadas superiores que identificam imagens cada vez mais
 complexas;
\end_layout

\begin_deeper
\begin_layout Itemize
Alguns campos receptivos identificam linhas horizontais, linhas em ângulos
 diferentes, etc.
 (que são os filtros);
\end_layout

\begin_layout Itemize
Eles alimentariam uma camada que identifica as formas;
\end_layout

\begin_layout Itemize
Que pode alimentar uma camada que identifica objetos;
\end_layout

\end_deeper
\begin_layout Itemize
Para imagens coloridas, camadas extras para vermelho, verde e azul;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Como sabemos que é um sinal de pare?
\end_layout

\begin_layout Itemize
Campos receptivos locais individuais examinam a imagem procurando bordas
 e colocam as bordas do sinal de parada em uma camada;
\end_layout

\begin_layout Itemize
Essas bordas, por sua vez, são captada por uma convolução de nível superior
 que identifica a forma do sinal de Pare (e as letras também);
\end_layout

\begin_layout Itemize
Esta forma, então, é comparada ao padrão de como é um sinal de parada, também
 usando o sinal vermelho forte proveniente de suas camadas vermelhas;
\end_layout

\begin_layout Itemize
Essas informações continuam sendo processadas em níveis superiores até que
 seu pé pise no freio!
\end_layout

\begin_layout Itemize
Uma CNN funciona da mesma forma;
\end_layout

\begin_layout Subsubsection*
CNN's com Keras/Tensorflow
\end_layout

\begin_layout Itemize
Os dados de origem devem ter dimensões adequadas;
\end_layout

\begin_deeper
\begin_layout Itemize
Ou seja, largura x comprimento x canais de cores
\end_layout

\end_deeper
\begin_layout Itemize
O tipo de camada Conv2D faz a convolução real em uma imagem 2D;
\end_layout

\begin_deeper
\begin_layout Itemize
Conv1D e Conv3D também estão disponíveis - não precisam ser dados de imagens
\end_layout

\end_deeper
\begin_layout Itemize
Camadas MaxPooling2D podem ser usadas para reduzir uma camada 2D pegando
 o valor máximo em um determinado bloco;
\end_layout

\begin_layout Itemize
As camadas 
\begin_inset Quotes eld
\end_inset

Flatten
\begin_inset Quotes erd
\end_inset

 irão converter uma camada 2D em uma camada 1D para passar em uma camada
 de vetor oculta de neurônios;
\end_layout

\begin_layout Itemize
Uso típico:
\end_layout

\begin_deeper
\begin_layout Itemize
Conv2D -> MaxPooling2D -> Dropout -> Flatten -> Dense -> Dropout -> Softmax;
\end_layout

\end_deeper
\begin_layout Subsubsection*
CNNs são difíceis
\end_layout

\begin_layout Itemize
Consome muitos recursos (CPU, GPU e RAM);
\end_layout

\begin_layout Itemize
Muitos hiperparâmetros;
\end_layout

\begin_deeper
\begin_layout Itemize
Kernel sizes, muitas camadas com diferentes números de unidades, quantidade
 de pooling...
 além das coisas usuais como número de camadas, escolha do otimizador;
\end_layout

\end_deeper
\begin_layout Itemize
Obter os dados de treinamento costuma ser a parte mais difícil, bem como
 armazená-lo e acessá-lo;
\end_layout

\begin_layout Subsubsection*
Arquiteturas CNN especializadas
\end_layout

\begin_layout Itemize
Define o arranjo específico de camadas, preenchimento e hiperparâmetros;
\end_layout

\begin_layout Itemize
LeNet-5;
\end_layout

\begin_deeper
\begin_layout Itemize
Bom para reconhecimento de escrita;
\end_layout

\end_deeper
\begin_layout Itemize
AlexNet;
\end_layout

\begin_deeper
\begin_layout Itemize
Classificação de imagem, mais profunda do que o LeNet;
\end_layout

\end_deeper
\begin_layout Itemize
GoogLeNet;
\end_layout

\begin_deeper
\begin_layout Itemize
Ainda mais profundo, mas com melhor desempenho;
\end_layout

\begin_layout Itemize
Apresenta módulos de iniciação (grupos de camadas de convolução);
\end_layout

\end_deeper
\begin_layout Itemize
ResNet (rede residual);
\end_layout

\begin_deeper
\begin_layout Itemize
Ainda mais profundo - mantém o desempenho por meio skip connections;
\end_layout

\end_deeper
\begin_layout Subsection
Redes neurais recorrentes e LSTM
\end_layout

\begin_layout Subsubsection*
RNN's: Para que servem?
\end_layout

\begin_layout Itemize
Dados de série temporal;
\end_layout

\begin_deeper
\begin_layout Itemize
Quando você deseja prever o comportamento futuro com base no comportamento
 do passado;
\end_layout

\begin_layout Itemize
Logs da web, logs de sensores, negociações de ações;
\end_layout

\begin_layout Itemize
Onde dirigir seu carro autônomo com base em trajetórias anteriores;
\end_layout

\end_deeper
\begin_layout Itemize
Dados que consistem em sequências de comprimento arbitrário;
\end_layout

\begin_deeper
\begin_layout Itemize
Tradução;
\end_layout

\begin_layout Itemize
Legendas de imagens;
\end_layout

\begin_layout Itemize
Música gerada por máquina;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Neurônio Recorrente
\end_layout

\begin_layout Itemize
Um neurônio recorrente é muito similar ao neurônio visto anteriormente;
\end_layout

\begin_layout Itemize
A grande diferença está no laço que liga o neurônio com ele mesmo;
\end_layout

\begin_layout Itemize
Então, conforme executamos uma estapa de treinamento neste neurônio, alguns
 dados de treinamento são inseridos nesse neurônio, ou talvez uma entrada
 de uma camada anterior da nossa rede neural;
\end_layout

\begin_layout Itemize
Normalmente, é apenas gerado o resultado de saída da função de ativação
 desse neurônio, mas o neurônio recorrente permite que o alimentemos novamente
 com esse dado de saída, então da próxima vez que os dados forem processados
 através deste neurônio, então os dados da execução anterior também são
 somados nos resultados como uma entrada extra;
\end_layout

\begin_layout Itemize
Então, a medida que continuamos executando esse processamento de forma contínua,
 teremos alguns novos dados chegando que serão combinados com a saída anterior
 deste neurônio e isso ocorre continuamente;
\end_layout

\begin_layout Itemize
Logo, o passado nesse neurônio influência o futuro de como esse neurônio
 aprende;
\end_layout

\begin_layout Subsubsection*
Célula de memória
\end_layout

\begin_layout Itemize
Outra forma também de aplicar esse tipo de arquitetura é utilizando células
 de memória;
\end_layout

\begin_layout Itemize
Uma célula de memória, é um neurônio que inicia com uma entrada e que produz
 duas saídas;
\end_layout

\begin_deeper
\begin_layout Itemize
Uma saída alimenta a rede neural e a outra saída alimenta este neurônio
 no próximo passo, que pode ser interpretado como um tempo futuro;
\end_layout

\begin_layout Itemize
Então o neurônio que recebeu a informação do neurônio no tempo passado,
 passará a receber duas entradas, uma referente aos dados de entrada de
 processamento e outra referente à saída do neurônio do tempo passado, com
 isso ele produzirá mais duas saídas, uma para alimentar a rede neural e
 outra como entrada para este mesmo neurônio em um outro tempo futuro;
\end_layout

\begin_layout Itemize
Este processo ocorre de maneira contínua e recorrente;
\end_layout

\begin_layout Itemize
Ela é chamada de célula de memória pois mantém a sua memória com o passar
 do tempo do processamento;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Uma camada de neurônios recorrentes
\end_layout

\begin_layout Itemize
De maneira similar, então você pode construir uma camada de neurônios recorrente
s;
\end_layout

\begin_layout Itemize
Onde essa camada possui duas saídas, uma para alimentar o resto da rede
 neural e outra para alimentar novamente a camada de neurônios;
\end_layout

\begin_layout Subsubsection*
Topologias de RNN
\end_layout

\begin_layout Itemize
Sequência para sequência;
\end_layout

\begin_deeper
\begin_layout Itemize
Ou seja, preveja os preços das ações com base em uma série de dados históricos;
\end_layout

\end_deeper
\begin_layout Itemize
Sequência para vetor;
\end_layout

\begin_deeper
\begin_layout Itemize
Ou seja, palavras em uma frase para sentimento;
\end_layout

\end_deeper
\begin_layout Itemize
Vetor para sequência;
\end_layout

\begin_deeper
\begin_layout Itemize
Ou seja, criar legendas a partir de uma imagem;
\end_layout

\end_deeper
\begin_layout Itemize
Codificador -> Decodificador;
\end_layout

\begin_deeper
\begin_layout Itemize
Sequência -> Vetor -> Sequência;
\end_layout

\begin_layout Itemize
Ou seja, tradução automática;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Treinando RNN
\end_layout

\begin_layout Itemize
Backpropagation através do tempo;
\end_layout

\begin_deeper
\begin_layout Itemize
Assim como a backpropagation em MLPs, mas aplicada a cada etapa de tempo;
\end_layout

\end_deeper
\begin_layout Itemize
Todas essas etapas de tempo aumentam rapidamente;
\end_layout

\begin_deeper
\begin_layout Itemize
Acaba parecendo uma rede neural muito, muito profunda;
\end_layout

\begin_layout Itemize
Pode limitar a backpropagation a um número limitado de estapas de tempo
 (Backpropagation truncada ao longo do tempo);
\end_layout

\end_deeper
\begin_layout Itemize
Estado de etapas de tempo anteriores se dilui ao longo do tempo;
\end_layout

\begin_deeper
\begin_layout Itemize
Isso pode ser um problema, por exemplo, ao aprender estruturas de frases;
\end_layout

\end_deeper
\begin_layout Itemize
Célula LSTM;
\end_layout

\begin_deeper
\begin_layout Itemize
(Long Short-Term Memory Cell) Célula de Memória Longa de Curto Prazo;
\end_layout

\begin_layout Itemize
Mantém estados separados de curto e longo prazo;
\end_layout

\end_deeper
\begin_layout Itemize
Célula GRU;
\end_layout

\begin_deeper
\begin_layout Itemize
Unidade recorrente bloqueada - Gated Recurrent Unit;
\end_layout

\begin_layout Itemize
Célula LSTM simplificada com desempenho quase igual;
\end_layout

\end_deeper
\begin_layout Itemize
É realmente difícil;
\end_layout

\begin_deeper
\begin_layout Itemize
Muito sensível a topologias, escolha de hiperparâmetros;
\end_layout

\begin_layout Itemize
Uso intensivo de recursos;
\end_layout

\begin_layout Itemize
Uma escolha errada pode levar a uma RNN que não converge;
\end_layout

\end_deeper
\begin_layout Subsection
Deep Learning no EC2/EMR
\end_layout

\begin_layout Itemize
EMR é compatível com Apache MXNet e tipos de instância GPU;
\end_layout

\begin_layout Itemize
Tipos de instância apropriados para aprendizado profundo:
\end_layout

\begin_deeper
\begin_layout Itemize
P3: 8 GPUs Tesla V100;
\end_layout

\begin_layout Itemize
P2: 16 GPUs K80;
\end_layout

\begin_layout Itemize
G3: 4GPUs M60 (todos os chips Nvidia);
\end_layout

\end_deeper
\begin_layout Itemize
Deep Learning AMI's (TensorFlow, PyTorch, Apache MXNet, Chainer, Gluon e
 Keras);
\end_layout

\begin_deeper
\begin_layout Itemize
Não tem custo adicional;
\end_layout

\end_deeper
\begin_layout Itemize
Sagemaker;
\end_layout

\begin_layout Subsection
Tuning de redes neurais
\end_layout

\begin_layout Subsubsection*
Taxa de aprendizagem (Learning Rate)
\end_layout

\begin_layout Itemize
As redes neurais são treinadas por gradiente descent (ou técnicas semelhantes);
\end_layout

\begin_layout Itemize
Começamos em algum ponto aleatório, e amostramos soluções diferentes (pesos)
 buscando minimizar alguma função de custo, ao longo de muitas epochs;
\end_layout

\begin_layout Itemize
A distância entre essas amostras é a taxa de aprendizagem;
\end_layout

\begin_layout Subsubsection*
Efeito da taxa de aprendizagem
\end_layout

\begin_layout Itemize
Uma taxa de aprendizado muito alta significa que você pode ultrapassar a
 solução ideal;
\end_layout

\begin_layout Itemize
Uma taxa de aprendizado muito pequena demorará muito para encontrar a solução
 ideal;
\end_layout

\begin_layout Itemize
A taxa de aprendizagem é um exemplo de um hiperparâmetro;
\end_layout

\begin_layout Subsubsection*
Batch size
\end_layout

\begin_layout Itemize
Define quantas amostras de treinamento são usada em cada epoch;
\end_layout

\begin_layout Itemize
Um tanto contra-intuitivo:
\end_layout

\begin_deeper
\begin_layout Itemize
Batch size pequenos podemo ultrapassar os 
\begin_inset Quotes eld
\end_inset

mínimos locais
\begin_inset Quotes erd
\end_inset

 mais facilmente;
\end_layout

\begin_layout Itemize
Batch size muito grandes podem acabar ficando presos na solução errada;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Para recapitular
\end_layout

\begin_layout Itemize
Batch sizes pequenos tendem a não ficar presos nos mínimos locais;
\end_layout

\begin_layout Itemize
Batch sizes grandes podem convergir para a solução errada aleatoriamente;
\end_layout

\begin_layout Itemize
Grandes taxas de aprendizagem podem ultrapassar a solução correta;
\end_layout

\begin_layout Itemize
Pequenas taxas de aprendizagem aumentam o tempo de treinamento;
\end_layout

\begin_layout Subsection
Técnicas de regularização
\end_layout

\begin_layout Subsubsection*
O que é regularização?
\end_layout

\begin_layout Itemize
Prevenindo o overfitting;
\end_layout

\begin_deeper
\begin_layout Itemize
Modelos que são bons em fazer previsões sobre os dados em que foram treinados,
 mas não sobre novos dados que não tenham visto antes;
\end_layout

\begin_layout Itemize
Modelos superdimensionados aprenderam padrões nos dados de treinamento que
 não se generalizam para o mundo real;
\end_layout

\begin_layout Itemize
Frequentemente visto como alta precisão no conjunto de dados de treinamento,
 mas menor precisão no conjunto de dados de teste ou avaliação;
\end_layout

\begin_deeper
\begin_layout Itemize
Ao treinar e avaliar um modelo, usamos conjunto de dados de treinamento,
 avaliação e teste;
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
As técnicas de regularização têm como objetivo evitar o overfitting;
\end_layout

\begin_layout Subsubsection*
Algumas técnicas de regularização
\end_layout

\begin_layout Itemize
Simplificação do modelo:
\end_layout

\begin_deeper
\begin_layout Itemize
Muitas vezes um modelo pode estar sendo construído de uma maneira muito
 mais complexa do que deveria ser, por um exemplo, imagine que numa rede
 neural nós temos centenas de camadas ocultas e cada comada oculta possui
 milhares de neurônios, tudo isso para obter um simples modelo de classificação
 binária que poderia ser feito utilizando uma árvore de decisão;
\end_layout

\begin_layout Itemize
É claro que isso é uma maneira um tanto quanto exagerada de expor o problema
 e na vida real, a linha entre o quão complexo e o mínimo de simplificação
 que ele tem que ter para ser eficiente não é tão evidente.
 Mas num caso como esse, diminuir o número de camadas e o número de neurônios
 por camada pode ajudar e muito em reduzir as chances de o modelo superajustar;
\end_layout

\begin_layout Itemize
Isso porque reduzir a complexidade do modelo também reduz as chances de
 ele aprender padrões complexos (lê-se ruídos) da base de treinamento;
\end_layout

\end_deeper
\begin_layout Itemize
Dropout:
\end_layout

\begin_deeper
\begin_layout Itemize
O dropout é uma técnica que remove neurônios da sua rede de maneira completament
e aleatória;
\end_layout

\begin_layout Itemize
Isso força a sua rede neural a aprender padrões genéricos da base de dados,
 pois diminui a possibilidade de algum desses neurônios aprenderem padrões
 específicos (provavelmente associados a ruídos) da base de treinamento;
\end_layout

\end_deeper
\begin_layout Itemize
Parada Antecipada;
\end_layout

\begin_deeper
\begin_layout Itemize
O que podemos observar no treinamento de uma rede neural é que ao decorrer
 das suas epochs, as suas métricas de classificação podem acabar por estabilizar
 em um valor específico, sem apresentar melhoras reais com novos treinamentos;
\end_layout

\begin_layout Itemize
Nesses casos, você continuar o treinamento pode acarretar em problemas para
 o seu algoritmo, pois este pode acabar por gerar um modelo superajustado;
\end_layout

\end_deeper
\begin_layout Subsection
Gradientes
\end_layout

\begin_layout Itemize
Apenas recordando, uma rede neural ela funciona através do ajuste de pesos,
 então num processo de treinamento os dados passam pela rede neural, as
 funções de ativação vão produzir valores e na camada de saída, uma loss
 function vai calcular o erro e esse erro vai ser propagado de volta e neste
 processo de propagação, os pesos devem ser ajustados;
\end_layout

\begin_layout Itemize
Os pesos eles devem ser ajustados de quê forma? Mais ou menos? Qual é o
 valor do ajuste?
\end_layout

\begin_layout Itemize
Nesse aspecto, o gradiente descendente tem um papel fundamental, pois ele
 vai responder essa pergunta;
\end_layout

\begin_layout Subsubsection*
O problema do 
\begin_inset Quotes eld
\end_inset

Vanishing Gradient
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
Quando a inclinação da curva de aprendizado se aproxima de zero, o processamento
 pode 
\begin_inset Quotes eld
\end_inset

travar
\begin_inset Quotes erd
\end_inset

;
\end_layout

\begin_layout Itemize
Acabamos trabalhando com números muito pequenos que tornam o treinamento
 mais lento, ou mesmo introduzem erros numéricos;
\end_layout

\begin_layout Itemize
Torna-se um problema com redes mais profundas e RNNs à medida que se propagam
 para camadas mais profundas;
\end_layout

\begin_layout Itemize
Problema oposto: 
\begin_inset Quotes eld
\end_inset

exploding gradients
\begin_inset Quotes erd
\end_inset

;
\end_layout

\begin_layout Subsubsection*
Corrigindo o problema do 
\begin_inset Quotes eld
\end_inset

Vanishing Gradient
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
Hierarquia multinível;
\end_layout

\begin_deeper
\begin_layout Itemize
Divida em níveis com suas próprias sub-redes, treinando individualmente;
\end_layout

\end_deeper
\begin_layout Itemize
Long Short-Term Memory (LSTM);
\end_layout

\begin_layout Itemize
Residual Networks;
\end_layout

\begin_deeper
\begin_layout Itemize
ResNet;
\end_layout

\begin_layout Itemize
Conjunto de redes mais curtas;
\end_layout

\end_deeper
\begin_layout Itemize
Melhor escolha da função de ativação;
\end_layout

\begin_deeper
\begin_layout Itemize
ReLU é uma boa escolha;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Verificação de gradiente
\end_layout

\begin_layout Itemize
Uma técnica de depuração;
\end_layout

\begin_layout Itemize
Verifica numericamente as derivadas calculadas durante o treinamento;
\end_layout

\begin_layout Itemize
Útil para validar o código de treinamento de rede neural;
\end_layout

\begin_deeper
\begin_layout Itemize
Mas provavelmente você não vai querer escrever este código;
\end_layout

\end_deeper
\begin_layout Subsection
Regularização L1 e L2
\end_layout

\begin_layout Subsubsection*
O que é?
\end_layout

\begin_layout Itemize
Prevenir overfitting em ML em geral;
\end_layout

\begin_layout Itemize
Um 
\begin_inset Quotes eld
\end_inset

termo
\begin_inset Quotes erd
\end_inset

 de regularização é adicionado à medida que os pesos são aprendidos;
\end_layout

\begin_layout Itemize
O termos L1 é a soma dos pesos
\begin_inset Formula 
\begin{equation}
\lambda\sum_{i=1}^{k}\left|w_{i}\right|,
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize
O termo L2 é a soma do quadrado dos pesos
\begin_inset Formula 
\begin{equation}
\lambda\sum_{i=1}^{k}w_{i}^{2},
\end{equation}

\end_inset

 
\end_layout

\begin_layout Itemize
A mesma ideia pode ser aplicada a funções de perda;
\end_layout

\begin_layout Subsubsection*
Qual é a diferença?
\end_layout

\begin_layout Itemize
L1: soma dos pesos
\end_layout

\begin_deeper
\begin_layout Itemize
Executa a seleção de atributos - atributos inteiros vão para 0;
\end_layout

\begin_layout Itemize
Computacionalmente ineficiente;
\end_layout

\begin_layout Itemize
Saída esparsa;
\end_layout

\end_deeper
\begin_layout Itemize
L2: soma do quadrado dos pesos
\end_layout

\begin_deeper
\begin_layout Itemize
Todos os atributos permanecem, são apenas podenrados;
\end_layout

\begin_layout Itemize
Computacionalmente eficiente;
\end_layout

\begin_layout Itemize
Saída densa;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Por que você iria usar o L1?
\end_layout

\begin_layout Itemize
A seleção de atributos pode reduzir a dimensionalidade;
\end_layout

\begin_deeper
\begin_layout Itemize
De 100 atributos, talvez apenas 10 acabem com coeficientes diferentes de
 zero;
\end_layout

\begin_layout Itemize
A dispersão resultante pode compesar sua ineficiência computacional;
\end_layout

\end_deeper
\begin_layout Itemize
Mas se você acha que todos os seus recursos são importantes, L2 é provavelmente
 é uma escolha melhor;
\end_layout

\end_body
\end_document
