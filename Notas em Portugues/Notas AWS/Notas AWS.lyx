#LyX 2.3 created this file. For more info see http://www.lyx.org/
\lyxformat 544
\begin_document
\begin_header
\save_transient_properties true
\origin unavailable
\textclass article
\use_default_options true
\maintain_unincluded_children false
\language english
\language_package default
\inputencoding auto
\fontencoding global
\font_roman "default" "default"
\font_sans "default" "default"
\font_typewriter "default" "default"
\font_math "auto" "auto"
\font_default_family default
\use_non_tex_fonts false
\font_sc false
\font_osf false
\font_sf_scale 100 100
\font_tt_scale 100 100
\use_microtype false
\use_dash_ligatures true
\graphics default
\default_output_format default
\output_sync 0
\bibtex_command default
\index_command default
\paperfontsize default
\use_hyperref false
\papersize default
\use_geometry false
\use_package amsmath 1
\use_package amssymb 1
\use_package cancel 1
\use_package esint 1
\use_package mathdots 1
\use_package mathtools 1
\use_package mhchem 1
\use_package stackrel 1
\use_package stmaryrd 1
\use_package undertilde 1
\cite_engine basic
\cite_engine_type default
\use_bibtopic false
\use_indices false
\paperorientation portrait
\suppress_date false
\justification true
\use_refstyle 1
\use_minted 0
\index Index
\shortcut idx
\color #008000
\end_index
\secnumdepth 3
\tocdepth 3
\paragraph_separation indent
\paragraph_indentation default
\is_math_indent 0
\math_numbering_side default
\quotes_style english
\dynamic_quotes 0
\papercolumns 1
\papersides 1
\paperpagestyle default
\tracking_changes false
\output_changes false
\html_math_output 0
\html_css_as_file 0
\html_be_strict false
\end_header

\begin_body

\begin_layout Title
Notas sobre Machine Learning com AWS
\end_layout

\begin_layout Section
Engenharia de Dados
\end_layout

\begin_layout Subsection
Amazon S3
\end_layout

\begin_layout Subsubsection*
Visão Geral
\end_layout

\begin_layout Itemize
O amazon S3 permite que as pessoas armazenem objetos (arquivos) em buckets
 (diretórios);
\end_layout

\begin_layout Itemize
Os buckets devem ter um nome único global, isso porque o endereço de acesso
 de todos os usuários do S3 deve ser único;
\end_layout

\begin_layout Itemize
Os objetos (arquivos) tem uma chave.
 A chave é o caminho completo:
\end_layout

\begin_deeper
\begin_layout Labeling
\labelwidthstring 00.00.0000
<my_bucket>/my_file.txt
\end_layout

\begin_layout Labeling
\labelwidthstring 00.00.0000
<my_bucket>/my_folder1/another_folder/my_file.txt
\end_layout

\end_deeper
\begin_layout Itemize
Isso é útil e interessante quando olharmos partições: as partições permitem
 uma consulta mais otimizada;
\end_layout

\begin_layout Itemize
O tamanho máximo de um objeto é de 5TB;
\end_layout

\begin_layout Itemize
Tags de objeto (chave/valor, até 10), úteis para segurança e ciclo de vida;
\end_layout

\begin_layout Subsubsection*
AWS S3 para Machine Learning
\end_layout

\begin_layout Itemize
Backbone para muitos seviços de ML do AWS (ex.
 SageMaker)
\end_layout

\begin_layout Itemize
Cria um DataLake:
\end_layout

\begin_deeper
\begin_layout Itemize
Tamanho infinito, sem necessidade de provisionar o espaço que será utilizado;
\end_layout

\end_deeper
\begin_layout Itemize
Durabilidade 99,99999999%
\end_layout

\begin_deeper
\begin_layout Itemize
A durabilidade é uma medida da probabilidade de seus dados serem não serem
 corrompidos, quanto maior a durabilidade, menos a chance de serem corrompidos.
\end_layout

\end_deeper
\begin_layout Itemize
Armazenamento (S3) desacoplado do processamento (EC2, Amazon, Athena, Amazon
 RedShift Spectrum, Amazon Rekognition e AWS Glue);
\end_layout

\begin_layout Itemize
Arquitetura centralizada: isso é importante para que se tenha todos os seus
 arquivos em único local de forma centralizada;
\end_layout

\begin_layout Itemize
Armazenamento de objetos: suporta qualquer tipo de arquivo;
\end_layout

\begin_layout Itemize
Formatos comuns para ML: CSV, JSON, Parquet, ORC, Avro, Protobuf;
\end_layout

\begin_layout Subsubsection*
AWS S3: Particionamento
\end_layout

\begin_layout Itemize
Padrões para acelerar consultas em intervalos (ex: AWS Athena)
\end_layout

\begin_layout Itemize
Por data: S3://bucket/my-data-set/year/month/day/hour/data_00.csv
\end_layout

\begin_layout Itemize
Por produto: S3://bucket/my-data-set/product-id/data_32.csv
\end_layout

\begin_layout Itemize
Você pode definir qual estratégia de particionamento você quer
\end_layout

\begin_layout Itemize
O particionamento de dados será feito por algumas ferramentas que vamos
 usar.
 (AWS Glue)
\end_layout

\begin_layout Subsection
S3 Storage - Camadas de Armazenamento e Políticas de Ciclo de Vida
\end_layout

\begin_layout Itemize
Amazon S3 Standard - Uso geral;
\end_layout

\begin_layout Itemize
Amazon S3 - Acesso Infrequente (IA);
\end_layout

\begin_layout Itemize
Amazon S3 One Zone - Acesso Infrequente: Armazenada em um local único;
\end_layout

\begin_layout Itemize
Amazon S3 - Camada Inteligente: O serviço escolhe os melhores locais de
 armazenamento visando melhores preços;
\end_layout

\begin_layout Itemize
Amazon Glacier: Utilizado para arquivar dados que não serão mais utilizados;
\end_layout

\begin_layout Subsubsection*
Regras de Ciclo de vida
\end_layout

\begin_layout Itemize
Conjunto de regras para mover os dados entre diferentes camadas, para reduzir
 custo de armazenamento;
\end_layout

\begin_layout Itemize
Exemplo: Primeiramente o arquivo é alocado para uso geral, depois de um
 tempo, este arquivo é alocado para uso infrequente, depois de mais algum
 tempo, esse arquivo então é arquivado, sendo alocado para o Amazon Glacier;
\end_layout

\begin_layout Itemize
Ações de transição: Objetos fazem a transição para outra classe de armazenamento
;
\end_layout

\begin_deeper
\begin_layout Itemize
Mover objetos da classe Padrão para o Uso Infrequente depois de 60 dias
 de criação;
\end_layout

\begin_layout Itemize
Mover os objetos do Uso Infrequente para o Glacier após 6 meses;
\end_layout

\end_deeper
\begin_layout Itemize
Ações de expiração: O S3 exclui objetos experiados para nós ao nosso critério.
\end_layout

\begin_layout Subsection
Segurança
\end_layout

\begin_layout Subsubsection*
Criptografia S3 para Objetos
\end_layout

\begin_layout Itemize
Criptografia S3: A criptografia pode ser realizada no servidor AWS ou pelo
 próprio cliente;
\end_layout

\begin_layout Itemize
Exitem 4 métodos de criptografia para objetos no S3;
\end_layout

\begin_deeper
\begin_layout Itemize
SSE-S3: Criptografa objetos S3 usando chaves criadas e gerenciadas pelo
 AWS;
\end_layout

\begin_layout Itemize
SSE-KMS: Usa o serviço de gestão de chaves do AWS para gerenciar chaves
 criptográficas;
\end_layout

\begin_deeper
\begin_layout Itemize
Segurança adicional (usuário deve ter acesso à chave KMS);
\end_layout

\begin_layout Itemize
Trilha de auditoria da chave KMS;
\end_layout

\end_deeper
\begin_layout Itemize
SSE-C: Quando se quer gerencias as suas próprias chaves;
\end_layout

\begin_layout Itemize
Criptografia no cliente: Ocorre fora do ambiente AWS;
\end_layout

\end_deeper
\begin_layout Itemize
De uma perspectiva de ML, SSE-S3 e SSE-KMS são os mais usados;
\end_layout

\begin_layout Subsubsection*
Gestão de Segurança
\end_layout

\begin_layout Itemize
Gestão de segurança baseada no usuário
\end_layout

\begin_deeper
\begin_layout Itemize
Políticas IAM (Identity Access Management) - Quais chamadas de API devem
 ser permitidas para usuários específicos;
\end_layout

\end_deeper
\begin_layout Itemize
Baseada em recursos
\end_layout

\begin_deeper
\begin_layout Itemize
Políticas de buckets: 
\end_layout

\begin_deeper
\begin_layout Itemize
Regras abrangentes de buckets;
\end_layout

\begin_layout Itemize
Permitem contas cruzadas
\end_layout

\end_deeper
\begin_layout Itemize
Lista de controle de acesso a objetos (ACL):
\end_layout

\begin_deeper
\begin_layout Itemize
Controle mais detalhado;
\end_layout

\end_deeper
\begin_layout Itemize
Lista de controle de acesso ao bucket (ACL):
\end_layout

\begin_deeper
\begin_layout Itemize
Menos comum;
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Políticas de Buckets S3:
\end_layout

\begin_deeper
\begin_layout Itemize
Políticas baseadas em JSON:
\end_layout

\begin_deeper
\begin_layout Itemize
Gerenciamento de Recursos: buckets e objetos
\end_layout

\begin_layout Itemize
Ações: vai permitir ou negar o consumo de uma API;
\end_layout

\begin_layout Itemize
Efeito da API: Permitir ou negar;
\end_layout

\begin_layout Itemize
Principal: A conta ou usuário que aplica a política;
\end_layout

\end_deeper
\begin_layout Itemize
Use a política de Bucket S3 para:
\end_layout

\begin_deeper
\begin_layout Itemize
Dar acesso ao público a um bucket;
\end_layout

\begin_layout Itemize
Forçar objetos a serem criptografados no upload;
\end_layout

\begin_layout Itemize
Dar acesso a outra conta (conta cruzada);
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Criptografia Padrão S3 vs Políticas de Buckets
\end_layout

\begin_deeper
\begin_layout Itemize
A forma antiga de habilitar criptografia por padrão era usar uma política
 de Bucket e recusar qualquer comando HTTP sem o cabeçalho apropriado;
\end_layout

\begin_layout Itemize
A nova forma é usar a opção de 
\begin_inset Quotes eld
\end_inset

criptografia padrão
\begin_inset Quotes erd
\end_inset

 no S3;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Segurança S3 - Outros
\end_layout

\begin_layout Itemize
Rede - VPC (Virtual Private Cloud) Endpoint Gateway:
\end_layout

\begin_deeper
\begin_layout Itemize
Permite que o tráfico fique dentro da sua VPC, ao invés de ir para a internet
 pública;
\end_layout

\begin_layout Itemize
Garante que seus serviços privados (AWS SageMaker) possam acessar o S3;
\end_layout

\begin_layout Itemize
Muito importante para o exame AWS ML;
\end_layout

\end_deeper
\begin_layout Itemize
Log e Auditoria
\end_layout

\begin_deeper
\begin_layout Itemize
Logs de acesso podem ser armazenados em outro bucket S3;
\end_layout

\begin_layout Itemize
Chamadas de API podem ser logadas na 
\begin_inset Quotes eld
\end_inset

AWS Cloud Trail
\begin_inset Quotes erd
\end_inset

;
\end_layout

\end_deeper
\begin_layout Itemize
Baseados em Tags: Combina política IAM e políticas de Bucket:
\end_layout

\begin_deeper
\begin_layout Itemize
Exemplo: Adicionar a tag classification=PHI a seus objetos;
\end_layout

\end_deeper
\begin_layout Subsection
AWS Kinesis Data Stream Data Firehose
\end_layout

\begin_layout Subsubsection*
AWS Kineses: Visão Geral
\end_layout

\begin_layout Itemize
Kinesis é uma alternativa gerenciada do Apache Kafka;
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
O Apache Kafka é uma ferramenta de Data Streaming.
 
\end_layout

\begin_layout Plain Layout
No Data Streaming os dados são processados em tempo real, ou muito próximo
 do real.
 Diferente do batch de dados, que é um processamento em blocos, geralmente
 ocorrendo tomando os dados obtidos a partir de um intervalo de tempo, como
 dias, semanas meses, ou anos.
\end_layout

\end_inset


\end_layout

\begin_layout Itemize
Ótimo para logs de aplicações, IOT, clickstreams;
\end_layout

\begin_layout Itemize
Ótimo para processar dados em tempo real;
\end_layout

\begin_layout Itemize
Ótimo para frameworks de processamento em streaming (Spark, NiFi, etc.)
\end_layout

\begin_layout Itemize
Dados são automaticamente replicados de forma síncrona para 
\begin_inset Formula $3AZ$
\end_inset


\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Itemize
O AWS Kinesis é formado por 4 aplicações principais:
\end_layout

\begin_deeper
\begin_layout Itemize
Kinesis Streams: Ingestão de streaming com baixa latência e em grande escala;
\end_layout

\begin_layout Itemize
Kinesis Analytics: Executa análise em tempo real em streams usando SQL;
\end_layout

\begin_layout Itemize
Kinesis Firehose: Carrega streams no S3, RedShift, ElasticSearch e Splunk;
\end_layout

\begin_layout Itemize
Kinesis Video Streams: Usado para stream de vídeo em tempo real;
\end_layout

\end_deeper
\begin_layout Itemize
Visão Geral do Kinesis Streams:
\end_layout

\begin_deeper
\begin_layout Itemize
Streams são divididos em Shards ordenados/partições;
\end_layout

\begin_layout Itemize
Os shards devem ser provisionados com antecedência (Planejamento de capacidade);
\end_layout

\begin_layout Itemize
Retenção de dados é de 24 horas por padrão, pode chegar a 7 dias;
\end_layout

\begin_layout Itemize
Capaz de reprocessar dados;
\end_layout

\begin_layout Itemize
Várias aplicações podem consumir o mesmo stream;
\end_layout

\begin_layout Itemize
Uma vez que os dados são inseridos no Kinesis, não pode ser excluído (Imutabilid
ade);
\end_layout

\begin_layout Itemize
Registros podem ter até 1MB de tamanho;
\end_layout

\end_deeper
\begin_layout Itemize
Limites de dados do Kinesis Data
\end_layout

\begin_deeper
\begin_layout Itemize
Produtores
\end_layout

\begin_deeper
\begin_layout Itemize
1MB por segundo ou 1000 mensagens na escrita por SHARD;
\end_layout

\begin_layout Itemize
Ou então 
\begin_inset Quotes eld
\end_inset

ProvisionedThroughputException
\begin_inset Quotes erd
\end_inset

 será levantado, caso o limite seja ultrapassado;
\end_layout

\end_deeper
\begin_layout Itemize
Consumidor clássico:
\end_layout

\begin_deeper
\begin_layout Itemize
2MB/s de leitura por SHARD entre todos os consumidores;
\end_layout

\begin_layout Itemize
5 camadas de API por segundo por SHARD entre todos os consumidores
\end_layout

\end_deeper
\begin_layout Itemize
Retenção de dados:
\end_layout

\begin_deeper
\begin_layout Itemize
24 horas por padrão
\end_layout

\begin_layout Itemize
Pode ser estendido até por 7 dias;
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Kinesis Data Firehose:
\end_layout

\begin_deeper
\begin_layout Itemize
Serviço totalmente gerenciado, sem administração;
\end_layout

\begin_layout Itemize
Próximo ao tempo real (mínimo de 60 segundos de latencia para batches não
 completos);
\end_layout

\begin_layout Itemize
Ingestão de dados no RedShift/Amazon S3/ElasticSearch/Splunk
\end_layout

\begin_layout Itemize
Escala automaticamente;
\end_layout

\begin_layout Itemize
Suporte a muitos formatos de dados;
\end_layout

\begin_layout Itemize
Conversão de dados CSV/JSON para Parquet/ORC (apenas para o S3);
\end_layout

\begin_layout Itemize
Transformação de dados através do AWS Lambda (ex: CSV=>JSON);
\end_layout

\begin_layout Itemize
Suporta compressão quando usa o Amazon S3 (GZIP, ZIP e SNAPPY);
\end_layout

\begin_layout Itemize
Paga-se pela quantidade de dados que entra no Firehose;
\end_layout

\end_deeper
\begin_layout Itemize
Kinesis Data Analytics
\end_layout

\begin_deeper
\begin_layout Itemize
Casos de uso:
\end_layout

\begin_deeper
\begin_layout Itemize
Streaming ETL: Seleciona colunas, faz transformações simples em dados em
 streaming;
\end_layout

\begin_layout Itemize
Gerador contínuo de métricas: classificação ao vivo para um jogo mobile;
\end_layout

\begin_layout Itemize
Análise responsiva: verifica certo critério e cria alertas (filtrando);
\end_layout

\end_deeper
\begin_layout Itemize
Características:
\end_layout

\begin_deeper
\begin_layout Itemize
Paga apenas por recursos consumidos (mas não é barato);
\end_layout

\begin_layout Itemize
Serverless: escala automaticamente;
\end_layout

\begin_layout Itemize
Usa permissão IAM para acessar fontes de streaming e destinos;
\end_layout

\begin_layout Itemize
SQL ou Flink para escrever o processamento;
\end_layout

\begin_layout Itemize
Descoberta de Schema;
\end_layout

\begin_layout Itemize
Lambda pode ser usado para pré-processamento;
\end_layout

\end_deeper
\begin_layout Itemize
Machine Learning no Kinesis Data Analytics:
\end_layout

\begin_deeper
\begin_layout Itemize
RANDOM_CUT_FOREST:
\end_layout

\begin_deeper
\begin_layout Itemize
Função SQL usada para detecção de anomalias em colunas numéricas de um stream;
\end_layout

\begin_layout Itemize
Exemplo: detectar passageiros anormais no metrô durante a maratona de Nova
 Iorque;
\end_layout

\begin_layout Itemize
Usa o histórico recente para processar o modelo;
\end_layout

\end_deeper
\begin_layout Itemize
HOTSPOTS:
\end_layout

\begin_deeper
\begin_layout Itemize
Localiza e informa sobre regiões relativamente densas nos seus dados;
\end_layout

\begin_layout Itemize
Exemplo: uma coleção de servidores superaquecidos em um datacenter;
\end_layout

\end_deeper
\end_deeper
\end_deeper
\begin_layout Itemize
Resumo do Kinesis - Machine Learning:
\end_layout

\begin_deeper
\begin_layout Itemize
Kinesis Data Stream: Cria aplicações de machine learning em tempo real;
\end_layout

\begin_layout Itemize
Kinesis Data Analytics: algoritmos ETL/ML em tempo real em stream;
\end_layout

\begin_layout Itemize
Kinesis Video Stream: Stream de vídeo em tempo real para criar aplicações
 em ML;
\end_layout

\end_deeper
\begin_layout Subsection
Glue Data Catalog
\end_layout

\begin_layout Itemize
Repositório de metadados para todas as suas tabelas;
\end_layout

\begin_deeper
\begin_layout Itemize
Automatiza inferência de schema: lembrando que schema é a definição dos
 seus dados ou a estrutura que os dados tem.
\end_layout

\begin_layout Itemize
O schema é versionado: a medida que a estrutura é mudada, ela é versionada;
\end_layout

\end_deeper
\begin_layout Itemize
Integrado com o Athena ou RedShift Spectrum (schema e data discovery)
\end_layout

\begin_layout Itemize
Glue Crawlers pode lhe ajudar a construir um Glue Data Catalog;
\end_layout

\begin_layout Subsubsection*
Glue Data Catalog - Crawlers
\end_layout

\begin_layout Itemize
Crawlers exploram seus dados para inferir schemas e partições;
\end_layout

\begin_layout Itemize
Funciona com JSON, Parquet, CSV, relacional;
\end_layout

\begin_layout Itemize
Crawlers funciona com: S3, Amazon RedShift, Amazon RDS;
\end_layout

\begin_layout Itemize
O Crawler pode ser agendado ou rodado sob demanda;
\end_layout

\begin_layout Itemize
Para rodar o crawler precisa de uma credencial ou IAM Role para acessar
 as fontes de dados;
\end_layout

\begin_layout Subsubsection*
Glue e Partições S3
\end_layout

\begin_layout Itemize
Glue Crawler vai extrair partições baseadas em como seus dados no S3 estão
 organizados;
\end_layout

\begin_layout Itemize
Pense com antecedência sobre como você consultará seu data lake no S3;
\end_layout

\begin_layout Itemize
Exemplo: dispositivos enviam dados de sensores a cada hora;
\end_layout

\begin_deeper
\begin_layout Itemize
Você consulta principalmente por intervalos de tempo?
\end_layout

\begin_deeper
\begin_layout Itemize
Em caso afirmativo, organize seus intervalos como S3://my-bucket/dataset/aaaa/mm
/dd/dispositivo
\end_layout

\end_deeper
\begin_layout Itemize
Você consulta principalmente por dispositivo?
\end_layout

\begin_deeper
\begin_layout Itemize
Em caso afirmativo, organize seus intervalos como S3://my-bucket/dataset/device/
aaaa/mm/dd
\end_layout

\end_deeper
\end_deeper
\begin_layout Subsubsection*
Glue ETL
\end_layout

\begin_layout Itemize
Transformar dados, limpar dados, enriquecer dados (antes de fazer a análise)
\end_layout

\begin_deeper
\begin_layout Itemize
Gera código ETL em Python ou Scala, você pode modificar o código;
\end_layout

\begin_layout Itemize
Ou você pode fornecer seus próprios scripts Spark ou Pyspark;
\end_layout

\begin_layout Itemize
O destino pode ser S3, JDBC (RDS, RedShift) ou o catálogo de dados do Glue;
\end_layout

\end_deeper
\begin_layout Itemize
Totalmente gerenciado, econômico, paga apenas pelos recursos consumidos;
\end_layout

\begin_layout Itemize
Os jobs são executados em uma plataforma spark serverless;
\end_layout

\begin_layout Itemize
Glue Scheduler para agendar os trabalhos
\end_layout

\begin_layout Itemize
Glue Triggers para automatizar execuções de trabalho com base em 
\begin_inset Quotes eld
\end_inset

eventos
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Subsubsection*
Glue ET: Transformações
\end_layout

\begin_layout Itemize
Transformações empacotadas (Bundled):
\end_layout

\begin_deeper
\begin_layout Itemize
DropFields, DropNullFields: Remover campos nulos;
\end_layout

\begin_layout Itemize
Filter: Específica uma função para filtrar registros;
\end_layout

\begin_layout Itemize
Join: Para enriquecer os dados;
\end_layout

\begin_layout Itemize
Map: Adicionar campos, excluir campos, realizar pesquisas externas;
\end_layout

\end_deeper
\begin_layout Itemize
Transformações para aprendizado de máquinas:
\end_layout

\begin_deeper
\begin_layout Itemize
FindMatches ML: Identifica registros duplicados ou correspondentes em seu
 conjunto de dados, mesmo quando os registros não têm um identificador único
 comum e nenhum campo que corresponde exatamente;
\end_layout

\begin_layout Itemize
Conversões de formato: CSV, JSON, AVRO, Parquet, ORC, XML;
\end_layout

\begin_layout Itemize
Transformações do Apache Spark (exemplo: K-means);
\end_layout

\end_deeper
\begin_layout Subsection
AWS Data Stores Para Machine Learning 
\end_layout

\begin_layout Itemize
RedShift - Data Warehousing, SQL Analytics (OLAP - Online Analytical Processing)
:
\end_layout

\begin_deeper
\begin_layout Itemize
Carrega dados do S3 para o RedShift;
\end_layout

\begin_layout Itemize
Use o RedShift Spectrum para consultar dados diretamente no S3 (sem necessitar
 carregar);
\end_layout

\end_deeper
\begin_layout Itemize
RDS, Aurora:
\end_layout

\begin_deeper
\begin_layout Itemize
Armazenamento Relacional, SQL (OLTP - Online Transaction Processing);
\end_layout

\begin_layout Itemize
Servidores devem ser provisionados com antecedência;
\end_layout

\end_deeper
\begin_layout Itemize
DynamoDB:
\end_layout

\begin_deeper
\begin_layout Itemize
Armazenamento NoSQL, serverless, provisão com capacidade de leitura e escrita;
\end_layout

\begin_layout Itemize
Útil para armazenar o modelo de machine learning servido pela sua aplicação;
\end_layout

\end_deeper
\begin_layout Itemize
S3:
\end_layout

\begin_deeper
\begin_layout Itemize
Armazenamento de objetos;
\end_layout

\begin_layout Itemize
Serverless, armazenamento infinito;
\end_layout

\begin_layout Itemize
Integração com a maioria dos serviços AWS;
\end_layout

\end_deeper
\begin_layout Itemize
ElasticSearch:
\end_layout

\begin_deeper
\begin_layout Itemize
Indexação de dados;
\end_layout

\begin_layout Itemize
Pesquisa nos dados;
\end_layout

\begin_layout Itemize
Clickstream Analytics;
\end_layout

\end_deeper
\begin_layout Itemize
ElastiCache:
\end_layout

\begin_deeper
\begin_layout Itemize
Mecanismo de cache;
\end_layout

\begin_layout Itemize
Não é usado para aprendizado de máquina;
\end_layout

\end_deeper
\begin_layout Subsection
AWS Data Pipeline
\end_layout

\begin_layout Itemize
Os destinos incluem S3, RDS, DynamoDB, RedShift e EMR;
\end_layout

\begin_layout Itemize
Gerencia dependências entre tarefas;
\end_layout

\begin_layout Itemize
Tenta novamente e notifica falhas;
\end_layout

\begin_layout Itemize
As fontes de dados podem ser locais (on-premises);
\end_layout

\begin_layout Itemize
Altamente disponível;
\end_layout

\begin_layout Subsubsection*
AWS Data Pipeline vs Glue
\end_layout

\begin_layout Itemize
Glue:
\end_layout

\begin_deeper
\begin_layout Itemize
Glue ETL - Executa o código Apache Spark, baseado em Scala ou Python, com
 foco no ETL;
\end_layout

\begin_layout Itemize
Não se preocupa em configurar ou gerenciar os recursos;
\end_layout

\begin_layout Itemize
Tem um catálogo de dados para disponibililzar os dados para o Athena ou
 RedShift Spectrum;
\end_layout

\end_deeper
\begin_layout Itemize
Data Pipeline:
\end_layout

\begin_deeper
\begin_layout Itemize
Serviço de Orquestração;
\end_layout

\begin_layout Itemize
Mais controle sobre o ambiente, recursos de computação que executam código;
\end_layout

\begin_layout Itemize
Permite acesso à instâncias EC2 ou EMR (cria recursos em sua própria conta);
\end_layout

\end_deeper
\begin_layout Section
Análise de dados exploratória
\end_layout

\begin_layout Subsection
AWS Athena
\end_layout

\begin_layout Itemize
Serviço de consulta interativa para S3 (SQL);
\end_layout

\begin_deeper
\begin_layout Itemize
Não há necessidade de carregar dados, ele permanece no S3;
\end_layout

\begin_layout Itemize
Utiliza Presto;
\end_layout

\begin_layout Itemize
Serverless;
\end_layout

\begin_layout Itemize
Suporta muitos formatos de dados:
\end_layout

\begin_deeper
\begin_layout Itemize
CSV (legível para humanos);
\end_layout

\begin_layout Itemize
JSON (legível para humanos);
\end_layout

\begin_layout Itemize
ORC (colunar, divísivel);
\end_layout

\begin_layout Itemize
Parquet (colunar, divísivel);
\end_layout

\begin_layout Itemize
Avro (divísivel);
\end_layout

\begin_layout Itemize
Não estruturado, semiestruturado ou estruturado;
\end_layout

\end_deeper
\begin_layout Itemize
Alguns exemplos:
\end_layout

\begin_deeper
\begin_layout Itemize
Consultas ad-hoc de logs da web;
\end_layout

\begin_layout Itemize
Consultas de dados de teste antes de carregar no RedShift;
\end_layout

\begin_layout Itemize
Analisa olos do cloudtrail/cloudfront/VPL/ELB, etc no S3;
\end_layout

\begin_layout Itemize
Integração com notebookos do Jupyter, Zeppelin, RStudio;
\end_layout

\begin_layout Itemize
Integração com o QuickSight;
\end_layout

\begin_layout Itemize
Integração via ODBC/JDBC com ferramentas de visualização;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Modelo de custo do Athena;
\end_layout

\begin_layout Itemize
Paga conforme o uso
\end_layout

\begin_deeper
\begin_layout Itemize
$5 por TB;
\end_layout

\begin_layout Itemize
Consultas bem-sucedidas ou canceladas contam, consultas com falha não;
\end_layout

\end_deeper
\begin_layout Itemize
Sem custo para DDL (CREATE, ALTER, DROP, etc.)
\end_layout

\begin_layout Itemize
Economize muito dinheiro usando formatos em colunas:
\end_layout

\begin_deeper
\begin_layout Itemize
ORC, Parquet;
\end_layout

\begin_layout Itemize
Economize 30-90% e obtenha melhor desempenho;
\end_layout

\end_deeper
\begin_layout Itemize
Glue e S3 têm seus próprios custos;
\end_layout

\begin_layout Subsubsection*
Segurança no Athena 
\end_layout

\end_deeper
\begin_layout Itemize
Controle de Acesso
\end_layout

\begin_deeper
\begin_layout Itemize
IAM, ACLs, Políticas de bucket S3;
\end_layout

\begin_layout Itemize
/AmazonAthenaFullAccess/AWSQuicksightAthenaAccess
\end_layout

\end_deeper
\begin_layout Itemize
Criptografia resultados 
\begin_inset Quotes eld
\end_inset

at rest
\begin_inset Quotes erd
\end_inset

 no diretórios de staging do S3;
\end_layout

\begin_layout Itemize
Croptografia 
\begin_inset Quotes eld
\end_inset

server side
\begin_inset Quotes erd
\end_inset

 com chave KMS (CSE-KMS);
\end_layout

\begin_layout Itemize
Croptografia 
\begin_inset Quotes eld
\end_inset

server side
\begin_inset Quotes erd
\end_inset

 com chave KMS (SSE-KMS);
\end_layout

\begin_layout Itemize
Possibilidade de acesso entre contas na política de Bucket S3;
\end_layout

\begin_layout Itemize
Criptografia Transport Layer Security (TLS) 
\begin_inset Quotes eld
\end_inset

em trânsito
\begin_inset Quotes erd
\end_inset

.
 (entre Athena e S3)
\end_layout

\begin_layout Subsubsection*
Quando não usar o Athena
\end_layout

\begin_layout Itemize
Relatório/Visualização altamente formatados
\end_layout

\begin_deeper
\begin_layout Itemize
É para isso que serve o Quicksight
\end_layout

\end_deeper
\begin_layout Itemize
ETL
\end_layout

\begin_deeper
\begin_layout Itemize
Em vez disso, use o Glue;
\end_layout

\end_deeper
\begin_layout Subsection
Amazon QuickSight
\end_layout

\begin_layout Itemize
Serviço de análise de dados rápido, fácil e baseado na nuvem;
\end_layout

\begin_layout Itemize
Permite que todos os funcionários de uma organização:
\end_layout

\begin_deeper
\begin_layout Itemize
Crie visualizações;
\end_layout

\begin_layout Itemize
Realizar análise ad-hoc;
\end_layout

\begin_layout Itemize
Obtenha rapidamente insight de negócios a partir de dados;
\end_layout

\begin_layout Itemize
A qualquer hora, em qualquer dispositivo (navegadores, celular);
\end_layout

\begin_layout Itemize
Serverless;
\end_layout

\end_deeper
\begin_layout Itemize
Fontes de dados QuickSight
\end_layout

\begin_deeper
\begin_layout Itemize
RedShift;
\end_layout

\begin_layout Itemize
Aurora/RDS;
\end_layout

\begin_layout Itemize
Athena;
\end_layout

\begin_layout Itemize
EC2: Hosted databases
\end_layout

\begin_layout Itemize
Arquivos (S3 ou on-premises)
\end_layout

\begin_deeper
\begin_layout Itemize
Excel;
\end_layout

\begin_layout Itemize
CSV, TSV
\end_layout

\begin_layout Itemize
Formatos de log
\end_layout

\end_deeper
\begin_layout Itemize
A preparação de dados permite ETL limitado;
\end_layout

\end_deeper
\begin_layout Itemize
SPICE
\end_layout

\begin_deeper
\begin_layout Itemize
Os conjuntos de dados são importados para o SPICE
\end_layout

\begin_deeper
\begin_layout Itemize
Mecanismo de cálculo in-memory super rápido e paralelo;
\end_layout

\begin_layout Itemize
Usa armazenamento colunar in-memory, geração de código de máquina;
\end_layout

\begin_layout Itemize
Acelera consultas interativas em grandes conjuntos de dados;
\end_layout

\end_deeper
\begin_layout Itemize
Cada usuário recebe 10GB de SPICE;
\end_layout

\begin_layout Itemize
Altamente disponível durável;
\end_layout

\begin_layout Itemize
Escala para centenas de milhares de usuários;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Casos de uso do QuickSight
\end_layout

\begin_layout Itemize
Exploração/Visualização ad-hoc interativa de dados;
\end_layout

\begin_layout Itemize
Painéis e KPIs;
\end_layout

\begin_layout Itemize
Histórias
\end_layout

\begin_deeper
\begin_layout Itemize
Visitas guiadas por visualizações específicas de uma análise
\end_layout

\begin_layout Itemize
Transmitir os pontos-chave, processo de pensamento, evolução de uma análise;
\end_layout

\begin_layout Itemize
Analisar/Visualizar dados de:
\end_layout

\begin_deeper
\begin_layout Itemize
Logs no S3;
\end_layout

\begin_layout Itemize
Bancos de dados on-premises
\end_layout

\begin_layout Itemize
AWS (RDS, RedShift, Athena, S3)
\end_layout

\begin_layout Itemize
Aplicativos SaaS, como salesforce;
\end_layout

\begin_layout Itemize
Qualquer fonte de dados JDBC/ODBC
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Machine Learning Insights
\end_layout

\begin_deeper
\begin_layout Itemize
Detecção de anomalia;
\end_layout

\begin_layout Itemize
Previsão;
\end_layout

\begin_layout Itemize
Autonarrativas
\end_layout

\end_deeper
\begin_layout Subsubsection*
QuickSight quando não usar
\end_layout

\begin_layout Itemize
Relatórios prontos formatados;
\end_layout

\begin_deeper
\begin_layout Itemize
Quicksight é para consultas e visualizações ad-hoc;
\end_layout

\end_deeper
\begin_layout Itemize
ETL
\end_layout

\begin_deeper
\begin_layout Itemize
Use Glue, embora Quicksight possa fazer algumas transformações;
\end_layout

\end_deeper
\begin_layout Itemize
Segurança do Quicksight;
\end_layout

\begin_deeper
\begin_layout Itemize
Autenticação multifator em sua conta
\end_layout

\begin_layout Itemize
Conectividade VPC;
\end_layout

\begin_deeper
\begin_layout Itemize
Adicione o intervalo de endereços IP do Quicksight aos seus grupos de segurança
 de banco de dados;
\end_layout

\end_deeper
\begin_layout Itemize
Segurança de nível de linha;
\end_layout

\begin_layout Itemize
Acesso VPC privado
\end_layout

\begin_deeper
\begin_layout Itemize
Interface de rede 
\begin_inset Quotes eld
\end_inset

Elastic
\begin_inset Quotes erd
\end_inset

, AWS Direct Connect;
\end_layout

\end_deeper
\end_deeper
\begin_layout Subsubsection*
Gestão de usuários no QuickSight
\end_layout

\begin_layout Itemize
Usuários definidos via IAM ou inscrição por e-mail;
\end_layout

\begin_layout Itemize
Integração do Active Directory com QuickSight Enterprise Edition;
\end_layout

\begin_layout Itemize
Precificação do QuickSight:
\end_layout

\begin_deeper
\begin_layout Itemize
Pagamento anual:
\end_layout

\begin_deeper
\begin_layout Itemize
Standard: $9/Usuário/mês
\end_layout

\begin_layout Itemize
Enterprise: $18/Usuário/mês
\end_layout

\end_deeper
\begin_layout Itemize
Capacidade extra do spice (além do 10GB)
\end_layout

\begin_deeper
\begin_layout Itemize
$0,25 (standard) $0,38 (enterprise)/GB/mês
\end_layout

\end_deeper
\begin_layout Itemize
Mês a mês
\end_layout

\begin_deeper
\begin_layout Itemize
Standard: $12/GB/mês
\end_layout

\begin_layout Itemize
Enterprise: $24/GB/mês
\end_layout

\end_deeper
\begin_layout Itemize
Edição Enterprise:
\end_layout

\begin_deeper
\begin_layout Itemize
Criptografia 
\begin_inset Quotes eld
\end_inset

at rest
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
Integração com Microsoft Active Directory
\end_layout

\end_deeper
\end_deeper
\begin_layout Subsection
O que é EMR?
\end_layout

\begin_layout Itemize
Elastic Map Reduce;
\end_layout

\begin_layout Itemize
Estrutura Gerenciada do Hadoop em instâncias EC2;
\end_layout

\begin_layout Itemize
Inclui Spark, HBase, Presto, Flink, Hive e mais;
\end_layout

\begin_layout Itemize
EMR notebooks;
\end_layout

\begin_layout Itemize
Vários pontos de integração com AWS;
\end_layout

\begin_layout Subsubsection*
Cluster EMR
\end_layout

\begin_layout Itemize
Master Node: Gerencia o cluster
\end_layout

\begin_deeper
\begin_layout Itemize
Instâncias EC2 única;
\end_layout

\end_deeper
\begin_layout Itemize
Core Node: hospeda dados HDFS e executa tarefas
\end_layout

\begin_deeper
\begin_layout Itemize
Pode ser escalado para cima e para baixo, mas com algum risco;
\end_layout

\end_deeper
\begin_layout Itemize
Task Node: Executa tarefas, não hospeda dados;
\end_layout

\begin_deeper
\begin_layout Itemize
Sem risco de perda de dados ao remover;
\end_layout

\begin_layout Itemize
Bom uso de instâncias pontuais;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Uso do EMR
\end_layout

\begin_layout Itemize
Clusters transitórios versus clusters de longa duração 
\begin_inset Note Note
status open

\begin_layout Plain Layout
O cluster transitório é encerrado quando ele concluir todas as etapas.
\end_layout

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Pode alternar task nodes usando 
\begin_inset Quotes eld
\end_inset

Spot Instances
\begin_inset Quotes erd
\end_inset

 para capacidade temporária;
\end_layout

\begin_layout Itemize
Pode usar instâncias reservadas em clusters de longa duração para economizar
 dinheiro;
\end_layout

\end_deeper
\begin_layout Itemize
Conecta diretamente ao mestre para executar ao jobs;
\end_layout

\begin_layout Itemize
Envie as etapas ordenadas por meio do console;
\end_layout

\begin_layout Subsubsection*
Integração EMR / AWS
\end_layout

\begin_layout Itemize
Amazon EC2 para as instâncias dos nós que fazem parte do cluster
\end_layout

\begin_layout Itemize
Amazon VPC para configurar a rede virtual na qual você inicia suas instâncias;
\end_layout

\begin_layout Itemize
Amazon S3 para armazenar dados de entrada e saída;
\end_layout

\begin_layout Itemize
Amazon CloudWatch para monitorar o desempenho do cluster e configurar alarmes;
\end_layout

\begin_layout Itemize
AWS IAM para configurar permissões;
\end_layout

\begin_layout Itemize
AWS CloudTrail para auditar as solicitações feitas ao serviço;
\end_layout

\begin_layout Itemize
AWS Data Pipeline para agendar e iniciar seus clusters;
\end_layout

\begin_layout Subsubsection*
EMR Storage
\end_layout

\begin_layout Itemize
HDFS
\end_layout

\begin_layout Itemize
EMRFS: Acessa S3 como se fosse HDFS
\end_layout

\begin_deeper
\begin_layout Itemize
Visualização consistente EMRFS 
\begin_inset Note Note
status collapsed

\begin_layout Plain Layout
EMRFS você lê dados em S3 como se fosse em HDFS
\end_layout

\end_inset

 - Opcional para consistência S3;
\end_layout

\begin_layout Itemize
Usa DynamoDB para monitorar consistência;
\end_layout

\end_deeper
\begin_layout Itemize
Sistema de arquivos local
\end_layout

\begin_layout Itemize
EBS para HDFS
\end_layout

\begin_layout Itemize
O armazenamento é temporário, então quando você encerrar o cluster os dados
 serão perdidos;
\end_layout

\begin_layout Itemize
Então ele é útil como armazenamento em cache para resultados temporários;
\end_layout

\begin_layout Itemize
Cobrança do EMR por hora
\end_layout

\begin_deeper
\begin_layout Itemize
Mais cobrança EC2
\end_layout

\end_deeper
\begin_layout Itemize
Provê novos nós se um nó central falhar;
\end_layout

\begin_layout Itemize
Pode adicionar e remover nós de tarefas rapidamente;
\end_layout

\begin_layout Itemize
Pode redimensionar os nós centrais de um cluster em execução;
\end_layout

\begin_layout Subsubsection*
Então, o que é Hadoop?
\end_layout

\begin_layout Itemize
O Hadoop é um ecossistema de bigdata.
\end_layout

\begin_layout Itemize
Ele é composto pelos seguintes módulos: 
\end_layout

\begin_deeper
\begin_layout Itemize
Hadoop Core, que tem as bibliotecas e utilitários necessários para os outros
 módulos do Hadoop; 
\end_layout

\begin_layout Itemize
HDFS, sistema de arquivos distribuídos e escalável para Hadoop, ele distribui
 os dados que armazena entre todas as instâncias do cluster.
 Neste caso aqui, o HDFS é não persistente, portanto, se você encerra o
 cluster, os dados são apagados; 
\end_layout

\begin_layout Itemize
Hadoop YARN (Yet Another Resource Negotiator) é um componente para gerenciar
 de forma centralizada os recursos do cluster; 
\end_layout

\begin_layout Itemize
E por fim, o MapReduce, que é uma estrutura de software que permite que
 você crie aplicativos que são capazes de processar grandes volumes de dados,
 em paralelo, em clusters, ao mesmo tempo tolerante à falhas;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Apache Spark
\end_layout

\begin_layout Itemize
O Apache Spark é um sistema de processamento distribuído de código aberto,
 e ele é frequentemente utilizado para processamento de dados;
\end_layout

\begin_layout Itemize
Ele utiliza cache na memória e otimiza a execução das consultas;
\end_layout

\begin_layout Itemize
Com esses elementos, você tem um resultado das análises de maneira mais
 rápido, mesmo com um grande volume de dados sendo processados;
\end_layout

\begin_layout Itemize
Além disso, ele tem APIs, para você desenvolver as suas aplicações em Java,
 Scala, Python e R;
\end_layout

\begin_layout Itemize
Ele suporta a reutilização de código, para vários tipos de tarefas;
\end_layout

\begin_layout Subsubsection*
Como ele é utilizado?
\end_layout

\begin_layout Itemize
Ele pode ser utilizado para o processamento de streaming de dados;
\end_layout

\begin_deeper
\begin_layout Itemize
Por exemplo, ele pode ser utilizado para processar dados em tempo real coletados
 do Amazon Kinesis;
\end_layout

\begin_layout Itemize
Ou do Apache Kafka, ou do Apache Streaming;
\end_layout

\end_deeper
\begin_layout Itemize
A análise do Apache Spark é feita de maneira totalmente tolerante à falhas
 e os resultados são gravados no S3, ou num cluster do HDFS;
\end_layout

\begin_layout Itemize
Com relação ao aprendizado de máquina:
\end_layout

\begin_deeper
\begin_layout Itemize
O Spark inclui o ML Library, ou Machine Learning Library, uma biblioteca
 para fazer aprendizado de máquina em dados de grandes volumes;
\end_layout

\begin_layout Itemize
Ele possui ainda o Spark SQL, que é uma ferramenta de SQL interativo que
 é usado para consultas interativas de baixa latência utilizando linguagem
 SQL ou SQL Hive;
\end_layout

\begin_layout Itemize
Ele não é usado para OLTP, e também não é utilizado para processar dados
 em lote (batch).
 Ele é uma ferramenta para processar dados à medida que os dados são carregados;
\end_layout

\end_deeper
\begin_layout Itemize
Como funciona o Spark?
\end_layout

\begin_deeper
\begin_layout Itemize
Os aplicativos Spark são executados como conjuntos independentes de processos
 em um cluster;
\end_layout

\begin_layout Itemize
Eles são coordenados pelo objeto Spark Context, no programa principal;
\end_layout

\begin_layout Itemize
Logo, a primeira coisa a ser feita quando vamos processar dados utilizando
 o Spark é criar o contexto do Spark;
\end_layout

\begin_layout Itemize
O Spark Context se conecta em diferentes gerenciadores de cluster que alocam
 recursos entre os aplicativos que estão usando os contextos;
\end_layout

\begin_layout Itemize
E quando eles se conectam, o spark adquire executores nos nós que fazem
 parte do cluster;
\end_layout

\begin_layout Itemize
Esses executores são proessos que executam cálculos e armazenam dados para
 os aplicativos que estão executando este código;
\end_layout

\begin_layout Itemize
Na etapa final, o Spark Context envia a tarefa para os executores então
 executarem;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Spark MLLib
\end_layout

\begin_layout Itemize
Classificação: logistic regression, naive bayes;
\end_layout

\begin_layout Itemize
Regressão;
\end_layout

\begin_layout Itemize
Árvore de Decisão;
\end_layout

\begin_layout Itemize
Recommendation engine (ALS);
\end_layout

\begin_layout Itemize
Clustering (K-Means);
\end_layout

\begin_layout Itemize
LDA (topic modeling);
\end_layout

\begin_layout Itemize
Utilitários de fluxo de trabalho de ML (pipelines, transformação de atributos,
 persistência)
\end_layout

\begin_layout Itemize
SVD, PCA, estatísticas;
\end_layout

\begin_layout Subsubsection*
Zeppelin + Spark
\end_layout

\begin_layout Itemize
Pode executar o código do spark interativamente (como no shell do spark);
\end_layout

\begin_layout Itemize
Isso acelera seu ciclo de desenvolvimento;
\end_layout

\begin_layout Itemize
Permite fácil experimentação e exploração de seu big data;
\end_layout

\begin_layout Itemize
Pode executar consultas SQL diretamente no SparkSQL;
\end_layout

\begin_layout Itemize
Os resultados da consulta podem ser visualizados em tabelas e gráficos;
\end_layout

\begin_layout Itemize
Faz com que o Spark pareça mais uma ferramenta de ciência de dados;
\end_layout

\begin_layout Standard
\begin_inset Separator plain
\end_inset


\end_layout

\begin_layout Subsubsection*
EMR Notebook
\end_layout

\begin_layout Itemize
Conceito semelhante ao Zeppelin, com mais integração AWS;
\end_layout

\begin_layout Itemize
Notebooks com backup para S3;
\end_layout

\begin_layout Itemize
Provisione clusters a partir do notebook;
\end_layout

\begin_layout Itemize
Hospedado em um VPC;
\end_layout

\begin_layout Itemize
Acessado apenas por meio do console AWS;
\end_layout

\begin_layout Subsubsection*
Segurança no EMR
\end_layout

\begin_layout Itemize
IAM policies: Concedem ou negam permissão e determinam quais ações um usuário
 pode tomar no EMR, além de outros recursos do AWS.
 Também podemos combinar políticas IAM com tag para controlar o acesso aos
 clusters;
\end_layout

\begin_layout Itemize
Kerberos: É um protocolo de autenticação de rede, que garante que as senhas
 e outras credenciais não sejam enviadas através da rede sem ser criptografadas;
\end_layout

\begin_layout Itemize
SSH: Fornece uma forma segura para os usuários se conectarem por linha de
 comando em instâncias de um cluster.
 Ele também fornece tunelamento para que as interfaces web dos aplicativos
 hospedados no Master Node sejam acessadas;
\end_layout

\begin_layout Itemize
IAM roles: Controla como o EMR pode acessar outros serviços do AWS.
 Cada cluster deve ter uma role de serviço e uma role por perfil de instância
 do EC2, e as políticas de IAM anexadas a essa role fornece permissões para
 o cluster interoperar com outros serviços do AWS e isso vai ser feito com
 o nome do próprio usuário;
\end_layout

\begin_layout Subsubsection*
EMR: Escolhendo os tipos de Instância
\end_layout

\begin_layout Itemize
Master Node:
\end_layout

\begin_deeper
\begin_layout Itemize
m4.large se <50 nós, m4.xlarge se >50 nós;
\end_layout

\end_deeper
\begin_layout Itemize
Core & task nodes:
\end_layout

\begin_deeper
\begin_layout Itemize
m4.large geralmente é suficiente
\end_layout

\begin_layout Itemize
Se o cluster esperar muito por dependências externas (por exemplo um web
 crawler), t2.medium;
\end_layout

\begin_layout Itemize
Desempenho maior: m4.xlarge;
\end_layout

\begin_layout Itemize
Aplicativos de computação intensiva: instâncias com mais CPU;
\end_layout

\begin_layout Itemize
Banco de dados, aplicativos de cache em memória: instâncias com mais memória;
\end_layout

\begin_layout Itemize
Rede/uso intensivo de CPU (NLP, ML) - instâncias de cluster de computador;
\end_layout

\end_deeper
\begin_layout Itemize
Spot Instances
\end_layout

\begin_deeper
\begin_layout Itemize
Bons para nós de tarefa;
\end_layout

\begin_layout Itemize
Use apenas no core & master se você estiver testando ou muito sensível ao
 custo, você está arriscando a perda parcial de dados;
\end_layout

\end_deeper
\begin_layout Subsection
Engenharia de Atributos
\end_layout

\begin_layout Subsubsection*
O que é a Engenharia de Atributos?
\end_layout

\begin_layout Itemize
Aplicar seu conhecimento dos dados - e do modelo que você está usando -
 para criar características melhores para treinar o seu modelo.
\end_layout

\begin_deeper
\begin_layout Itemize
Quais características devo usar?
\end_layout

\begin_layout Itemize
Preciso transformar estas características de alguma forma?
\end_layout

\begin_layout Itemize
Como faço para lidar com dados faltantes?
\end_layout

\begin_layout Itemize
Devo criar novas características a partir das existentes?
\end_layout

\end_deeper
\begin_layout Itemize
Você não pode simplesmente inserir dados brutos e esperar bons resultados;
\end_layout

\begin_layout Itemize
Esta é a arte do aprendizado de máquina, onde a experiência é aplicada;
\end_layout

\begin_layout Subsubsection*
A Maldição da Dimensionalidade
\end_layout

\begin_layout Itemize
Muitas características podem ser um problema - leva a dados esparsos;
\end_layout

\begin_layout Itemize
Cada característica é uma nova dimensão
\end_layout

\begin_layout Itemize
Grande parte da engenharia de atributos é selecionar os atributos mais relevante
s para o problema em questão
\end_layout

\begin_deeper
\begin_layout Itemize
Muitas vezezé aqui que o conhecimento do domínio entra em jogo
\end_layout

\end_deeper
\begin_layout Itemize
Técnicas de redução de dimensionalidade não supervisionadas também podem
 ser empregadas para transformar muitas características em menos características
;
\end_layout

\begin_layout Itemize
PCA;
\end_layout

\begin_layout Itemize
K-Means;
\end_layout

\begin_layout Subsubsection*
Imputando dados ausentes: substituição pela média
\end_layout

\begin_layout Itemize
Substituir os valores ausentes pelo valor médio das colunas (colunas, não
 linhas! Uma coluna representa um único atributo.
 Só faz sentido tirar a média de outras amostras do mesmo atributo);
\end_layout

\begin_layout Itemize
Rápido e fácil, não afeta a média ou o tamanho da amostra do conjunto de
 dados geral;
\end_layout

\begin_layout Itemize
A mediana pode ser uma escolha melhor do que a média quando há outliers;
\end_layout

\begin_layout Itemize
De uma maneira geral pode não ser uma boa ideia:
\end_layout

\begin_deeper
\begin_layout Itemize
Funciona apenas a nível da coluna, perde correlações entre as características;
\end_layout

\begin_layout Itemize
Não pode ser usado em características categóricas (inputar com valor mais
 frequente pode funcionar neste caso, no entando...);
\end_layout

\begin_layout Itemize
Não muito preciso;
\end_layout

\end_deeper
\begin_layout Section
Modelagem
\end_layout

\begin_layout Subsection
Funções de ativação
\end_layout

\begin_layout Itemize
Define a saída de um nó/neurônio de acordo com seus 
\begin_inset Quotes eld
\end_inset

sinais
\begin_inset Quotes erd
\end_inset

 de entrada;
\end_layout

\begin_layout Itemize
A definição da função de ativação é importante, pois diferentes funções
 de ativação podem render performances bastantes diferentes da rede neural;
\end_layout

\begin_layout Itemize
Exemplos de função de ativação impróprias:
\end_layout

\begin_deeper
\begin_layout Itemize
Função de ativação linear;
\end_layout

\begin_deeper
\begin_layout Itemize
Uma rede neural deve ter uma função de ativação não-linear para que possa
 tratar de problemas complexos (não-lineares), se não a função de ativação
 não consegue ser aprimorada.
 Logo, uma função de ativação linear não interfere no resultado da rede
 neural no final;
\end_layout

\begin_layout Itemize
Não pode executar backpropagation;
\end_layout

\end_deeper
\begin_layout Itemize
Binary step function;
\end_layout

\begin_deeper
\begin_layout Itemize
A solução será de ligado ou desligado;
\end_layout

\begin_layout Itemize
Sendo assim, não é possível lidar com múltiplas classes, pois sua natureza
 é completamente binária;
\end_layout

\begin_layout Itemize
Inclinações verticais, elas não funcionam bem quando você precisa realizar
 o backpropagation;
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Em vez disso, precisamos de funções de ativação não-lineares;
\end_layout

\begin_deeper
\begin_layout Itemize
Pois, elas podem criar mapeamentos complexos entre entradas e saídas;
\end_layout

\begin_layout Itemize
Permitem backpropagation, ou seja, a derivada delas possui valor útil;
\end_layout

\begin_layout Itemize
Permite várias camadas, pois funções lineares degeneram em uma única camada;
\end_layout

\end_deeper
\begin_layout Itemize
Algumas funções de ativação não-lineares:
\end_layout

\begin_deeper
\begin_layout Itemize
Sigmoid/tanh;
\end_layout

\begin_deeper
\begin_layout Itemize
Gera 0-1 (sigmoide/logística)
\end_layout

\begin_layout Itemize
-1 a 1 (tanh / tangente hiperbólica)
\end_layout

\begin_layout Itemize
Mas mudam lentamente para valores altos ou baixos;
\end_layout

\begin_deeper
\begin_layout Itemize
Problema do 
\begin_inset Quotes eld
\end_inset

vanishing gradient
\begin_inset Quotes erd
\end_inset

;
\end_layout

\end_deeper
\begin_layout Itemize
Computacionalmente caro;
\end_layout

\begin_layout Itemize
tanh geralmente é preferível em relação à sigmóide;
\end_layout

\end_deeper
\begin_layout Itemize
Rectified Linear Unit (ReLU);
\end_layout

\begin_deeper
\begin_layout Itemize
Muito popular;
\end_layout

\begin_layout Itemize
Fácil e rápida de calcular
\end_layout

\begin_layout Itemize
Mas quando as entradas são zero ou negativas, temos uma função linear e
 consequentemente os mesmo problemas vistos;
\end_layout

\begin_deeper
\begin_layout Itemize
O 
\begin_inset Quotes eld
\end_inset

Dying ReLU problem
\begin_inset Quotes erd
\end_inset

;
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Leaky ReLU;
\end_layout

\begin_deeper
\begin_layout Itemize
Resolve o problema do 
\begin_inset Quotes eld
\end_inset

Dying ReLU
\begin_inset Quotes erd
\end_inset

 introduzindo uma inclinação negativa abaixo de 0 (geralmente não tão íngreme);
\end_layout

\end_deeper
\begin_layout Itemize
Parametric ReLU (PReLU)
\end_layout

\begin_deeper
\begin_layout Itemize
ReLU, mas a inclinação na parte negativa é 
\begin_inset Quotes eld
\end_inset

aprendida
\begin_inset Quotes erd
\end_inset

 por backpropagation;
\end_layout

\begin_layout Itemize
Pode ser bastante complicada;
\end_layout

\end_deeper
\begin_layout Itemize
Outras variações de ReLU;
\end_layout

\begin_deeper
\begin_layout Itemize
Exponential Linear Unit (ELU);
\end_layout

\begin_layout Itemize
Swish;
\end_layout

\begin_deeper
\begin_layout Itemize
Do Google, tem um desempenho muito bom;
\end_layout

\begin_layout Itemize
Mas é do Google, não da Amazon;
\end_layout

\begin_layout Itemize
Traz benefício com redes muito profundas (mais de 40 camadas);
\end_layout

\end_deeper
\begin_layout Itemize
Maxout;
\end_layout

\begin_deeper
\begin_layout Itemize
Produz o máximo das entradas;
\end_layout

\begin_layout Itemize
Tecnicamente, ReLU é um caso especial da maxout;
\end_layout

\begin_layout Itemize
Mas duplica os parâmetros que precisam ser treinados, muitas vezes ela não
 é viável;
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Softmax;
\end_layout

\begin_deeper
\begin_layout Itemize
Usado na camada de saída (final) de um problema de classificação múltipla;
\end_layout

\begin_layout Itemize
Converte basicamente os resultados em probabilidades para cada classificação;
\end_layout

\begin_layout Itemize
Não é possível produzir mais de um rótulo para algo (sigmóide pode);
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Escolhendo uma função de ativação;
\end_layout

\begin_deeper
\begin_layout Itemize
Para classificação múltipla, use softmax na camada de saída;
\end_layout

\begin_layout Itemize
RNN's se 
\begin_inset Quotes eld
\end_inset

dão bem
\begin_inset Quotes erd
\end_inset

 com tanh;
\end_layout

\begin_layout Itemize
Para todas as outras:
\end_layout

\begin_deeper
\begin_layout Itemize
Comece com ReLU;
\end_layout

\begin_layout Itemize
Para tentar melhorar, experimente Leaky ReLU;
\end_layout

\begin_layout Itemize
Último recurso: PReLU, Maxout;
\end_layout

\begin_layout Itemize
Swish para redes realmente profundas;
\end_layout

\end_deeper
\end_deeper
\begin_layout Subsection
Redes Neurais Convolucionais
\end_layout

\begin_layout Subsubsection*
CNN's: Para que servem?
\end_layout

\begin_layout Itemize
Quando você tem dados que não se alinham perfeitamente em colunas;
\end_layout

\begin_deeper
\begin_layout Itemize
Imagens nas quais você deseja encontrar características;
\end_layout

\begin_layout Itemize
Tradução;
\end_layout

\begin_layout Itemize
Classificação de sentenças;
\end_layout

\end_deeper
\begin_layout Itemize
Podem encontrar características que não estão em um local específico;
\end_layout

\begin_deeper
\begin_layout Itemize
Como uma placa de pare em uma foto;
\end_layout

\begin_layout Itemize
Ou palavras dentro de uma frase;
\end_layout

\end_deeper
\begin_layout Itemize
São 
\begin_inset Quotes eld
\end_inset

invariáveis na localização de características
\begin_inset Quotes erd
\end_inset

;
\end_layout

\begin_layout Itemize
Inspirado na biologia do córtex visual;
\end_layout

\begin_deeper
\begin_layout Itemize
Os campos receptivos locais são grupos de neurônios que respondem apenas
 a uma parte do que seus olhos veem (sub-amostragem);
\end_layout

\begin_layout Itemize
Eles se sobrepõem para cobrir todo o campo visual (convoluções);
\end_layout

\begin_layout Itemize
Eles alimentam camadas superiores que identificam imagens cada vez mais
 complexas;
\end_layout

\begin_deeper
\begin_layout Itemize
Alguns campos receptivos identificam linhas horizontais, linhas em ângulos
 diferentes, etc.
 (que são os filtros);
\end_layout

\begin_layout Itemize
Eles alimentariam uma camada que identifica as formas;
\end_layout

\begin_layout Itemize
Que pode alimentar uma camada que identifica objetos;
\end_layout

\end_deeper
\begin_layout Itemize
Para imagens coloridas, camadas extras para vermelho, verde e azul;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Como sabemos que é um sinal de pare?
\end_layout

\begin_layout Itemize
Campos receptivos locais individuais examinam a imagem procurando bordas
 e colocam as bordas do sinal de parada em uma camada;
\end_layout

\begin_layout Itemize
Essas bordas, por sua vez, são captada por uma convolução de nível superior
 que identifica a forma do sinal de Pare (e as letras também);
\end_layout

\begin_layout Itemize
Esta forma, então, é comparada ao padrão de como é um sinal de parada, também
 usando o sinal vermelho forte proveniente de suas camadas vermelhas;
\end_layout

\begin_layout Itemize
Essas informações continuam sendo processadas em níveis superiores até que
 seu pé pise no freio!
\end_layout

\begin_layout Itemize
Uma CNN funciona da mesma forma;
\end_layout

\begin_layout Subsubsection*
CNN's com Keras/Tensorflow
\end_layout

\begin_layout Itemize
Os dados de origem devem ter dimensões adequadas;
\end_layout

\begin_deeper
\begin_layout Itemize
Ou seja, largura x comprimento x canais de cores
\end_layout

\end_deeper
\begin_layout Itemize
O tipo de camada Conv2D faz a convolução real em uma imagem 2D;
\end_layout

\begin_deeper
\begin_layout Itemize
Conv1D e Conv3D também estão disponíveis - não precisam ser dados de imagens
\end_layout

\end_deeper
\begin_layout Itemize
Camadas MaxPooling2D podem ser usadas para reduzir uma camada 2D pegando
 o valor máximo em um determinado bloco;
\end_layout

\begin_layout Itemize
As camadas 
\begin_inset Quotes eld
\end_inset

Flatten
\begin_inset Quotes erd
\end_inset

 irão converter uma camada 2D em uma camada 1D para passar em uma camada
 de vetor oculta de neurônios;
\end_layout

\begin_layout Itemize
Uso típico:
\end_layout

\begin_deeper
\begin_layout Itemize
Conv2D -> MaxPooling2D -> Dropout -> Flatten -> Dense -> Dropout -> Softmax;
\end_layout

\end_deeper
\begin_layout Subsubsection*
CNNs são difíceis
\end_layout

\begin_layout Itemize
Consome muitos recursos (CPU, GPU e RAM);
\end_layout

\begin_layout Itemize
Muitos hiperparâmetros;
\end_layout

\begin_deeper
\begin_layout Itemize
Kernel sizes, muitas camadas com diferentes números de unidades, quantidade
 de pooling...
 além das coisas usuais como número de camadas, escolha do otimizador;
\end_layout

\end_deeper
\begin_layout Itemize
Obter os dados de treinamento costuma ser a parte mais difícil, bem como
 armazená-lo e acessá-lo;
\end_layout

\begin_layout Subsubsection*
Arquiteturas CNN especializadas
\end_layout

\begin_layout Itemize
Define o arranjo específico de camadas, preenchimento e hiperparâmetros;
\end_layout

\begin_layout Itemize
LeNet-5;
\end_layout

\begin_deeper
\begin_layout Itemize
Bom para reconhecimento de escrita;
\end_layout

\end_deeper
\begin_layout Itemize
AlexNet;
\end_layout

\begin_deeper
\begin_layout Itemize
Classificação de imagem, mais profunda do que o LeNet;
\end_layout

\end_deeper
\begin_layout Itemize
GoogLeNet;
\end_layout

\begin_deeper
\begin_layout Itemize
Ainda mais profundo, mas com melhor desempenho;
\end_layout

\begin_layout Itemize
Apresenta módulos de iniciação (grupos de camadas de convolução);
\end_layout

\end_deeper
\begin_layout Itemize
ResNet (rede residual);
\end_layout

\begin_deeper
\begin_layout Itemize
Ainda mais profundo - mantém o desempenho por meio skip connections;
\end_layout

\end_deeper
\begin_layout Subsection
Redes neurais recorrentes e LSTM
\end_layout

\begin_layout Subsubsection*
RNN's: Para que servem?
\end_layout

\begin_layout Itemize
Dados de série temporal;
\end_layout

\begin_deeper
\begin_layout Itemize
Quando você deseja prever o comportamento futuro com base no comportamento
 do passado;
\end_layout

\begin_layout Itemize
Logs da web, logs de sensores, negociações de ações;
\end_layout

\begin_layout Itemize
Onde dirigir seu carro autônomo com base em trajetórias anteriores;
\end_layout

\end_deeper
\begin_layout Itemize
Dados que consistem em sequências de comprimento arbitrário;
\end_layout

\begin_deeper
\begin_layout Itemize
Tradução;
\end_layout

\begin_layout Itemize
Legendas de imagens;
\end_layout

\begin_layout Itemize
Música gerada por máquina;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Neurônio Recorrente
\end_layout

\begin_layout Itemize
Um neurônio recorrente é muito similar ao neurônio visto anteriormente;
\end_layout

\begin_layout Itemize
A grande diferença está no laço que liga o neurônio com ele mesmo;
\end_layout

\begin_layout Itemize
Então, conforme executamos uma estapa de treinamento neste neurônio, alguns
 dados de treinamento são inseridos nesse neurônio, ou talvez uma entrada
 de uma camada anterior da nossa rede neural;
\end_layout

\begin_layout Itemize
Normalmente, é apenas gerado o resultado de saída da função de ativação
 desse neurônio, mas o neurônio recorrente permite que o alimentemos novamente
 com esse dado de saída, então da próxima vez que os dados forem processados
 através deste neurônio, então os dados da execução anterior também são
 somados nos resultados como uma entrada extra;
\end_layout

\begin_layout Itemize
Então, a medida que continuamos executando esse processamento de forma contínua,
 teremos alguns novos dados chegando que serão combinados com a saída anterior
 deste neurônio e isso ocorre continuamente;
\end_layout

\begin_layout Itemize
Logo, o passado nesse neurônio influência o futuro de como esse neurônio
 aprende;
\end_layout

\begin_layout Subsubsection*
Célula de memória
\end_layout

\begin_layout Itemize
Outra forma também de aplicar esse tipo de arquitetura é utilizando células
 de memória;
\end_layout

\begin_layout Itemize
Uma célula de memória, é um neurônio que inicia com uma entrada e que produz
 duas saídas;
\end_layout

\begin_deeper
\begin_layout Itemize
Uma saída alimenta a rede neural e a outra saída alimenta este neurônio
 no próximo passo, que pode ser interpretado como um tempo futuro;
\end_layout

\begin_layout Itemize
Então o neurônio que recebeu a informação do neurônio no tempo passado,
 passará a receber duas entradas, uma referente aos dados de entrada de
 processamento e outra referente à saída do neurônio do tempo passado, com
 isso ele produzirá mais duas saídas, uma para alimentar a rede neural e
 outra como entrada para este mesmo neurônio em um outro tempo futuro;
\end_layout

\begin_layout Itemize
Este processo ocorre de maneira contínua e recorrente;
\end_layout

\begin_layout Itemize
Ela é chamada de célula de memória pois mantém a sua memória com o passar
 do tempo do processamento;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Uma camada de neurônios recorrentes
\end_layout

\begin_layout Itemize
De maneira similar, então você pode construir uma camada de neurônios recorrente
s;
\end_layout

\begin_layout Itemize
Onde essa camada possui duas saídas, uma para alimentar o resto da rede
 neural e outra para alimentar novamente a camada de neurônios;
\end_layout

\begin_layout Subsubsection*
Topologias de RNN
\end_layout

\begin_layout Itemize
Sequência para sequência;
\end_layout

\begin_deeper
\begin_layout Itemize
Ou seja, preveja os preços das ações com base em uma série de dados históricos;
\end_layout

\end_deeper
\begin_layout Itemize
Sequência para vetor;
\end_layout

\begin_deeper
\begin_layout Itemize
Ou seja, palavras em uma frase para sentimento;
\end_layout

\end_deeper
\begin_layout Itemize
Vetor para sequência;
\end_layout

\begin_deeper
\begin_layout Itemize
Ou seja, criar legendas a partir de uma imagem;
\end_layout

\end_deeper
\begin_layout Itemize
Codificador -> Decodificador;
\end_layout

\begin_deeper
\begin_layout Itemize
Sequência -> Vetor -> Sequência;
\end_layout

\begin_layout Itemize
Ou seja, tradução automática;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Treinando RNN
\end_layout

\begin_layout Itemize
Backpropagation através do tempo;
\end_layout

\begin_deeper
\begin_layout Itemize
Assim como a backpropagation em MLPs, mas aplicada a cada etapa de tempo;
\end_layout

\end_deeper
\begin_layout Itemize
Todas essas etapas de tempo aumentam rapidamente;
\end_layout

\begin_deeper
\begin_layout Itemize
Acaba parecendo uma rede neural muito, muito profunda;
\end_layout

\begin_layout Itemize
Pode limitar a backpropagation a um número limitado de estapas de tempo
 (Backpropagation truncada ao longo do tempo);
\end_layout

\end_deeper
\begin_layout Itemize
Estado de etapas de tempo anteriores se dilui ao longo do tempo;
\end_layout

\begin_deeper
\begin_layout Itemize
Isso pode ser um problema, por exemplo, ao aprender estruturas de frases;
\end_layout

\end_deeper
\begin_layout Itemize
Célula LSTM;
\end_layout

\begin_deeper
\begin_layout Itemize
(Long Short-Term Memory Cell) Célula de Memória Longa de Curto Prazo;
\end_layout

\begin_layout Itemize
Mantém estados separados de curto e longo prazo;
\end_layout

\end_deeper
\begin_layout Itemize
Célula GRU;
\end_layout

\begin_deeper
\begin_layout Itemize
Unidade recorrente bloqueada - Gated Recurrent Unit;
\end_layout

\begin_layout Itemize
Célula LSTM simplificada com desempenho quase igual;
\end_layout

\end_deeper
\begin_layout Itemize
É realmente difícil;
\end_layout

\begin_deeper
\begin_layout Itemize
Muito sensível a topologias, escolha de hiperparâmetros;
\end_layout

\begin_layout Itemize
Uso intensivo de recursos;
\end_layout

\begin_layout Itemize
Uma escolha errada pode levar a uma RNN que não converge;
\end_layout

\end_deeper
\begin_layout Subsection
Deep Learning no EC2/EMR
\end_layout

\begin_layout Itemize
EMR é compatível com Apache MXNet e tipos de instância GPU;
\end_layout

\begin_layout Itemize
Tipos de instância apropriados para aprendizado profundo:
\end_layout

\begin_deeper
\begin_layout Itemize
P3: 8 GPUs Tesla V100;
\end_layout

\begin_layout Itemize
P2: 16 GPUs K80;
\end_layout

\begin_layout Itemize
G3: 4GPUs M60 (todos os chips Nvidia);
\end_layout

\end_deeper
\begin_layout Itemize
Deep Learning AMI's (TensorFlow, PyTorch, Apache MXNet, Chainer, Gluon e
 Keras);
\end_layout

\begin_deeper
\begin_layout Itemize
Não tem custo adicional;
\end_layout

\end_deeper
\begin_layout Itemize
Sagemaker;
\end_layout

\begin_layout Subsection
Tuning de redes neurais
\end_layout

\begin_layout Subsubsection*
Taxa de aprendizagem (Learning Rate)
\end_layout

\begin_layout Itemize
As redes neurais são treinadas por gradiente descent (ou técnicas semelhantes);
\end_layout

\begin_layout Itemize
Começamos em algum ponto aleatório, e amostramos soluções diferentes (pesos)
 buscando minimizar alguma função de custo, ao longo de muitas epochs;
\end_layout

\begin_layout Itemize
A distância entre essas amostras é a taxa de aprendizagem;
\end_layout

\begin_layout Subsubsection*
Efeito da taxa de aprendizagem
\end_layout

\begin_layout Itemize
Uma taxa de aprendizado muito alta significa que você pode ultrapassar a
 solução ideal;
\end_layout

\begin_layout Itemize
Uma taxa de aprendizado muito pequena demorará muito para encontrar a solução
 ideal;
\end_layout

\begin_layout Itemize
A taxa de aprendizagem é um exemplo de um hiperparâmetro;
\end_layout

\begin_layout Subsubsection*
Batch size
\end_layout

\begin_layout Itemize
Define quantas amostras de treinamento são usada em cada epoch;
\end_layout

\begin_layout Itemize
Um tanto contra-intuitivo:
\end_layout

\begin_deeper
\begin_layout Itemize
Batch size pequenos podemo ultrapassar os 
\begin_inset Quotes eld
\end_inset

mínimos locais
\begin_inset Quotes erd
\end_inset

 mais facilmente;
\end_layout

\begin_layout Itemize
Batch size muito grandes podem acabar ficando presos na solução errada;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Para recapitular
\end_layout

\begin_layout Itemize
Batch sizes pequenos tendem a não ficar presos nos mínimos locais;
\end_layout

\begin_layout Itemize
Batch sizes grandes podem convergir para a solução errada aleatoriamente;
\end_layout

\begin_layout Itemize
Grandes taxas de aprendizagem podem ultrapassar a solução correta;
\end_layout

\begin_layout Itemize
Pequenas taxas de aprendizagem aumentam o tempo de treinamento;
\end_layout

\begin_layout Subsection
Técnicas de regularização
\end_layout

\begin_layout Subsubsection*
O que é regularização?
\end_layout

\begin_layout Itemize
Prevenindo o overfitting;
\end_layout

\begin_deeper
\begin_layout Itemize
Modelos que são bons em fazer previsões sobre os dados em que foram treinados,
 mas não sobre novos dados que não tenham visto antes;
\end_layout

\begin_layout Itemize
Modelos superdimensionados aprenderam padrões nos dados de treinamento que
 não se generalizam para o mundo real;
\end_layout

\begin_layout Itemize
Frequentemente visto como alta precisão no conjunto de dados de treinamento,
 mas menor precisão no conjunto de dados de teste ou avaliação;
\end_layout

\begin_deeper
\begin_layout Itemize
Ao treinar e avaliar um modelo, usamos conjunto de dados de treinamento,
 avaliação e teste;
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
As técnicas de regularização têm como objetivo evitar o overfitting;
\end_layout

\begin_layout Subsubsection*
Algumas técnicas de regularização
\end_layout

\begin_layout Itemize
Simplificação do modelo:
\end_layout

\begin_deeper
\begin_layout Itemize
Muitas vezes um modelo pode estar sendo construído de uma maneira muito
 mais complexa do que deveria ser, por um exemplo, imagine que numa rede
 neural nós temos centenas de camadas ocultas e cada comada oculta possui
 milhares de neurônios, tudo isso para obter um simples modelo de classificação
 binária que poderia ser feito utilizando uma árvore de decisão;
\end_layout

\begin_layout Itemize
É claro que isso é uma maneira um tanto quanto exagerada de expor o problema
 e na vida real, a linha entre o quão complexo e o mínimo de simplificação
 que ele tem que ter para ser eficiente não é tão evidente.
 Mas num caso como esse, diminuir o número de camadas e o número de neurônios
 por camada pode ajudar e muito em reduzir as chances de o modelo superajustar;
\end_layout

\begin_layout Itemize
Isso porque reduzir a complexidade do modelo também reduz as chances de
 ele aprender padrões complexos (lê-se ruídos) da base de treinamento;
\end_layout

\end_deeper
\begin_layout Itemize
Dropout:
\end_layout

\begin_deeper
\begin_layout Itemize
O dropout é uma técnica que remove neurônios da sua rede de maneira completament
e aleatória;
\end_layout

\begin_layout Itemize
Isso força a sua rede neural a aprender padrões genéricos da base de dados,
 pois diminui a possibilidade de algum desses neurônios aprenderem padrões
 específicos (provavelmente associados a ruídos) da base de treinamento;
\end_layout

\end_deeper
\begin_layout Itemize
Parada Antecipada;
\end_layout

\begin_deeper
\begin_layout Itemize
O que podemos observar no treinamento de uma rede neural é que ao decorrer
 das suas epochs, as suas métricas de classificação podem acabar por estabilizar
 em um valor específico, sem apresentar melhoras reais com novos treinamentos;
\end_layout

\begin_layout Itemize
Nesses casos, você continuar o treinamento pode acarretar em problemas para
 o seu algoritmo, pois este pode acabar por gerar um modelo superajustado;
\end_layout

\end_deeper
\begin_layout Subsection
Gradientes
\end_layout

\begin_layout Itemize
Apenas recordando, uma rede neural ela funciona através do ajuste de pesos,
 então num processo de treinamento os dados passam pela rede neural, as
 funções de ativação vão produzir valores e na camada de saída, uma loss
 function vai calcular o erro e esse erro vai ser propagado de volta e neste
 processo de propagação, os pesos devem ser ajustados;
\end_layout

\begin_layout Itemize
Os pesos eles devem ser ajustados de quê forma? Mais ou menos? Qual é o
 valor do ajuste?
\end_layout

\begin_layout Itemize
Nesse aspecto, o gradiente descendente tem um papel fundamental, pois ele
 vai responder essa pergunta;
\end_layout

\begin_layout Subsubsection*
O problema do 
\begin_inset Quotes eld
\end_inset

Vanishing Gradient
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
Quando a inclinação da curva de aprendizado se aproxima de zero, o processamento
 pode 
\begin_inset Quotes eld
\end_inset

travar
\begin_inset Quotes erd
\end_inset

;
\end_layout

\begin_layout Itemize
Acabamos trabalhando com números muito pequenos que tornam o treinamento
 mais lento, ou mesmo introduzem erros numéricos;
\end_layout

\begin_layout Itemize
Torna-se um problema com redes mais profundas e RNNs à medida que se propagam
 para camadas mais profundas;
\end_layout

\begin_layout Itemize
Problema oposto: 
\begin_inset Quotes eld
\end_inset

exploding gradients
\begin_inset Quotes erd
\end_inset

;
\end_layout

\begin_layout Subsubsection*
Corrigindo o problema do 
\begin_inset Quotes eld
\end_inset

Vanishing Gradient
\begin_inset Quotes erd
\end_inset


\end_layout

\begin_layout Itemize
Hierarquia multinível;
\end_layout

\begin_deeper
\begin_layout Itemize
Divida em níveis com suas próprias sub-redes, treinando individualmente;
\end_layout

\end_deeper
\begin_layout Itemize
Long Short-Term Memory (LSTM);
\end_layout

\begin_layout Itemize
Residual Networks;
\end_layout

\begin_deeper
\begin_layout Itemize
ResNet;
\end_layout

\begin_layout Itemize
Conjunto de redes mais curtas;
\end_layout

\end_deeper
\begin_layout Itemize
Melhor escolha da função de ativação;
\end_layout

\begin_deeper
\begin_layout Itemize
ReLU é uma boa escolha;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Verificação de gradiente
\end_layout

\begin_layout Itemize
Uma técnica de depuração;
\end_layout

\begin_layout Itemize
Verifica numericamente as derivadas calculadas durante o treinamento;
\end_layout

\begin_layout Itemize
Útil para validar o código de treinamento de rede neural;
\end_layout

\begin_deeper
\begin_layout Itemize
Mas provavelmente você não vai querer escrever este código;
\end_layout

\end_deeper
\begin_layout Subsection
Regularização L1 e L2
\end_layout

\begin_layout Subsubsection*
O que é?
\end_layout

\begin_layout Itemize
Prevenir overfitting em ML em geral;
\end_layout

\begin_layout Itemize
Um 
\begin_inset Quotes eld
\end_inset

termo
\begin_inset Quotes erd
\end_inset

 de regularização é adicionado à medida que os pesos são aprendidos;
\end_layout

\begin_layout Itemize
O termos L1 é a soma dos pesos
\begin_inset Formula 
\begin{equation}
\lambda\sum_{i=1}^{k}\left|w_{i}\right|,
\end{equation}

\end_inset


\end_layout

\begin_layout Itemize
O termo L2 é a soma do quadrado dos pesos
\begin_inset Formula 
\begin{equation}
\lambda\sum_{i=1}^{k}w_{i}^{2},
\end{equation}

\end_inset

 
\end_layout

\begin_layout Itemize
A mesma ideia pode ser aplicada a funções de perda;
\end_layout

\begin_layout Subsubsection*
Qual é a diferença?
\end_layout

\begin_layout Itemize
L1: soma dos pesos
\end_layout

\begin_deeper
\begin_layout Itemize
Executa a seleção de atributos - atributos inteiros vão para 0;
\end_layout

\begin_layout Itemize
Computacionalmente ineficiente;
\end_layout

\begin_layout Itemize
Saída esparsa;
\end_layout

\end_deeper
\begin_layout Itemize
L2: soma do quadrado dos pesos
\end_layout

\begin_deeper
\begin_layout Itemize
Todos os atributos permanecem, são apenas podenrados;
\end_layout

\begin_layout Itemize
Computacionalmente eficiente;
\end_layout

\begin_layout Itemize
Saída densa;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Por que você iria usar o L1?
\end_layout

\begin_layout Itemize
A seleção de atributos pode reduzir a dimensionalidade;
\end_layout

\begin_deeper
\begin_layout Itemize
De 100 atributos, talvez apenas 10 acabem com coeficientes diferentes de
 zero;
\end_layout

\begin_layout Itemize
A dispersão resultante pode compesar sua ineficiência computacional;
\end_layout

\end_deeper
\begin_layout Itemize
Mas se você acha que todos os seus recursos são importantes, L2 é provavelmente
 é uma escolha melhor;
\end_layout

\begin_layout Subsection
Matriz de confusão
\end_layout

\begin_layout Subsubsection*
Às vezes, precisão não mostra tudo
\end_layout

\begin_layout Itemize
Um teste para uma doença rara pode ter 99.9% de precisão, bastando adivinhar
 
\begin_inset Quotes eld
\end_inset

não
\begin_inset Quotes erd
\end_inset

 o tempo todo;
\end_layout

\begin_layout Itemize
Precisamos entender os verdadeiros positivos e verdadeiros negativos, bem
 como os falsos positivos e falsos negativos;
\end_layout

\begin_layout Itemize
Uma matriz de confusão mostra isso.
\end_layout

\begin_layout Subsubsection*
Matriz de confusão binária
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename confusion_matrix.png

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Matriz de confusão binária.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsubsection*
Matriz de confusão multiclasse + heatmap
\end_layout

\begin_layout Standard
\begin_inset Float figure
wide false
sideways false
status open

\begin_layout Plain Layout
\begin_inset Graphics
	filename multiclass_matrix.png

\end_inset


\end_layout

\begin_layout Plain Layout
\begin_inset Caption Standard

\begin_layout Plain Layout
Matriz de confusão multiclasse visualizada a partir de um heatmap.
\end_layout

\end_inset


\end_layout

\end_inset


\end_layout

\begin_layout Subsection
Métricas de classificação
\end_layout

\begin_layout Subsubsection*
Recall ou Sensibilidade
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\frac{\text{Verdadeiros Positivos}}{\text{Verdadeiros Positivos}+\text{Falsos Negativos}}
\]

\end_inset

 
\end_layout

\begin_layout Itemize
Sensbilidade, taxa de verdadeiro positivo, integridade;
\end_layout

\begin_layout Itemize
Porcentagem de positivos previstos corretamente;
\end_layout

\begin_layout Itemize
Boa escolha de métrica quando você se preocupa muito com falsos negativos;
\end_layout

\begin_deeper
\begin_layout Itemize
Ou seja, detecção de fraude;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Precision/Precisão
\end_layout

\begin_layout Standard
\begin_inset Formula 
\[
=\frac{\text{Verdadeiros Positivos}}{\text{Verdadeiros Positivos}+\text{Falsos Positivos}}
\]

\end_inset


\end_layout

\begin_layout Itemize
Positivos corretos;
\end_layout

\begin_layout Itemize
Porcentagem de resultados relevantes
\end_layout

\begin_layout Itemize
Boa escolha de métrica quando você se preocupa muito com falsos positivos;
\end_layout

\begin_deeper
\begin_layout Itemize
Ou seja, triagem médica, teste de drogas;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Outras métricas
\end_layout

\begin_layout Itemize
Especificidade
\begin_inset Formula 
\[
=\frac{\text{VN}}{\text{VN}+\text{FP}}=\text{”Taxa de verdadeiros negativos”}
\]

\end_inset


\end_layout

\begin_layout Itemize
F1-Score
\begin_inset Formula 
\[
\frac{2\text{VP}}{2\text{VP}+\text{FP}+\text{FN}}=2\frac{\text{Precisão}\times\text{Recall}}{\text{Precisão}+\text{Recall}}
\]

\end_inset


\end_layout

\begin_deeper
\begin_layout Itemize
Média harmônica de precisão e sensibilidade;
\end_layout

\begin_layout Itemize
Quando você se preocupa com precisão e recall;
\end_layout

\end_deeper
\begin_layout Itemize
RMSE
\end_layout

\begin_deeper
\begin_layout Itemize
Raiz do erro quadrático médio;
\end_layout

\begin_layout Itemize
Medição de precisão;
\end_layout

\begin_layout Itemize
Só se preocupa com as respostas certas e erradas;
\end_layout

\end_deeper
\begin_layout Itemize
Curva ROC
\end_layout

\begin_deeper
\begin_layout Itemize
Receiver Operating Characteristic Curve (Curva de Característica de Operação
 do Receptor);
\end_layout

\begin_layout Itemize
Gráfico da taxa de verdadeiro positivo (recall) vs taxa de falso positivo
 em várias configurações;
\end_layout

\begin_layout Itemize
Os pontos acima da diagonal representam uma boa classificação (melhor do
 que aleatória);
\end_layout

\begin_layout Itemize
A curva ideal seria apenas um ponto no canto superior esquerdo;
\end_layout

\begin_layout Itemize
Quanto mais 
\begin_inset Quotes eld
\end_inset

dobrado
\begin_inset Quotes erd
\end_inset

 em direção ao canto superior esquerdo, melhor;
\end_layout

\end_deeper
\begin_layout Itemize
Curva AUC
\end_layout

\begin_deeper
\begin_layout Itemize
A área sob a curva ROC - Area Under the Curve (AUC);
\end_layout

\begin_layout Itemize
Probabilidade de um classificador classificar uma instância positiva escolhida
 aleatoriamente melhor do que uma negativa escolhida aleatoriamente;
\end_layout

\begin_layout Itemize
ROC AUC de 0.5 é um classificador inútil, já 1.0 é perfeito.
\end_layout

\begin_layout Itemize
Métrica comumente usada pra comparar classificadores;
\end_layout

\end_deeper
\begin_layout Subsection
Ensemble Learning
\end_layout

\begin_layout Subsubsection*
Métodos de grupo
\end_layout

\begin_layout Itemize
Exemplo comum: floresta aleatória.
\end_layout

\begin_deeper
\begin_layout Itemize
Árvores de decisão são propensas a overfitting;
\end_layout

\begin_layout Itemize
Então, faça várias árvores de decisão e deixe que todos votem no resultado;
\end_layout

\begin_layout Itemize
Esta é uma floresta aleatória;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Bagging
\end_layout

\begin_layout Itemize
Gere N novos conjuntos de treinamento por amostragem aleatória com reposição;
\end_layout

\begin_layout Itemize
Cada modelo reamostrado pode ser treinado em paralelo;
\end_layout

\begin_layout Subsubsection*
Boosting
\end_layout

\begin_layout Itemize
As observações são ponderadas;
\end_layout

\begin_layout Itemize
Alguns participarão de novos conjuntos de treinamento com mais frequência;
\end_layout

\begin_layout Itemize
O treinamento é sequencial;
\end_layout

\begin_layout Itemize
Cada classificador leva em consideração o sucesso do anterior;
\end_layout

\begin_layout Subsubsection*
Bagging vs Boosting
\end_layout

\begin_layout Itemize
Boosting:
\end_layout

\begin_deeper
\begin_layout Itemize
XGBoost é a 
\begin_inset Quotes eld
\end_inset

última moda
\begin_inset Quotes erd
\end_inset

;
\end_layout

\begin_layout Itemize
Boosting geralmlente produz melhor precisão;
\end_layout

\end_deeper
\begin_layout Itemize
Bagging
\end_layout

\begin_deeper
\begin_layout Itemize
Evita overfitting;
\end_layout

\begin_layout Itemize
Mais fácil de paralelizar;
\end_layout

\end_deeper
\begin_layout Itemize
Então, depende do seu objetivo;
\end_layout

\begin_layout Subsection
Amazon SageMaker
\end_layout

\begin_layout Subsubsection*
O SageMaker foi desenvolvido para lidar com todo o workflow de ML
\end_layout

\begin_layout Itemize
Implantar modelo, avaliar resultados na produção;
\end_layout

\begin_layout Itemize
Buscar, limpar e preparar os dados;
\end_layout

\begin_layout Itemize
Treine e avalie um modelo;
\end_layout

\begin_layout Subsubsection*
Treinamento e implantação do SageMaker
\end_layout

\begin_layout Itemize
Em termos de arquitetura, como isso funcionará?
\end_layout

\begin_deeper
\begin_layout Itemize
Você vai ter dados de treinamento, que eles devem estar no S3 do Amazon;
\end_layout

\begin_layout Itemize
Você vai ter o treinamento do seu modelo a partir dos dados de treinamento;
\end_layout

\begin_layout Itemize
O código de treinamento deste modelo vai estar no ECR (Elastic Container
 Register), que vem num container em Docker;
\end_layout

\begin_layout Itemize
Uma vez o modelo treinado, você vai fazer o deploy deste modelo, e ele também
 vai ficar no S3, os artefatos desse modelo estará no S3;
\end_layout

\begin_layout Itemize
Então, você pode fazer a implantação e hospedagem desse modelo e aí você
 vai ter lá seu código de previsão, que também vai vir de um container em
 docker;
\end_layout

\begin_layout Itemize
Uma vez implantado, o modelo estará pronto para servir uma aplicação do
 cliente via endpoint;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Notebooks SageMaker podem direcionar o processo
\end_layout

\begin_layout Itemize
Instâncias de notebook no EC2 são executadas a partir do console;
\end_layout

\begin_deeper
\begin_layout Itemize
Acesso a dados S3;
\end_layout

\begin_layout Itemize
Scikit_learn, Spark, Tensorflow;
\end_layout

\begin_layout Itemize
Grande variedade de modelos integrados;
\end_layout

\begin_layout Itemize
Capacidade de acelerar instâncias de treinamento;
\end_layout

\begin_layout Itemize
Capacidade de implantar modelos treinados para fazer previsões em escala;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Preparação de dados no SageMaker
\end_layout

\begin_layout Itemize
Os dados devem vir do S3;
\end_layout

\begin_deeper
\begin_layout Itemize
O formato ideal varia com o algoritmo
\end_layout

\begin_deeper
\begin_layout Itemize
Geralmente é RecordIO/Protobuf
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Apache Spark integra-se ao SageMaker
\end_layout

\begin_layout Itemize
Scikit_learn, numpy, pandas, tudo à sua disposição dentro de um notebook;
\end_layout

\begin_layout Subsubsection*
Treinamento em SageMaker
\end_layout

\begin_layout Itemize
Crie um job de treinamento;
\end_layout

\begin_deeper
\begin_layout Itemize
URL do bucket S3 com dados de treinamento;
\end_layout

\begin_layout Itemize
Recursos de computação de ML;
\end_layout

\begin_layout Itemize
URL do bucket S3 para saída;
\end_layout

\begin_layout Itemize
Caminho ECR para o código de treinamento;
\end_layout

\end_deeper
\begin_layout Itemize
Opções de treinamento;
\end_layout

\begin_deeper
\begin_layout Itemize
Algoritmos de treinamento integrados;
\end_layout

\begin_layout Itemize
Spark MLLib
\end_layout

\begin_layout Itemize
Código Python Tensorflow/MXNet personalizado;
\end_layout

\begin_layout Itemize
Sua própria imagem do Docker;
\end_layout

\begin_layout Itemize
Algoritmo adquirido do Marketplace do AWS;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Impantando modelos treinados
\end_layout

\begin_layout Itemize
Salve seu modelo treinado no S3;
\end_layout

\begin_layout Itemize
Pode implantar de duas maneiras:
\end_layout

\begin_deeper
\begin_layout Itemize
Endpoint persistente para fazer previsões individuais sob demanda;
\end_layout

\begin_layout Itemize
SageMaker Batch Transform para obter previsões para todo um conjunto de
 dados;
\end_layout

\end_deeper
\begin_layout Itemize
Muitas opções legais:
\end_layout

\begin_deeper
\begin_layout Itemize
Pipelines de inferência para processamento mais complexo;
\end_layout

\begin_layout Itemize
SageMaker Neo para implantação em dispositivos na ponta;
\end_layout

\begin_layout Itemize
Elastic Inference para acelerar modelos de aprendizado profundo;
\end_layout

\begin_layout Itemize
Escalonamento automático (aumente o número de endpoints conforme necessário);
\end_layout

\end_deeper
\begin_layout Subsection
Algoritmos integrados do SageMaker
\end_layout

\begin_layout Subsubsection*
Aprendizado linear
\end_layout

\begin_layout Itemize
Regressão Linear
\end_layout

\begin_deeper
\begin_layout Itemize
Ajusta uma linha para seus dados de treinamento (linha de regressão);
\end_layout

\begin_layout Itemize
Predicações baseadas nessa linha;
\end_layout

\end_deeper
\begin_layout Itemize
Pode lidar com previsões de regressão (númericas) e classificação;
\end_layout

\begin_deeper
\begin_layout Itemize
Para classificação, uma função de limite linear é usada;
\end_layout

\begin_layout Itemize
Pode ser binária ou multiclasse;
\end_layout

\end_deeper
\begin_layout Itemize
Que tipo de treinamento se espera?
\end_layout

\begin_deeper
\begin_layout Itemize
RecordIO/Protobuf;
\end_layout

\begin_deeper
\begin_layout Itemize
Somente dados Float32;
\end_layout

\end_deeper
\begin_layout Itemize
CSV;
\end_layout

\begin_deeper
\begin_layout Itemize
A primeira coluna é considerada o rótulo;
\end_layout

\end_deeper
\begin_layout Itemize
Suporta o modo file ou pipe;
\end_layout

\begin_deeper
\begin_layout Itemize
File: copia todos os dados de treino em um único arquivo;
\end_layout

\begin_layout Itemize
Pipe: stream do S3 conforme necessário - mais eficiente;
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Como é usado?
\end_layout

\begin_deeper
\begin_layout Itemize
Pré-processando:
\end_layout

\begin_deeper
\begin_layout Itemize
Os dados de treinamento devem ser normalizados (para que todos os atributos
 tenham o mesmo peso);
\end_layout

\begin_layout Itemize
O linear learner pode fazer isso para você automaticamente;
\end_layout

\begin_layout Itemize
Os dados de entrada devem ser 
\begin_inset Quotes eld
\end_inset

misturados
\begin_inset Quotes erd
\end_inset

;
\end_layout

\end_deeper
\begin_layout Itemize
Treinamento:
\end_layout

\begin_deeper
\begin_layout Itemize
Usa stochastic gradient descent;
\end_layout

\begin_layout Itemize
Escolha um algoritmo de otimização (Adam, AdaGrad, SGD, etc.);
\end_layout

\begin_layout Itemize
Vários modelos são otimizados em paralelo;
\end_layout

\begin_layout Itemize
Regularização L1, L2 para ajuste;
\end_layout

\end_deeper
\begin_layout Itemize
Validação:
\end_layout

\begin_layout Itemize
O modelo mais otimizado é selecionado;
\end_layout

\end_deeper
\begin_layout Itemize
Hiperparâmetros importantes:
\end_layout

\begin_deeper
\begin_layout Itemize
Balance_multiclass_weights
\end_layout

\begin_deeper
\begin_layout Itemize
Dá a cada classe igual importância nas funções de perda (loss function);
\end_layout

\end_deeper
\begin_layout Itemize
Learning_rate, mini_batch_size;
\end_layout

\begin_layout Itemize
L1;
\end_layout

\begin_deeper
\begin_layout Itemize
Regularização;
\end_layout

\end_deeper
\begin_layout Itemize
Wd;
\end_layout

\begin_deeper
\begin_layout Itemize
Weight decay (Regularização L2);
\end_layout

\end_deeper
\begin_layout Itemize
Aprendizado linear: tipos de instância
\end_layout

\begin_deeper
\begin_layout Itemize
Treinamento
\end_layout

\begin_deeper
\begin_layout Itemize
CPU ou GPU de uma ou várias máquinas;
\end_layout

\begin_layout Itemize
Multi-GPU não melhora a performance do modelo;
\end_layout

\end_deeper
\end_deeper
\end_deeper
\begin_layout Subsection
XGBoost
\end_layout

\begin_layout Subsubsection*
Para que serve?
\end_layout

\begin_layout Itemize
O eXtreme Gradient Boosting:
\end_layout

\begin_deeper
\begin_layout Itemize
Grupo de árvores de decisão;
\end_layout

\begin_layout Itemize
Novas árvores feitas para corrigir os erros das árvores anteriores;
\end_layout

\begin_layout Itemize
Usa gradient descent para minimizar a perda conforme novas árvores são adicionad
as;
\end_layout

\end_deeper
\begin_layout Itemize
Tem ganhado muitas competições do Kaggle;
\end_layout

\begin_deeper
\begin_layout Itemize
E também é muito rápido;
\end_layout

\end_deeper
\begin_layout Itemize
Pode ser usado para classificação;
\end_layout

\begin_layout Itemize
E também para regressão;
\end_layout

\begin_deeper
\begin_layout Itemize
Usando árvores de regressão;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Que tipo de treinamento ele espera?
\end_layout

\begin_layout Itemize
XGBoost não foi feito para o SageMaker, XGBoost Open Source;
\end_layout

\begin_layout Itemize
Portanto, é necessária a entrada CSV ou lbsvm;
\end_layout

\begin_layout Itemize
O AWS recentemente melhorou para aceitar também RecordIO/Protubuf e Parquet;
\end_layout

\begin_layout Subsubsection*
Como é usado?
\end_layout

\begin_layout Itemize
Os modelos são serializados/desserializados com Pickle;
\end_layout

\begin_layout Itemize
Pode ser usado comom uma estrutura em notebooks;
\end_layout

\begin_deeper
\begin_layout Itemize
Sagemaker.xgboost
\end_layout

\end_deeper
\begin_layout Itemize
Ou como um algoritmo SageMaker integrado;
\end_layout

\begin_layout Subsubsection*
Hiperparâmetros importantes
\end_layout

\begin_layout Itemize
Existem muitos, alguns exemplos são:
\end_layout

\begin_deeper
\begin_layout Itemize
Subsample:
\end_layout

\begin_deeper
\begin_layout Itemize
Previne o overfitting;
\end_layout

\end_deeper
\begin_layout Itemize
ETA:
\end_layout

\begin_deeper
\begin_layout Itemize
Reduz o tamanho do step, evitando overfitting;
\end_layout

\end_deeper
\begin_layout Itemize
Gama:
\end_layout

\begin_deeper
\begin_layout Itemize
Redução de perda mínima para criar uma partição; maior=mais conservador;
\end_layout

\end_deeper
\begin_layout Itemize
Alfa:
\end_layout

\begin_deeper
\begin_layout Itemize
Termo de regularização L1; maior = mais conservador;
\end_layout

\end_deeper
\begin_layout Itemize
Lambda:
\end_layout

\begin_deeper
\begin_layout Itemize
Termo de regularização L2; maior = mais conservador;
\end_layout

\end_deeper
\end_deeper
\begin_layout Subsubsection*
Tipos de instância
\end_layout

\begin_layout Itemize
Usa apenas CPU;
\end_layout

\begin_layout Itemize
É limitado pela memória, não pelo computador;
\end_layout

\begin_layout Itemize
Então, M4 é uma boa opção;
\end_layout

\begin_layout Subsection
Seq2Seq
\end_layout

\begin_layout Subsubsection*
Para que serve?
\end_layout

\begin_layout Itemize
A entrada é uma sequência de tokens, a saída é uma sequência de tokens;
\end_layout

\begin_layout Itemize
Tradução por máquina;
\end_layout

\begin_layout Itemize
Resumo de texto;
\end_layout

\begin_layout Itemize
Fala para texto;
\end_layout

\begin_layout Itemize
Implementado com RNNs e CNNs
\end_layout

\begin_layout Subsubsection*
Que tipo de treinamento ele espera?
\end_layout

\begin_layout Itemize
RecordIO/Protobuf:
\end_layout

\begin_deeper
\begin_layout Itemize
Os tokens devem ser inteiros (isso é incomum pois a maioria dos algoritmos
 espera dados de pontos flutuante);
\end_layout

\end_deeper
\begin_layout Itemize
Comece com arquivos de texto tokenizados;
\end_layout

\begin_layout Itemize
Converter para protobuf usando código de exemplo:
\end_layout

\begin_deeper
\begin_layout Itemize
Pacotes de tensores inteiros com arquivos de vocabulário;
\end_layout

\begin_layout Itemize
Muito parecido com o lab TF/IDF que fizemos anteriormente;
\end_layout

\end_deeper
\begin_layout Itemize
Deve fornecer dados de treinamento, dados de vallidação e arquivos de vocabulári
o;
\end_layout

\begin_layout Subsubsection*
Como é usado?
\end_layout

\begin_layout Itemize
O treinamento para tradução automática pode levar dias, mesmo no SageMaker;
\end_layout

\begin_layout Itemize
Modelos pré-treinados estão disponíveis:
\end_layout

\begin_deeper
\begin_layout Itemize
Veja o notebook de exemplo;
\end_layout

\end_deeper
\begin_layout Itemize
Conjunto de dados de treinamento públicos estão disponíveis para tarefas
 de tradução específicas;
\end_layout

\begin_layout Subsubsection*
Hiperparâmetros importantes
\end_layout

\begin_layout Itemize
Batch_size;
\end_layout

\begin_layout Itemize
Optimizer_type(adam, sgd, rmsprop);
\end_layout

\begin_layout Itemize
Learning_rate;
\end_layout

\begin_layout Itemize
Num_layers_encoder;
\end_layout

\begin_layout Itemize
Num_layers_decoder;
\end_layout

\begin_layout Itemize
Pode otimizar em:
\end_layout

\begin_deeper
\begin_layout Itemize
Precisão:
\end_layout

\begin_deeper
\begin_layout Itemize
Vs.
 conjunto de dados de validação fornecido
\end_layout

\end_deeper
\begin_layout Itemize
BLEU score:
\end_layout

\begin_deeper
\begin_layout Itemize
Compara com várias traduções de referência
\end_layout

\end_deeper
\begin_layout Itemize
Perplexity:
\end_layout

\begin_deeper
\begin_layout Itemize
Cross-entropy
\end_layout

\end_deeper
\end_deeper
\begin_layout Subsubsection*
Tipos de instância
\end_layout

\begin_layout Itemize
Só pode usar tipos de instância de GPU (P3 por exemplo)
\end_layout

\begin_layout Itemize
Pode usar uma única máquina para treinamento;
\end_layout

\begin_deeper
\begin_layout Itemize
Mas pode usar multi-GPUs em uma máquina;
\end_layout

\end_deeper
\begin_layout Subsection
DeepAR
\end_layout

\begin_layout Subsubsection*
Para que serve?
\end_layout

\begin_layout Itemize
Previsão de dados de série temporal unidimensionais;
\end_layout

\begin_layout Itemize
Usa RNN's;
\end_layout

\begin_layout Itemize
Permite treinar o mesmo modelo em várias séries temporais relacionadas;
\end_layout

\begin_layout Itemize
Encontra frequências e sazonalidade;
\end_layout

\begin_layout Subsubsection*
Que tipo de treinamento ele espera?
\end_layout

\begin_layout Itemize
JSON
\end_layout

\begin_deeper
\begin_layout Itemize
Gzip ou Parquet;
\end_layout

\end_deeper
\begin_layout Itemize
Cada registro deve conter:
\end_layout

\begin_deeper
\begin_layout Itemize
Início: a hora de início;
\end_layout

\begin_layout Itemize
Objetivo: os valores da série temporal;
\end_layout

\end_deeper
\begin_layout Itemize
Cada registro pode conter:
\end_layout

\begin_deeper
\begin_layout Itemize
Dynamic_feat: recursos dinâmicos (como uma promoção aplicada a um produto
 em uma série temporal de compras de produtos);
\end_layout

\begin_layout Itemize
Cat: características categóricas;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Como é usado?
\end_layout

\begin_layout Itemize
Sempre inclua séries temporais inteiras para treinamento, teste e inferência;
\end_layout

\begin_layout Itemize
Use o conjunto de dados inteiro como conjunto de treinamento, remova os
 últimos dados de tempo para teste.
 Avalie os valores retidos;
\end_layout

\begin_layout Itemize
Não use valores muito grandes para previsão (>400)
\end_layout

\begin_layout Itemize
Treine em várias séries temporais e não apenas em uma, quando possível;
\end_layout

\begin_layout Subsubsection*
Hiperparâmetros importantes
\end_layout

\begin_layout Itemize
Context_length
\end_layout

\begin_deeper
\begin_layout Itemize
Número de dados temporais que o modelo vê antes de fazer uma previsão;
\end_layout

\begin_layout Itemize
Pode ser menor do que sazonalidades; o modelo vai ter um atraso de um ano
 de qualquer maneira;
\end_layout

\end_deeper
\begin_layout Itemize
Epochs;
\end_layout

\begin_layout Itemize
Mini_batch_size;
\end_layout

\begin_layout Itemize
Learning_rate;
\end_layout

\begin_layout Itemize
Num_cells;
\end_layout

\begin_layout Subsubsection*
Tipos de instância
\end_layout

\begin_layout Itemize
Pode usar CPU ou GPU;
\end_layout

\begin_layout Itemize
Máquina única ou multi-máquina;
\end_layout

\begin_layout Itemize
Comece com CPU (C4.2xlarge, C4.4xlarge);
\end_layout

\begin_layout Itemize
Mova para GPU, se necessário;
\end_layout

\begin_deeper
\begin_layout Itemize
Só ajuda com modelos maiores;
\end_layout

\end_deeper
\begin_layout Itemize
Apenas CPU para inferência;
\end_layout

\begin_layout Itemize
Pode precisar de instâncias maiores para ajuste;
\end_layout

\begin_layout Subsection
BlazingText
\end_layout

\begin_layout Subsubsection*
Para que serve?
\end_layout

\begin_layout Itemize
Classificação de texto:
\end_layout

\begin_deeper
\begin_layout Itemize
Prever textos para uma frase;
\end_layout

\begin_layout Itemize
Útil em pesquisas na web, recuperação de informações;
\end_layout

\begin_layout Itemize
Supervisionado;
\end_layout

\end_deeper
\begin_layout Itemize
Word2vec:
\end_layout

\begin_deeper
\begin_layout Itemize
Cria uma representação vetorial de palavras;
\end_layout

\begin_layout Itemize
Palavras com semânticas semelhantes são representadas por vetores próximos
 uns dos outros;
\end_layout

\begin_layout Itemize
Isso é chamado de incorporação de palavras;
\end_layout

\begin_layout Itemize
É útil para PLN, mas não é um algoritmo de PLN em si;
\end_layout

\begin_layout Itemize
Usado em tradução automática, análise de sentimento;
\end_layout

\begin_layout Itemize
Funciona com palavras individuais, mas não com frases ou documentos;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Que tipo de treinamento ele espera?
\end_layout

\begin_layout Itemize
Para modo supervisionado (classificação de texto):
\end_layout

\begin_deeper
\begin_layout Itemize
Uma frase por linha;
\end_layout

\begin_layout Itemize
A primeira 
\begin_inset Quotes eld
\end_inset

palavra
\begin_inset Quotes erd
\end_inset

 na frase é a string __label__ seguida pelo rótulo de fato da sentença;
\end_layout

\end_deeper
\begin_layout Itemize
Além disso, 
\begin_inset Quotes eld
\end_inset

augmented manifest text format
\begin_inset Quotes erd
\end_inset

;
\end_layout

\begin_layout Itemize
O Word2vec espera apenas um arquivo de texto com uma frase de treinamento
 por linha;
\end_layout

\begin_layout Subsubsection*
Como isso é usado?
\end_layout

\begin_layout Itemize
Word2vec tem várias formas:
\end_layout

\begin_deeper
\begin_layout Itemize
Cbow (Bag of words);
\end_layout

\begin_layout Itemize
Skip-gram;
\end_layout

\begin_layout Itemize
Batch skip-gram:
\end_layout

\begin_deeper
\begin_layout Itemize
Computação distribuída em muitos nós;
\end_layout

\end_deeper
\end_deeper
\begin_layout Subsubsection*
Hiperparâmetros importantes
\end_layout

\begin_layout Itemize
Word2vec:
\end_layout

\begin_deeper
\begin_layout Itemize
Mode (batch_skipgram, skipgram, cbow);
\end_layout

\begin_layout Itemize
Learning_rate;
\end_layout

\begin_layout Itemize
Window_size;
\end_layout

\begin_layout Itemize
Vector_dim;
\end_layout

\begin_layout Itemize
Negative_samples;
\end_layout

\end_deeper
\begin_layout Itemize
Classificação de texto:
\end_layout

\begin_deeper
\begin_layout Itemize
Epochs;
\end_layout

\begin_layout Itemize
Learning_rate;
\end_layout

\begin_layout Itemize
Word_ngrams;
\end_layout

\begin_layout Itemize
Vector_dim;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Tipos de instâncias
\end_layout

\begin_layout Itemize
Para cbow e skipgram, recomenda-se um único ml.p3.2xlarge;
\end_layout

\begin_deeper
\begin_layout Itemize
Qualquer CPU ou instância única de GPU funcionará;
\end_layout

\end_deeper
\begin_layout Itemize
Para batch_skipgram, pode usar uma ou várias instâncias de CPU;
\end_layout

\begin_layout Itemize
Para classificação de texto, é recomendado C5 se tiver menos de 2GB de dado
 de treinamento;
\end_layout

\begin_layout Itemize
Para conjuntos de dados maiores, use uma única instância de GPU (ml.p2.xlarge
 ou ml.p3.2xlarge);
\end_layout

\begin_layout Subsection
Object2Vec
\end_layout

\begin_layout Subsubsection*
Para que serve?
\end_layout

\begin_layout Itemize
Lembra do word2vec do BlazingText? É semelhante, mas serve também para objetos
 arbitrários;
\end_layout

\begin_layout Itemize
Ele cria 
\begin_inset Quotes eld
\end_inset

embeddings
\begin_inset Quotes erd
\end_inset

 densos de baixa dimensão de objetos de alta dimensão;
\end_layout

\begin_layout Itemize
É basicamente um word2vec generalizado, para lidar com outras coisas além
 de palavras;
\end_layout

\begin_layout Itemize
Calcula os vizinhos mais próximos de objetos;
\end_layout

\begin_layout Itemize
Visualiza clusters;
\end_layout

\begin_layout Itemize
Previsão de gênero;
\end_layout

\begin_layout Itemize
Recomendações (itens ou usuários semelhantes)
\end_layout

\begin_layout Itemize
Não supervisionado;
\end_layout

\begin_layout Subsubsection*
Que tipo de treinamento ele espera?
\end_layout

\begin_layout Itemize
Os dados devem ser tokenizados em inteiros;
\end_layout

\begin_layout Itemize
Os dados de treinamento consistem em pares de tokens e/ou sequências de
 tokens;
\end_layout

\begin_deeper
\begin_layout Itemize
Sentença-sentença;
\end_layout

\begin_layout Itemize
Sequência de rótulos (gênero para descrição);
\end_layout

\begin_layout Itemize
Cliente-cliente;
\end_layout

\begin_layout Itemize
Produto-produto;
\end_layout

\begin_layout Itemize
Item de usuário;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Como é usado?
\end_layout

\begin_layout Itemize
Processa dados em linhas JSON e os embaralha;
\end_layout

\begin_layout Itemize
Treina com dois canais de entrada, dois encoders e um comparador;
\end_layout

\begin_layout Itemize
Opções de encoders:
\end_layout

\begin_deeper
\begin_layout Itemize
Embeddings com pool médio;
\end_layout

\begin_layout Itemize
CNN's
\end_layout

\begin_layout Itemize
LSTM bidirecional;
\end_layout

\end_deeper
\begin_layout Itemize
O comparador é seguido por uma rede neural feed-forward;
\end_layout

\begin_layout Subsubsection*
Hiperparâmetros importantes
\end_layout

\begin_layout Itemize
Os usuais de deep learning;
\end_layout

\begin_deeper
\begin_layout Itemize
Dropout, early stopping, epochs, learning rate, batch size, layers, activation
 function, optimizer, weight decay;
\end_layout

\end_deeper
\begin_layout Itemize
Enc1_network, enc2_network
\end_layout

\begin_deeper
\begin_layout Itemize
Opções de hcnn, bilstm, pooled_embedding;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Tipos de instância
\end_layout

\begin_layout Itemize
Só pode treinar em uma única máquina (CPU ou GPU, multi-GPU)
\end_layout

\begin_deeper
\begin_layout Itemize
Ml.m5.2xlarge;
\end_layout

\begin_layout Itemize
Ml.p2.xlarge;
\end_layout

\begin_layout Itemize
Se necessário, vá até ml.m5.4xlarge ou ml.m5.12xlarge;
\end_layout

\end_deeper
\begin_layout Itemize
Inferência: use ml.p2.2xlarge;
\end_layout

\begin_deeper
\begin_layout Itemize
Use a variável de ambiente INFERENCE_PREFERRED_MODE para otimizar para embedding
s do codificador em vez de classificação ou regressão;
\end_layout

\end_deeper
\begin_layout Subsection
Detecção de objetos
\end_layout

\begin_layout Subsubsection*
Para que serve?
\end_layout

\begin_layout Itemize
Identifique todos os objetos de uma imagem com caixas delimitadoras;
\end_layout

\begin_layout Itemize
Detecta e classifica objetos com uma única rede neural profunda;
\end_layout

\begin_layout Itemize
As classes são acompanhadas por pontuações de confiança;
\end_layout

\begin_layout Itemize
Pode treinar do zero ou usar modelos pré-treinados com base na ImageNet;
\end_layout

\begin_layout Subsubsection*
Que tipo de treinamento ele espera?
\end_layout

\begin_layout Itemize
RecordIO ou formato de imagem (Jpg ou Png)
\end_layout

\begin_layout Itemize
Com o formato de imagem, fornça um arquivo JSON para dados de anotação para
 cada imagem;
\end_layout

\begin_layout Subsubsection*
Como isso é usado?
\end_layout

\begin_layout Itemize
Obtém uma imagem como entrada, produz todas as instâncias de objetos na
 imagem com categorias e pontuações de confiança;
\end_layout

\begin_layout Itemize
Usa uma CNN com o algoritmo Single Shot Multibox Detector (SSD);
\end_layout

\begin_deeper
\begin_layout Itemize
O CNN básico pode ser VGG-16 ou ResNet-50;
\end_layout

\end_deeper
\begin_layout Itemize
Transfer Learning/Treinamento Incremental;
\end_layout

\begin_deeper
\begin_layout Itemize
Use um modelo pré-treinado para os pesos básicos da rede, em vez de pesos
 iniciais aleatórios;
\end_layout

\end_deeper
\begin_layout Itemize
Usa flip, jitter e rescale internamente para evitar o overfitting;
\end_layout

\begin_layout Subsubsection*
Hiperparâmetros importantes
\end_layout

\begin_layout Itemize
Mini-batch_size
\end_layout

\begin_layout Itemize
Learning_rate
\end_layout

\begin_layout Itemize
Optimizer
\end_layout

\begin_deeper
\begin_layout Itemize
Sgd, adam, rmsprop, adadelta
\end_layout

\end_deeper
\begin_layout Subsubsection*
Tipos de instâncias
\end_layout

\begin_layout Itemize
Use instâncias de GPU para treinamento (multi-GPU e multi-máquina)
\end_layout

\begin_deeper
\begin_layout Itemize
ml.p2.xlarge, ml.p2.8xlarge, ml.p2.16xlarge, ml.p3.2xlarge, ml.p3.8xlarge, ml.p3.16xlarge;
\end_layout

\end_deeper
\begin_layout Itemize
Use CPU para inferência;
\end_layout

\begin_deeper
\begin_layout Itemize
C5, M5, P2, P3 todos ok;
\end_layout

\end_deeper
\begin_layout Subsection
Classificação de imagens
\end_layout

\begin_layout Subsubsection*
Para que serve?
\end_layout

\begin_layout Itemize
Atribuir um ou mais rótulos a uma imagem;
\end_layout

\begin_layout Itemize
Não diz onde os objetos estão, apenas quais objetos estão na imagem;
\end_layout

\begin_layout Subsubsection*
Que tipo de treinamento ele espera?
\end_layout

\begin_layout Itemize
Apache MXNet RecordIO:
\end_layout

\begin_deeper
\begin_layout Itemize
Não o protobuf;
\end_layout

\begin_layout Itemize
Isso é para interoperabilidade com outras estruturas de aprendizado profundo;
\end_layout

\end_deeper
\begin_layout Itemize
Ou imagens jpg ou png;
\end_layout

\begin_layout Itemize
O formato de imagem requer arquivos .lst para assosciar índice de imagem,
 rótulo de classe e caminho para a imagem;
\end_layout

\begin_layout Itemize
O formato 
\begin_inset Quotes eld
\end_inset

Augmented Manifest Image
\begin_inset Quotes erd
\end_inset

 habilita o modo Pipe;
\end_layout

\begin_layout Subsubsection*
Como é usada?
\end_layout

\begin_layout Itemize
ResNet CNN nos bastidores;
\end_layout

\begin_layout Itemize
Modo de treinamento completo;
\end_layout

\begin_deeper
\begin_layout Itemize
Rede inicializada com pesos aleatórios;
\end_layout

\end_deeper
\begin_layout Itemize
Modo de transferência de aprendizagem;
\end_layout

\begin_deeper
\begin_layout Itemize
Inicializado com pesos pré-treinados;
\end_layout

\begin_layout Itemize
A camada superior totalmente conectada é inicializada com pesos aleatórios;
\end_layout

\begin_layout Itemize
A rede é ajustada com novos dados de treinamento;
\end_layout

\end_deeper
\begin_layout Itemize
O tamanho padrão da imagem é de 3 canais 224x224 (conjunto de dados da imageNet)
;
\end_layout

\begin_layout Subsubsection*
Hiperparâmetros importantes
\end_layout

\begin_layout Itemize
Os de costume para aprendizado profundo:
\end_layout

\begin_deeper
\begin_layout Itemize
Batch size, learning rate, optimizer
\end_layout

\end_deeper
\begin_layout Itemize
Parâmetros específicos do otimizador
\end_layout

\begin_deeper
\begin_layout Itemize
Weight decay, beta 1, beta 2, eps, gamma;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Tipos de instância
\end_layout

\begin_layout Itemize
Instâncias de GPU para treinamento (P2, P3) multi-GPU e multi-máquina OK;
\end_layout

\begin_layout Itemize
CPU ou GPU para inferência (C4, P2, P3);
\end_layout

\begin_layout Subsection
Segmentação semântica
\end_layout

\begin_layout Subsubsection*
Para que serve?
\end_layout

\begin_layout Itemize
Classificação de objetos em nível de píxel;
\end_layout

\begin_layout Itemize
Diferente da classificação de imagem, que atribui rótulos a imagens inteiras;
\end_layout

\begin_layout Itemize
Diferente da detecção de objetos, que atribui rotulos a caixa delimitadoras;
\end_layout

\begin_layout Itemize
Útil para veículos autônomos, diagnósticos por imagens médicas, detecção
 de robôs;
\end_layout

\begin_layout Itemize
Produz uma máscara de segmentação;
\end_layout

\begin_layout Subsubsection*
Que tipo de treinamento ele espera?
\end_layout

\begin_layout Itemize
Imagens JPG ou anotações PNG;
\end_layout

\begin_layout Itemize
Para treinamento e validação;
\end_layout

\begin_layout Itemize
Formato Augmented Manifest Imagem suportado para o modo Pipe;
\end_layout

\begin_layout Itemize
Imagens JPG aceitas para inferência;
\end_layout

\begin_layout Subsubsection*
Como é usada?
\end_layout

\begin_layout Itemize
Construído em MXNet Gluon e Gluon CV;
\end_layout

\begin_layout Itemize
Escolha entre 3 algoritmos:
\end_layout

\begin_deeper
\begin_layout Itemize
Fully-conbolutional Network (FCN);
\end_layout

\begin_layout Itemize
Pyramid Scene Parsing (PSP);
\end_layout

\begin_layout Itemize
DeepLabV3;
\end_layout

\end_deeper
\begin_layout Itemize
Escolha entre backbones:
\end_layout

\begin_deeper
\begin_layout Itemize
ResNet50;
\end_layout

\begin_layout Itemize
ResNet101;
\end_layout

\begin_layout Itemize
Ambos treinados na ImageNet;
\end_layout

\end_deeper
\begin_layout Itemize
Treinamento incremental, treinamento do zero também suportado;
\end_layout

\begin_layout Subsubsection*
Hiperparâmetros importantes
\end_layout

\begin_layout Itemize
Epochs, learning rate, batch size, optimizer, etc.;
\end_layout

\begin_layout Itemize
Algoritmo;
\end_layout

\begin_layout Itemize
Backbone;
\end_layout

\begin_layout Subsubsection*
Tipos de instância
\end_layout

\begin_layout Itemize
Apenas GPU para treinamento (P2 ou P3) em uma única máquina apenas;
\end_layout

\begin_deeper
\begin_layout Itemize
Especificamente ml.p2.xlarge, ml.p2.8xlarge, ml.p2.16xlarge, ml.p3.2xlarge, ml.p3.8xlarge,
 ml.p3.16xlarge;
\end_layout

\end_deeper
\begin_layout Itemize
Inferência na CPU (C5 ou M5) ou GPU (P2 ou P3);
\end_layout

\begin_layout Subsection
Random Cut Forest
\end_layout

\begin_layout Subsubsection*
Para que serve?
\end_layout

\begin_layout Itemize
Detecção de anomalia;
\end_layout

\begin_layout Itemize
Não supervisionado;
\end_layout

\begin_layout Itemize
Detecta picos inesperados nos dados de uma série temporal;
\end_layout

\begin_layout Itemize
Divide em periodicidade;
\end_layout

\begin_layout Itemize
Pontos de dados não classificáveis;
\end_layout

\begin_layout Itemize
Atribui uma pontuação de anomalia a cada dado;
\end_layout

\begin_layout Itemize
Baseado em um algoritmo desenvolvido pela Amazon (do qual eles se orgulham
 muito!);
\end_layout

\begin_layout Subsubsection*
Que tipo de treinamento espera?
\end_layout

\begin_layout Itemize
RecordIO/Protobuf ou CSV;
\end_layout

\begin_layout Itemize
Pode usar modo File ou Pipe para ambos;
\end_layout

\begin_layout Itemize
Canal de teste opcional para calcular acurácia, precisão, recall e F2 em
 dados rotulados (anomalia ou não);
\end_layout

\begin_layout Subsubsection*
Como é usado?
\end_layout

\begin_layout Itemize
Cria uma floresta de árvores onde cada árvore é uma partição dos dados de
 treinamento; olha para a mudança esperada na complexidade da árvore como
 resultado da adição de um dado nela;
\end_layout

\begin_layout Itemize
Os dados são amostrados aleatoriamente;
\end_layout

\begin_layout Itemize
Então é treinada;
\end_layout

\begin_layout Itemize
O RCF também aparece no Kinesis Analytics, ele também pode funcionar em
 streaming de dados;
\end_layout

\begin_layout Subsubsection*
Hiperparâmetros importantes
\end_layout

\begin_layout Itemize
Num_trees;
\end_layout

\begin_deeper
\begin_layout Itemize
Aumentar reduz o ruído;
\end_layout

\end_deeper
\begin_layout Itemize
Num_samples_per_tree;
\end_layout

\begin_deeper
\begin_layout Itemize
Deve ser escolhido de forma que 1/num_samples_per_tree se aproxime da proporção
 de dados entre anômalos e normais;
\end_layout

\end_deeper
\begin_layout Subsection*
Tipos de instância
\end_layout

\begin_layout Itemize
Não tem vantagem usar GPUs;
\end_layout

\begin_layout Itemize
Use M4, C4 ou C5 para treinamento;
\end_layout

\begin_layout Itemize
ml.c5.xl para inferência;
\end_layout

\begin_layout Subsection
Neural Topic Model
\end_layout

\begin_layout Subsubsection*
Para que serve?
\end_layout

\begin_layout Itemize
Organiza documentos em tópicos;
\end_layout

\begin_layout Itemize
Classifica ou resume documentos com base em tópicos;
\end_layout

\begin_layout Itemize
Não é apenas TF/IDF;
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

Bicicleta
\begin_inset Quotes erd
\end_inset

, 
\begin_inset Quotes eld
\end_inset

carro
\begin_inset Quotes erd
\end_inset

, 
\begin_inset Quotes eld
\end_inset

trem
\begin_inset Quotes erd
\end_inset

, 
\begin_inset Quotes eld
\end_inset

quilometragem
\begin_inset Quotes erd
\end_inset

 e 
\begin_inset Quotes eld
\end_inset

velocidade
\begin_inset Quotes erd
\end_inset

 podem classificar um documento como 
\begin_inset Quotes eld
\end_inset

transporte
\begin_inset Quotes erd
\end_inset

, por exemplo (embora não seja rotulado exatamente desta maneira);
\end_layout

\end_deeper
\begin_layout Itemize
Sem supervisão;
\end_layout

\begin_deeper
\begin_layout Itemize
Algoritmo é 
\begin_inset Quotes eld
\end_inset

Inferência Neural Variacional
\begin_inset Quotes erd
\end_inset

;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Que tipo de treinamento ele espera?
\end_layout

\begin_layout Itemize
Quatro canais de dados:
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

Treinar
\begin_inset Quotes erd
\end_inset

 é necessário;
\end_layout

\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

Validação
\begin_inset Quotes erd
\end_inset

, 
\begin_inset Quotes eld
\end_inset

teste
\begin_inset Quotes erd
\end_inset

 e 
\begin_inset Quotes eld
\end_inset

auxiliar
\begin_inset Quotes erd
\end_inset

 opcional;
\end_layout

\end_deeper
\begin_layout Itemize
RecordIO/Protobuf ou CSV;
\end_layout

\begin_layout Itemize
As palavras devem ser convertidas em números inteiros;
\end_layout

\begin_deeper
\begin_layout Itemize
Cada documento deve conter uma contagem para cada palavra do vocabulário
 em CSV;
\end_layout

\begin_layout Itemize
O canal 
\begin_inset Quotes eld
\end_inset

auxiliar
\begin_inset Quotes erd
\end_inset

 é para vocabulário;
\end_layout

\end_deeper
\begin_layout Itemize
Modo file ou pipe;
\end_layout

\begin_layout Subsubsection*
Como é usado?
\end_layout

\begin_layout Itemize
Você define quantos tópicos deseja;
\end_layout

\begin_deeper
\begin_layout Itemize
Isto é um hiperparâmetro que você define quando irá configurar o algoritmo;
\end_layout

\end_deeper
\begin_layout Itemize
Esses tópicos são uma representação latente com base nas palavras mais bem
 classificadas;
\end_layout

\begin_layout Itemize
Um dos dois algoritmos de modelagem de tópicos no SageMaker - você pode
 tentar os dois;
\end_layout

\begin_layout Subsubsection*
Hiperparâmetros importantes
\end_layout

\begin_layout Itemize
Reduzir mini_batch_size e learning_rate pode reduzir validation_loss
\end_layout

\begin_deeper
\begin_layout Itemize
À custa do tempo de treinamento;
\end_layout

\end_deeper
\begin_layout Itemize
Num_topics;
\end_layout

\begin_layout Subsubsection*
Tipos de instâncias
\end_layout

\begin_layout Itemize
GPU ou CPU
\end_layout

\begin_deeper
\begin_layout Itemize
GPU é recomendado para treinamento;
\end_layout

\begin_layout Itemize
CPU para inferência;
\end_layout

\begin_layout Itemize
CPU é mais barato;
\end_layout

\end_deeper
\begin_layout Subsection
LDA
\end_layout

\begin_layout Subsubsection*
Para que serve?
\end_layout

\begin_layout Itemize
Latent Dirichlet Allocation;
\end_layout

\begin_layout Itemize
Outro algoritmo de modelagem de tópico;
\end_layout

\begin_deeper
\begin_layout Itemize
Não é deep learning;
\end_layout

\end_deeper
\begin_layout Itemize
Sem supervisão;
\end_layout

\begin_deeper
\begin_layout Itemize
Os próprios tópicos não estão rotulados;
\end_layout

\begin_layout Itemize
Eles são apenas agrupamentos de documentos com um subconjunto compartilhado
 de palavras;
\end_layout

\end_deeper
\begin_layout Itemize
Pode ser usado para outras coisas além de palavras;
\end_layout

\begin_deeper
\begin_layout Itemize
Agrupar clientes baseados em suas compras;
\end_layout

\begin_layout Itemize
Análise harmônica na música;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Que tipo de treinamento ele espera?
\end_layout

\begin_layout Itemize
Canal de treinamento, canal de teste opcional;
\end_layout

\begin_layout Itemize
RecordIO/Protobuf ou CSV;
\end_layout

\begin_layout Itemize
Cada documento tem contagens para cada palavra do vocabulário (em formato
 CSV);
\end_layout

\begin_layout Itemize
Modo Pipe suportado apenas com RecordIO;
\end_layout

\begin_layout Subsubsection*
Como é usado?
\end_layout

\begin_layout Itemize
Sem supervisão: gera quantos tópicos você especificar;
\end_layout

\begin_layout Itemize
O canal de teste opcional pode ser usado para pontuar os resultados;
\end_layout

\begin_deeper
\begin_layout Itemize
Probabilidade de registro por palavra;
\end_layout

\end_deeper
\begin_layout Itemize
Funcionalmente semelhante ao NTM, mas baseado em CPU;
\end_layout

\begin_deeper
\begin_layout Itemize
Portanto, pode ser mais barato/mais eficiente;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Hiperparâmetros importantes
\end_layout

\begin_layout Itemize
Num_topics;
\end_layout

\begin_layout Itemize
Alpha0;
\end_layout

\begin_deeper
\begin_layout Itemize
Estimativa inicial para o parâmetro de concentração;
\end_layout

\begin_layout Itemize
Valores menores geram misturas de tópicos esparsos;
\end_layout

\begin_layout Itemize
Valores maiores (>1.0) produzem misturas uniformes;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Tipos de instância
\end_layout

\begin_layout Itemize
Treinamento de CPU de instância única;
\end_layout

\begin_layout Subsection
KNN
\end_layout

\begin_layout Subsubsection*
Para que serve?
\end_layout

\begin_layout Itemize
K-Nearest-Neighbours;
\end_layout

\begin_layout Itemize
Algoritmo de Classificação ou Regressão Simples;
\end_layout

\begin_layout Itemize
Classificação;
\end_layout

\begin_deeper
\begin_layout Itemize
Encontre os K pontos mais próximos de um ponto de amostra e retorne o rótulo
 mais frequente;
\end_layout

\end_deeper
\begin_layout Itemize
Regressão;
\end_layout

\begin_deeper
\begin_layout Itemize
Encontre os K pontos mias próximos de um ponto de amostra e retorne o valor
 médio;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Que tipo de treinamento ele espera?
\end_layout

\begin_layout Itemize
O canal de treinamento contém seus dados;
\end_layout

\begin_layout Itemize
O canal de teste mede acurácia ou MSE;
\end_layout

\begin_layout Itemize
Treinamento com recordIO/protobuf ou CSV;
\end_layout

\begin_deeper
\begin_layout Itemize
A primeira coluna é o rótulo;
\end_layout

\end_deeper
\begin_layout Itemize
Modo file ou pipe em ambos;
\end_layout

\begin_layout Subsubsection*
Como é usado?
\end_layout

\begin_layout Itemize
Os dados são primeiro amostrados;
\end_layout

\begin_layout Itemize
O SageMaker inclui um estágio de redução de dimensionalidade;
\end_layout

\begin_deeper
\begin_layout Itemize
Evita dados esparsos (
\begin_inset Quotes eld
\end_inset

maldição da dimensionalidade
\begin_inset Quotes erd
\end_inset

);
\end_layout

\begin_layout Itemize
A custo de ruído/precisão;
\end_layout

\begin_layout Itemize
Métodos de 
\begin_inset Quotes eld
\end_inset

sign
\begin_inset Quotes erd
\end_inset

 ou 
\begin_inset Quotes eld
\end_inset

fjlt
\begin_inset Quotes erd
\end_inset

;
\end_layout

\end_deeper
\begin_layout Itemize
Cria um índice para procurar vizinhos;
\end_layout

\begin_layout Itemize
Serializa o modelo;
\end_layout

\begin_layout Itemize
Consulta o modelo para um determinado K;
\end_layout

\begin_layout Subsubsection*
Hiperparâmetros importantes
\end_layout

\begin_layout Itemize
K;
\end_layout

\begin_layout Itemize
Sample_size;
\end_layout

\begin_layout Subsubsection*
Tipos de instância
\end_layout

\begin_layout Itemize
Treinamento de CPU ou GPU;
\end_layout

\begin_deeper
\begin_layout Itemize
ml.m5.2xlarge;
\end_layout

\begin_layout Itemize
ml.p2.xlarge;
\end_layout

\end_deeper
\begin_layout Itemize
Inferência;
\end_layout

\begin_deeper
\begin_layout Itemize
CPU para menor latência;
\end_layout

\begin_layout Itemize
GPU para maior rendimento em grandes batchs;
\end_layout

\end_deeper
\begin_layout Subsection
K-Means
\end_layout

\begin_layout Subsubsection*
Para que serve?
\end_layout

\begin_layout Itemize
Agrupamento não supervisionado;
\end_layout

\begin_layout Itemize
Divida os dados em K grupos, onde os membros de um grupo são semelhantes
 quanto possível entre si;
\end_layout

\begin_deeper
\begin_layout Itemize
Você define o que 
\begin_inset Quotes eld
\end_inset

semelhante
\begin_inset Quotes erd
\end_inset

 significa;
\end_layout

\begin_layout Itemize
Medida pela distância euclideana;
\end_layout

\end_deeper
\begin_layout Itemize
Clustering K-Means em escala da web;
\end_layout

\begin_layout Subsubsection*
Que tipo de treinamento ele espera?
\end_layout

\begin_layout Itemize
Canal de treinamento, teste opcional;
\end_layout

\begin_deeper
\begin_layout Itemize
Treino ShardedByS3Key, teste FullyReplicated;
\end_layout

\end_deeper
\begin_layout Itemize
RecordIO/protobuf ou CSV;
\end_layout

\begin_layout Itemize
File ou Pipe em qualquer um;
\end_layout

\begin_layout Subsubsection*
Como é usado?
\end_layout

\begin_layout Itemize
Cada observação mapeada para o espaço n-dimensional (n=número de características
);
\end_layout

\begin_layout Itemize
Trabalha para otimizar o centro dos k clusters;
\end_layout

\begin_deeper
\begin_layout Itemize
\begin_inset Quotes eld
\end_inset

Centros dos clusters extras
\begin_inset Quotes erd
\end_inset

 podem ser especificados para melhorar a precisão (que acabam sendo reduzidos
 para k);
\end_layout

\begin_layout Itemize
\begin_inset Formula $K=k*x$
\end_inset

;
\end_layout

\end_deeper
\begin_layout Itemize
Algoritmo:
\end_layout

\begin_deeper
\begin_layout Itemize
Determina os centros de cluster iniciais;
\end_layout

\begin_deeper
\begin_layout Itemize
Abordagem aleatória ou k-means ++
\end_layout

\begin_layout Itemize
K-means ++ tenta separar os clusters iniciais;
\end_layout

\end_deeper
\end_deeper
\begin_layout Itemize
Execute interação nos dados de treinamento e calcule os centros de cluster;
\end_layout

\begin_layout Itemize
Reduza os clusters de K para k;
\end_layout

\begin_deeper
\begin_layout Itemize
Usando o método Lloyd's com kmeans ++;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Hiperparâmetros importantes
\end_layout

\begin_layout Itemize
K
\end_layout

\begin_deeper
\begin_layout Itemize
Escolher K é complicado;
\end_layout

\begin_layout Itemize
Use o método elbow;
\end_layout

\begin_layout Itemize
Plotar a soma dos quadrados dentro do cluster em função de K;
\end_layout

\begin_layout Itemize
Otimiza as dimensões dos clusters;
\end_layout

\end_deeper
\begin_layout Itemize
Mini_batch_size;
\end_layout

\begin_layout Itemize
Extra_center_factor;
\end_layout

\begin_layout Itemize
Init_method;
\end_layout

\begin_layout Subsubsection*
Tipos de instância
\end_layout

\begin_layout Itemize
CPU ou GPU, mas CPU é recomendada;
\end_layout

\begin_deeper
\begin_layout Itemize
Apenas uma GPU por instância usada na GPU;
\end_layout

\begin_layout Itemize
Portanto, use p*.xlarge se for usar GPU;
\end_layout

\end_deeper
\begin_layout Subsection
PCA
\end_layout

\begin_layout Subsubsection*
Para que serve?
\end_layout

\begin_layout Itemize
Principal Component Analysis;
\end_layout

\begin_layout Itemize
Redução de dimensionalidade;
\end_layout

\begin_deeper
\begin_layout Itemize
Projete dados com alta dimensionalidade (muitos atributos) em dimensões
 inferiores (como um gráficos 2D) enquanto minimiza a perda de informações;
\end_layout

\begin_layout Itemize
As dimensões reduzidas são chamadas de componentes;
\end_layout

\begin_layout Itemize
O primeiro componente tem a maior variabilidade possível;
\end_layout

\begin_layout Itemize
O segundo componente tem a próxima maior e assim por diante;
\end_layout

\end_deeper
\begin_layout Itemize
Sem supervisão;
\end_layout

\begin_layout Subsubsection*
Que tipo de treinamento ele espera?
\end_layout

\begin_layout Itemize
RecordIO/Protobuf ou CSV;
\end_layout

\begin_layout Itemize
File ou Pipe ou ambos;
\end_layout

\begin_layout Subsubsection*
Como é usado?
\end_layout

\begin_layout Itemize
Matriz de covariância é criada, então usa uma técnica de singular value
 decomposition (SVD);
\end_layout

\begin_layout Itemize
Dois modos;
\end_layout

\begin_deeper
\begin_layout Itemize
Regular:
\end_layout

\begin_deeper
\begin_layout Itemize
Para dados esparsos e número moderado de observações e recursos;
\end_layout

\end_deeper
\begin_layout Itemize
Randomizado:
\end_layout

\begin_deeper
\begin_layout Itemize
Para um grande número de observações e atributos;
\end_layout

\begin_layout Itemize
Usa algoritmo de aproximação;
\end_layout

\end_deeper
\end_deeper
\begin_layout Subsubsection*
Hiperparâmetros importantes
\end_layout

\begin_layout Itemize
Algorithm_mode;
\end_layout

\begin_layout Itemize
Subtract_mean;
\end_layout

\begin_deeper
\begin_layout Itemize
Dados não-enviesados;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Tipos de instância
\end_layout

\begin_layout Itemize
GPU ou CPU
\end_layout

\begin_deeper
\begin_layout Itemize
Depende 
\begin_inset Quotes eld
\end_inset

das especificações dos dados de entrada
\begin_inset Quotes erd
\end_inset

;
\end_layout

\end_deeper
\begin_layout Subsection
Factorization Machines
\end_layout

\begin_layout Subsubsection*
Para que serve?
\end_layout

\begin_layout Itemize
Lida com dados esparsos;
\end_layout

\begin_deeper
\begin_layout Itemize
Previsão de clique;
\end_layout

\begin_layout Itemize
Recomendações de itens;
\end_layout

\begin_layout Itemize
Como um usuário individual não interage com a maioria das págainas / produtos,
 os dados são esparsos;
\end_layout

\end_deeper
\begin_layout Itemize
Supervisionado
\end_layout

\begin_deeper
\begin_layout Itemize
Classificação ou regressão
\end_layout

\end_deeper
\begin_layout Itemize
Limitado a interação em pares;
\end_layout

\begin_deeper
\begin_layout Itemize
Usuário -> item por exemplo;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Que tipos de treinamento ele espera?
\end_layout

\begin_layout Itemize
RecordIO/Protobuf com Float32;
\end_layout

\begin_deeper
\begin_layout Itemize
Dados esparsos significam que CSV não é prático;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Como é usado?
\end_layout

\begin_layout Itemize
Encontra fatores que podemos usar para prever uma classificação (clique
 ou não? Compra ou não?) ou valor (avaliação prevista?).
 Dada uma matriz que representa algumas coisas (usuários e itens?);
\end_layout

\begin_layout Itemize
Normalmente usado no contexto de sistemas de recomendação;
\end_layout

\begin_layout Subsubsection*
Hiperparâmetros importantes
\end_layout

\begin_layout Itemize
Métodos de inicialização para bias, fatores e termos lineares;
\end_layout

\begin_deeper
\begin_layout Itemize
Uniforme, normal ou constante;
\end_layout

\begin_layout Itemize
Pode ajustar as propriedades de cada método;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Tipos de instância
\end_layout

\begin_layout Itemize
CPU ou GPU
\end_layout

\begin_deeper
\begin_layout Itemize
CPU é recomendado;
\end_layout

\begin_layout Itemize
GPU só funciona com dados densos;
\end_layout

\end_deeper
\begin_layout Subsection
IP Insights
\end_layout

\begin_layout Subsubsection*
Para que serve?
\end_layout

\begin_layout Itemize
Aprendizagem não supervisionada de padrões de uso de endereço IP;
\end_layout

\begin_layout Itemize
Identifica comportamento suspeito de endereços IP;
\end_layout

\begin_deeper
\begin_layout Itemize
Identifica logins de IPs anômalos;
\end_layout

\begin_layout Itemize
Identifique contas que criam recursos de IPs anômalos;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Que tipo de treinamento ele espera?
\end_layout

\begin_layout Itemize
Nomes de usuários e IDs de contas podem ser inseridos diretamente;
\end_layout

\begin_layout Itemize
Não há necessidade de pré-processamento;
\end_layout

\begin_layout Itemize
Canal de treinamento, validação opcional (calcula a pontuação AUC);
\end_layout

\begin_layout Itemize
CSV apenas;
\end_layout

\begin_deeper
\begin_layout Itemize
Entity, IP;
\end_layout

\end_deeper
\begin_layout Subsubsection*
Como é usado?
\end_layout

\begin_layout Itemize
Usa uma rede neural para aprender representações vetoriais latentes de entidades
 e endereços IP;
\end_layout

\begin_layout Itemize
Entidades são transformadas em hashs;
\end_layout

\begin_deeper
\begin_layout Itemize
Hash devem ter um tamanho grande o suficiente;
\end_layout

\end_deeper
\begin_layout Itemize
Gera automaticamente amostras negativas durante o treinamento, pareando
 aleatoriamente entidades e IPs;
\end_layout

\begin_layout Subsubsection*
Hiperparâmetros importantes
\end_layout

\begin_layout Itemize
Num_entity_vectors
\end_layout

\begin_deeper
\begin_layout Itemize
Tamanho do hash;
\end_layout

\begin_layout Itemize
Definido para duas vezes o número de identificadores de entidade exclusivos;
\end_layout

\end_deeper
\begin_layout Itemize
Vector_dim;
\end_layout

\begin_deeper
\begin_layout Itemize
Tamanho dos vetores de incorporação;
\end_layout

\begin_layout Itemize
Ajusta o tamanho do modelo;
\end_layout

\begin_layout Itemize
Muito grande gera overfitting;
\end_layout

\end_deeper
\begin_layout Itemize
Epochs, learning rate, batch size, etc.;
\end_layout

\begin_layout Subsubsection*
Tipos de instância
\end_layout

\begin_layout Itemize
CPU ou GPU
\end_layout

\begin_deeper
\begin_layout Itemize
GPU é recomendado;
\end_layout

\begin_layout Itemize
ml.p3.2xlarge ou superior;
\end_layout

\begin_layout Itemize
Pode usar várias GPUs;
\end_layout

\begin_layout Itemize
O tamanho da instância da CPU depende de vector_dim e num_entity_vectors;
\end_layout

\end_deeper
\end_body
\end_document
