{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c81f07ee",
   "metadata": {},
   "source": [
    "# Criando Aplicações de Deep Learning Utilizando o Keras 2.0\n",
    "\n",
    "## Criando um modelo no Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e47de643",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config IPCompleter.greedy=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89006455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-17 21:27:00.405092: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-03-17 21:27:00.405386: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-03-17 21:27:05.755132: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-03-17 21:27:05.755936: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-03-17 21:27:05.756260: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (lucas-Inspiron-5566): /proc/driver/nvidia/version does not exist\n",
      "2022-03-17 21:27:05.763701: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import *\n",
    "\n",
    "training_data_df = pd.read_csv(\"./ex_files/03/sales_data_training_scaled.csv\")\n",
    "\n",
    "X = training_data_df.drop('total_earnings', axis=1).values\n",
    "Y = training_data_df[['total_earnings']].values\n",
    "\n",
    "# define de model\n",
    "model = Sequential()\n",
    "model.add(Dense(50, input_dim=9, activation='relu'))\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(1, activation='linear'))\n",
    "model.compile(optimizer='adam', loss='mse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36da474e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "32/32 - 1s - loss: 0.0198 - 743ms/epoch - 23ms/step\n",
      "Epoch 2/50\n",
      "32/32 - 0s - loss: 0.0032 - 62ms/epoch - 2ms/step\n",
      "Epoch 3/50\n",
      "32/32 - 0s - loss: 0.0013 - 46ms/epoch - 1ms/step\n",
      "Epoch 4/50\n",
      "32/32 - 0s - loss: 6.2410e-04 - 47ms/epoch - 1ms/step\n",
      "Epoch 5/50\n",
      "32/32 - 0s - loss: 4.3155e-04 - 44ms/epoch - 1ms/step\n",
      "Epoch 6/50\n",
      "32/32 - 0s - loss: 2.7800e-04 - 46ms/epoch - 1ms/step\n",
      "Epoch 7/50\n",
      "32/32 - 0s - loss: 2.0947e-04 - 56ms/epoch - 2ms/step\n",
      "Epoch 8/50\n",
      "32/32 - 0s - loss: 1.7103e-04 - 52ms/epoch - 2ms/step\n",
      "Epoch 9/50\n",
      "32/32 - 0s - loss: 1.3260e-04 - 55ms/epoch - 2ms/step\n",
      "Epoch 10/50\n",
      "32/32 - 0s - loss: 1.1636e-04 - 67ms/epoch - 2ms/step\n",
      "Epoch 11/50\n",
      "32/32 - 0s - loss: 8.6805e-05 - 58ms/epoch - 2ms/step\n",
      "Epoch 12/50\n",
      "32/32 - 0s - loss: 8.1467e-05 - 57ms/epoch - 2ms/step\n",
      "Epoch 13/50\n",
      "32/32 - 0s - loss: 9.5749e-05 - 56ms/epoch - 2ms/step\n",
      "Epoch 14/50\n",
      "32/32 - 0s - loss: 7.7527e-05 - 60ms/epoch - 2ms/step\n",
      "Epoch 15/50\n",
      "32/32 - 0s - loss: 7.0923e-05 - 55ms/epoch - 2ms/step\n",
      "Epoch 16/50\n",
      "32/32 - 0s - loss: 5.0398e-05 - 60ms/epoch - 2ms/step\n",
      "Epoch 17/50\n",
      "32/32 - 0s - loss: 7.3999e-05 - 55ms/epoch - 2ms/step\n",
      "Epoch 18/50\n",
      "32/32 - 0s - loss: 7.3145e-05 - 64ms/epoch - 2ms/step\n",
      "Epoch 19/50\n",
      "32/32 - 0s - loss: 5.8953e-05 - 58ms/epoch - 2ms/step\n",
      "Epoch 20/50\n",
      "32/32 - 0s - loss: 3.9992e-05 - 56ms/epoch - 2ms/step\n",
      "Epoch 21/50\n",
      "32/32 - 0s - loss: 4.7801e-05 - 59ms/epoch - 2ms/step\n",
      "Epoch 22/50\n",
      "32/32 - 0s - loss: 5.3020e-05 - 55ms/epoch - 2ms/step\n",
      "Epoch 23/50\n",
      "32/32 - 0s - loss: 5.7627e-05 - 51ms/epoch - 2ms/step\n",
      "Epoch 24/50\n",
      "32/32 - 0s - loss: 3.5594e-05 - 60ms/epoch - 2ms/step\n",
      "Epoch 25/50\n",
      "32/32 - 0s - loss: 3.2356e-05 - 57ms/epoch - 2ms/step\n",
      "Epoch 26/50\n",
      "32/32 - 0s - loss: 2.9678e-05 - 59ms/epoch - 2ms/step\n",
      "Epoch 27/50\n",
      "32/32 - 0s - loss: 3.3319e-05 - 59ms/epoch - 2ms/step\n",
      "Epoch 28/50\n",
      "32/32 - 0s - loss: 4.5570e-05 - 56ms/epoch - 2ms/step\n",
      "Epoch 29/50\n",
      "32/32 - 0s - loss: 3.0179e-05 - 60ms/epoch - 2ms/step\n",
      "Epoch 30/50\n",
      "32/32 - 0s - loss: 2.5762e-05 - 56ms/epoch - 2ms/step\n",
      "Epoch 31/50\n",
      "32/32 - 0s - loss: 2.8588e-05 - 57ms/epoch - 2ms/step\n",
      "Epoch 32/50\n",
      "32/32 - 0s - loss: 2.7955e-05 - 52ms/epoch - 2ms/step\n",
      "Epoch 33/50\n",
      "32/32 - 0s - loss: 3.2954e-05 - 61ms/epoch - 2ms/step\n",
      "Epoch 34/50\n",
      "32/32 - 0s - loss: 3.3084e-05 - 59ms/epoch - 2ms/step\n",
      "Epoch 35/50\n",
      "32/32 - 0s - loss: 3.6105e-05 - 55ms/epoch - 2ms/step\n",
      "Epoch 36/50\n",
      "32/32 - 0s - loss: 4.2837e-05 - 58ms/epoch - 2ms/step\n",
      "Epoch 37/50\n",
      "32/32 - 0s - loss: 4.9786e-05 - 48ms/epoch - 1ms/step\n",
      "Epoch 38/50\n",
      "32/32 - 0s - loss: 3.1248e-05 - 46ms/epoch - 1ms/step\n",
      "Epoch 39/50\n",
      "32/32 - 0s - loss: 2.7646e-05 - 45ms/epoch - 1ms/step\n",
      "Epoch 40/50\n",
      "32/32 - 0s - loss: 2.6624e-05 - 46ms/epoch - 1ms/step\n",
      "Epoch 41/50\n",
      "32/32 - 0s - loss: 3.1067e-05 - 46ms/epoch - 1ms/step\n",
      "Epoch 42/50\n",
      "32/32 - 0s - loss: 5.2555e-05 - 45ms/epoch - 1ms/step\n",
      "Epoch 43/50\n",
      "32/32 - 0s - loss: 4.1550e-05 - 51ms/epoch - 2ms/step\n",
      "Epoch 44/50\n",
      "32/32 - 0s - loss: 4.4346e-05 - 56ms/epoch - 2ms/step\n",
      "Epoch 45/50\n",
      "32/32 - 0s - loss: 3.2182e-05 - 51ms/epoch - 2ms/step\n",
      "Epoch 46/50\n",
      "32/32 - 0s - loss: 5.3035e-05 - 58ms/epoch - 2ms/step\n",
      "Epoch 47/50\n",
      "32/32 - 0s - loss: 8.1163e-05 - 55ms/epoch - 2ms/step\n",
      "Epoch 48/50\n",
      "32/32 - 0s - loss: 7.1100e-05 - 60ms/epoch - 2ms/step\n",
      "Epoch 49/50\n",
      "32/32 - 0s - loss: 4.3068e-05 - 54ms/epoch - 2ms/step\n",
      "Epoch 50/50\n",
      "32/32 - 0s - loss: 3.4047e-05 - 62ms/epoch - 2ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7bd02fadf0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# train the model\n",
    "model.fit(\n",
    "    X,\n",
    "    Y,\n",
    "    epochs=50,\n",
    "    shuffle=True,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# load the separate test data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "355f0135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 1ms/step - loss: 8.2435e-05\n"
     ]
    }
   ],
   "source": [
    "test_data_df = pd.read_csv(\"./ex_files/03/sales_data_test_scaled.csv\")\n",
    "\n",
    "X_test = test_data_df.drop('total_earnings', axis=1).values\n",
    "Y_test = test_data_df[['total_earnings']].values\n",
    "\n",
    "test_error_rate = model.evaluate(X_test, Y_test, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5c815dec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Os valores de ganho previstos para o produto proposto é: $263878.5614644364\n"
     ]
    }
   ],
   "source": [
    "# Load the data we make to use to make a prediction\n",
    "X = pd.read_csv(\"./ex_files/04/proposed_new_product.csv\").values\n",
    "\n",
    "# make a prediction with the neural network\n",
    "prediction = model.predict(X)\n",
    "\n",
    "# grab just the first element of the first prediction\n",
    "prediction = prediction[0][0]\n",
    "\n",
    "# Re-scale the data from the 0-to-1 range back to dollars\n",
    "prediction = prediction + 0.1159\n",
    "prediction = prediction / 0.0000036968\n",
    "\n",
    "print(\"Os valores de ganho previstos para o produto proposto é: ${}\".format(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205736e0",
   "metadata": {},
   "source": [
    "## Salvando a rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "240423fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"trained_model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e72c433",
   "metadata": {},
   "source": [
    "## Carregando a rede neural"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a2b503bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earning prediction for proposed product - $263878.5614644364\n"
     ]
    }
   ],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"trained_model.h5\")\n",
    "\n",
    "X = pd.read_csv(\"./ex_files/04/proposed_new_product.csv\").values\n",
    "prediction = model.predict(X)\n",
    "\n",
    "# Grab just the first element of the first prediction\n",
    "prediction = prediction[0][0]\n",
    "\n",
    "# Re-scale the data from the 0-to-1 range back to dollar\n",
    "# These constants are from when the data was originally scaled down to 0-to-1\n",
    "prediction = prediction + 0.1159\n",
    "prediction = prediction / 0.0000036968\n",
    "\n",
    "print(\"Earning prediction for proposed product - ${}\".format(prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
